[
  {
    "page": 2,
    "bbox": [
      134.67494201660156,
      424.5639343261719,
      480.6753845214844,
      619.2679901123047
    ],
    "caption": "Fig. 1. Multi-modality evidence fusion framework. It is composed of four encoder-decoder feature extraction (FE) modules corresponding to T1Gd, T1, T2 and Flair modality inputs; four evidential segmentation (ES) modules corresponding to each of the inputs; and a multi-modality evidence fusion (MMEF) module.",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_01.png"
  },
  {
    "page": 2,
    "bbox": [
      134.67494201660156,
      424.5639343261719,
      480.6753845214844,
      619.2679901123047
    ],
    "caption": "Fig. 1. Multi-modality evidence fusion framework. It is composed of four encoder-decoder feature extraction (FE) modules corresponding to T1Gd, T1, T2 and Flair modality inputs; four evidential segmentation (ES) modules corresponding to each of the inputs; and a multi-modality evidence fusion (MMEF) module.",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      385.3045654296875,
      272.2035217285156,
      483.0822448730469,
      290.71820068359375
    ],
    "caption": "A⊆Ω",
    "file_name": [
      "figures/fileoutpart1.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_03.png"
  },
  {
    "page": 2,
    "bbox": [
      420.02099609375,
      278.5294952392578,
      423.99623107910156,
      285.5034942626953
    ],
    "caption": "Bel(A) =  ∅=B⊆A m(B) and Pl(A) =  B∩A=∅ m(B), ∀A ⊆ Ω.",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      435.11900329589844,
      278.5294952392578,
      439.09423828125,
      285.5034942626953
    ],
    "caption": "Bel(A) =  ∅=B⊆A m(B) and Pl(A) =  B∩A=∅ m(B), ∀A ⊆ Ω.",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      467.9290008544922,
      278.5294952392578,
      476.36753845214844,
      286.53564453125
    ],
    "caption": "(1)",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      385.3045654296875,
      272.2035217285156,
      483.0822448730469,
      290.71820068359375
    ],
    "caption": "A⊆Ω",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      134.76580810546875,
      235.83877563476562,
      483.08839416503906,
      278.75917053222656
    ],
    "caption": "Bel(A) =  ∅=B⊆A m(B) and Pl(A) =  B∩A=∅ m(B), ∀A ⊆ Ω.",
    "file_name": [
      "figures/fileoutpart2.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_08.png"
  },
  {
    "page": 2,
    "bbox": [
      288.8240051269531,
      259.72950744628906,
      296.7046203613281,
      267.73565673828125
    ],
    "caption": "Bel(A) =  ∅=B⊆A m(B) and Pl(A) =  B∩A=∅ m(B), ∀A ⊆ Ω.",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      386.9440002441406,
      248.23573303222656,
      407.04307556152344,
      261.1306457519531
    ],
    "caption": "Bel(A) =  ∅=B⊆A m(B) and Pl(A) =  B∩A=∅ m(B), ∀A ⊆ Ω.",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      134.76580810546875,
      235.83877563476562,
      483.08839416503906,
      278.75917053222656
    ],
    "caption": "Bel(A) =  ∅=B⊆A m(B) and Pl(A) =  B∩A=∅ m(B), ∀A ⊆ Ω.",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      167.41073608398438,
      178.17236328125,
      450.43980407714844,
      216.6101837158203
    ],
    "caption": "The contour function pl associated to m is the function that maps each element ω of Ω to its plausibility: pl(ω) = Pl({ω}).",
    "file_name": [
      "figures/fileoutpart3.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_12.png"
  },
  {
    "page": 2,
    "bbox": [
      167.41073608398438,
      178.17236328125,
      450.43980407714844,
      216.6101837158203
    ],
    "caption": "The contour function pl associated to m is the function that maps each element ω of Ω to its plausibility: pl(ω) = Pl({ω}).",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      210.62899780273438,
      618.7155151367188,
      407.2197570800781,
      657.1512298583984
    ],
    "caption": "for all A ⊆ Ω,A = ∅, where κ represents the degree of conﬂict between m1 and m2:",
    "file_name": [
      "figures/fileoutpart4.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_14.png"
  },
  {
    "page": 3,
    "bbox": [
      210.62899780273438,
      618.7155151367188,
      407.2197570800781,
      657.1512298583984
    ],
    "caption": "for all A ⊆ Ω,A = ∅, where κ represents the degree of conﬂict between m1 and m2:",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      252.97683715820312,
      560.3495788574219,
      364.8707580566406,
      598.7852935791016
    ],
    "caption": "pl12 = pl1pl2 1−κ .",
    "file_name": [
      "figures/fileoutpart5.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_16.png"
  },
  {
    "page": 3,
    "bbox": [
      252.97683715820312,
      560.3495788574219,
      364.8707580566406,
      598.7852935791016
    ],
    "caption": "pl12 = pl1pl2 1−κ .",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      277.7899932861328,
      483.73291015625,
      340.05604553222656,
      514.3419494628906
    ],
    "caption": "Equation ((<>)4) allows us to compute the contour function in time proportional to the size of Ω, without having to compute the combined mass m1 ⊕ m2.",
    "file_name": [
      "figures/fileoutpart6.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_18.png"
  },
  {
    "page": 3,
    "bbox": [
      277.7899932861328,
      483.73291015625,
      340.05604553222656,
      514.3419494628906
    ],
    "caption": "Equation ((<>)4) allows us to compute the contour function in time proportional to the size of Ω, without having to compute the combined mass m1 ⊕ m2.",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      250.0627899169922,
      264.9449005126953,
      367.77870178222656,
      283.85235595703125
    ],
    "caption": "where γi > 0 and αi ∈ [0, 1] are two parameters. The second hidden layer computes mass functions mi representing the evidence of each prototype pi using the following equations:",
    "file_name": [
      "figures/fileoutpart7.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_20.png"
  },
  {
    "page": 3,
    "bbox": [
      250.0627899169922,
      264.9449005126953,
      367.77870178222656,
      283.85235595703125
    ],
    "caption": "where γi > 0 and αi ∈ [0, 1] are two parameters. The second hidden layer computes mass functions mi representing the evidence of each prototype pi using the following equations:",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      237.6496124267578,
      180.5509033203125,
      379.4822540283203,
      214.0054168701172
    ],
    "caption": "where γi > 0 and αi ∈ [0, 1] are two parameters. The second hidden layer computes mass functions mi representing the evidence of each prototype pi using the following equations:",
    "file_name": [
      "figures/fileoutpart8.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_22.png"
  },
  {
    "page": 3,
    "bbox": [
      237.6496124267578,
      180.5509033203125,
      379.4822540283203,
      214.0054168701172
    ],
    "caption": "where γi > 0 and αi ∈ [0, 1] are two parameters. The second hidden layer computes mass functions mi representing the evidence of each prototype pi using the following equations:",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      255.35400390625,
      579.5048980712891,
      362.49424743652344,
      599.4444732666016
    ],
    "caption": "where m? is the vacuous mass function defined by m?(Ω) = 1, and coeﬃcient β is the degree of belief that the source mass function m is reliable [(<>)21]. When β = 1 we accept mass function m provided by the source and take it as a description of our knowledge; when β = 0, we reject it and we are left with the vacuous mass function m?. In this paper, we focus on the situation when β ∈ [0, 1] and combine uncertain evidence with partial reliability using Dempster’s rule.",
    "file_name": [
      "figures/fileoutpart9.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_24.png"
  },
  {
    "page": 4,
    "bbox": [
      255.35400390625,
      579.5048980712891,
      362.49424743652344,
      599.4444732666016
    ],
    "caption": "where m? is the vacuous mass function defined by m?(Ω) = 1, and coeﬃcient β is the degree of belief that the source mass function m is reliable [(<>)21]. When β = 1 we accept mass function m provided by the source and take it as a description of our knowledge; when β = 0, we reject it and we are left with the vacuous mass function m?. In this paper, we focus on the situation when β ∈ [0, 1] and combine uncertain evidence with partial reliability using Dempster’s rule.",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      200.05799865722656,
      392.8459014892578,
      417.7982635498047,
      412.7864685058594
    ],
    "caption": "When we have several sources provided by independent evidence, the discounted evidence can be combined by Dempster’s rule. Assuming that we have two source of information, let β1 plS1 and β2 plS2 be the discounted contour functions provided, respectively, by sources S1 and S2, with discount rate vectors 1 − β1 and 1 − β2. From ((<>)4), the combined contour function is proportional to the product β β 1 plS1 2 plS2 .",
    "file_name": [
      "figures/fileoutpart10.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_26.png"
  },
  {
    "page": 4,
    "bbox": [
      200.05799865722656,
      392.8459014892578,
      417.7982635498047,
      412.7864685058594
    ],
    "caption": "When we have several sources provided by independent evidence, the discounted evidence can be combined by Dempster’s rule. Assuming that we have two source of information, let β1 plS1 and β2 plS2 be the discounted contour functions provided, respectively, by sources S1 and S2, with discount rate vectors 1 − β1 and 1 − β2. From ((<>)4), the combined contour function is proportional to the product β β 1 plS1 2 plS2 .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      229.90899658203125,
      199.85865783691406,
      382.7279510498047,
      253.8465576171875
    ],
    "caption": "β Sn = H h=1 β h plSh ({ωk}) K k=1  H h=1 βh plSh ({ωk}) ,",
    "file_name": [
      "figures/fileoutpart11.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_28.png"
  },
  {
    "page": 4,
    "bbox": [
      229.90899658203125,
      199.85865783691406,
      382.7279510498047,
      253.8465576171875
    ],
    "caption": "β Sn = H h=1 β h plSh ({ωk}) K k=1  H h=1 βh plSh ({ωk}) ,",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      234.85899353027344,
      127.60670471191406,
      382.9905090332031,
      181.59556579589844
    ],
    "caption": "where βSn is the normalized segmentation output for voxel n by fusing H discounted source information,",
    "file_name": [
      "figures/fileoutpart12.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_30.png"
  },
  {
    "page": 4,
    "bbox": [
      234.85899353027344,
      127.60670471191406,
      382.9905090332031,
      181.59556579589844
    ],
    "caption": "where βSn is the normalized segmentation output for voxel n by fusing H discounted source information,",
    "file_name": ""
  },
  {
    "page": 8,
    "bbox": [
      134.68850708007812,
      510.8484649658203,
      480.667236328125,
      676.2413787841797
    ],
    "caption": "Fig. 2. Visualized segmentation results. The ﬁrst and the second row are the whole brain with tumor and the detailed tumor region (the main diﬀerences are marked in blue circles). The three columns correspond, from left to right, to the Flair image, the ground truth and the segmentation results obtained by Residual-UNet and MMEF-UNet. The green, yellow and red represent the ET, ED and NRC/NET, respectively.",
    "file_name": [
      "figures/fileoutpart19.png"
    ],
    "output_file": "assets/images/paper/Evidence-fusion-with-contextual-discounting-for-multi-modality-medical-image-segmentation/fig_32.png"
  },
  {
    "page": 8,
    "bbox": [
      134.68850708007812,
      510.8484649658203,
      480.667236328125,
      676.2413787841797
    ],
    "caption": "Fig. 2. Visualized segmentation results. The ﬁrst and the second row are the whole brain with tumor and the detailed tumor region (the main diﬀerences are marked in blue circles). The three columns correspond, from left to right, to the Flair image, the ground truth and the segmentation results obtained by Residual-UNet and MMEF-UNet. The green, yellow and red represent the ET, ED and NRC/NET, respectively.",
    "file_name": ""
  }
]