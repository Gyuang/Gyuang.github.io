[
  {
    "page": -1,
    "bbox": [
      131.47254943847656,
      543.5117492675781,
      481.7737274169922,
      556.7864685058594
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_01.png"
  },
  {
    "page": -1,
    "bbox": [
      131.47254943847656,
      543.5117492675781,
      481.7737274169922,
      556.7864685058594
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      107.89732360839844,
      606.2301788330078,
      504.0374298095703,
      721.0266265869141
    ],
    "caption": "Figure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end. For query x, we use Maximum Inner Product Search (MIPS) to find the top-K documents zi. For final prediction y, we treat z as a latent variable and marginalize over seq2seq predictions given different documents.",
    "file_name": [
      "figures/fileoutpart1.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_03.png"
  },
  {
    "page": 1,
    "bbox": [
      107.89732360839844,
      606.2301788330078,
      504.0374298095703,
      721.0266265869141
    ],
    "caption": "Figure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end. For query x, we use Maximum Inner Product Search (MIPS) to find the top-K documents zi. For final prediction y, we treat z as a latent variable and marginalize over seq2seq predictions given different documents.",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      143.35726928710938,
      494.70018005371094,
      471.1300964355469,
      533.1364135742188
    ],
    "caption": "RAG-Token Model In the RAG-Token model we can draw a different latent document for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Concretely, the top K documents are retrieved using the retriever, and then the generator produces a distribution for the next output token for each document, before marginalizing, and repeating the process with the following output token, Formally, we define:",
    "file_name": [
      "figures/fileoutpart2.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_05.png"
  },
  {
    "page": 2,
    "bbox": [
      143.35726928710938,
      494.70018005371094,
      471.1300964355469,
      533.1364135742188
    ],
    "caption": "RAG-Token Model In the RAG-Token model we can draw a different latent document for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Concretely, the top K documents are retrieved using the retriever, and then the generator produces a distribution for the next output token for each document, before marginalizing, and repeating the process with the following output token, Formally, we define:",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      181.8780059814453,
      392.28570556640625,
      432.6141052246094,
      430.72142028808594
    ],
    "caption": "Finally, we note that RAG can be used for sequence classification tasks by considering the target class as a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.",
    "file_name": [
      "figures/fileoutpart3.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_07.png"
  },
  {
    "page": 2,
    "bbox": [
      181.8780059814453,
      392.28570556640625,
      432.6141052246094,
      430.72142028808594
    ],
    "caption": "Finally, we note that RAG can be used for sequence classification tasks by considering the target class as a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      107.691162109375,
      285.89341735839844,
      490.3566589355469,
      333.8024444580078
    ],
    "caption": "2.3 Generator: BART",
    "file_name": [
      "figures/fileoutpart4.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_09.png"
  },
  {
    "page": 2,
    "bbox": [
      313.22161865234375,
      321.7975158691406,
      323.18421936035156,
      333.8024444580078
    ],
    "caption": "d(z) = BERTd(z), q(x) = BERTq(x)",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      107.691162109375,
      285.89341735839844,
      490.3566589355469,
      333.8024444580078
    ],
    "caption": "2.3 Generator: BART",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      297.07997131347656,
      304.07554626464844,
      459.81419372558594,
      316.51844787597656
    ],
    "caption": "where d(z) is a dense representation of a document produced by a BERTBASE document encoder [(<>)8], and q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating top-k(pη(·|x)), the list of k documents z with highest prior probability pη(z|x), is a Maximum Inner Product Search (MIPS) problem, which can be approximately solved in sub-linear time [(<>)23]. We use a pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This retriever was trained to retrieve documents which contain answers to TriviaQA [(<>)24] questions and Natural Questions [(<>)29]. We refer to the document index as the non-parametric memory.",
    "file_name": [
      "figures/fileoutpart5.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_12.png"
  },
  {
    "page": 2,
    "bbox": [
      297.07997131347656,
      304.07554626464844,
      459.81419372558594,
      316.51844787597656
    ],
    "caption": "where d(z) is a dense representation of a document produced by a BERTBASE document encoder [(<>)8], and q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating top-k(pη(·|x)), the list of k documents z with highest prior probability pη(z|x), is a Maximum Inner Product Search (MIPS) problem, which can be approximately solved in sub-linear time [(<>)23]. We use a pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This retriever was trained to retrieve documents which contain answers to TriviaQA [(<>)24] questions and Natural Questions [(<>)29]. We refer to the document index as the non-parametric memory.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      291.22096252441406,
      652.9346618652344,
      500.0685119628906,
      717.4498748779297
    ],
    "caption": "Table 3: Examples from generation tasks. RAG models generate more specific and factually accurate responses. ‘?’ indicates factually incorrect responses, * indicates partially correct responses.",
    "file_name": [
      "figures/fileoutpart10.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_14.png"
  },
  {
    "page": 6,
    "bbox": [
      291.22096252441406,
      652.9346618652344,
      500.0685119628906,
      717.4498748779297
    ],
    "caption": "Table 3: Examples from generation tasks. RAG models generate more specific and factually accurate responses. ‘?’ indicates factually incorrect responses, * indicates partially correct responses.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      108.08586120605469,
      208.16702270507812,
      505.0322570800781,
      292.3126525878906
    ],
    "caption": "5 Related Work",
    "file_name": [
      "figures/fileoutpart19.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_16.png"
  },
  {
    "page": 7,
    "bbox": [
      108.08586120605469,
      208.16702270507812,
      505.0322570800781,
      292.3126525878906
    ],
    "caption": "5 Related Work",
    "file_name": ""
  },
  {
    "page": 16,
    "bbox": [
      108.0,
      369.8800048828125,
      504.0050506591797,
      521.6132507324219
    ],
    "caption": "Figure 4: Annotation interface for human evaluation of factuality. A pop-out for detailed instructions and a worked example appear when clicking \"view tool guide\".",
    "file_name": [
      "figures/fileoutpart20.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_18.png"
  }
]