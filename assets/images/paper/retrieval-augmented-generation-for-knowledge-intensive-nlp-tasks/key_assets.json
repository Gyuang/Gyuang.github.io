{
  "architecture": {
    "page": 1,
    "bbox": [
      107.89732360839844,
      606.2301788330078,
      504.0374298095703,
      721.0266265869141
    ],
    "caption": "Figure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end. For query x, we use Maximum Inner Product Search (MIPS) to find the top-K documents zi. For final prediction y, we treat z as a latent variable and marginalize over seq2seq predictions given different documents.",
    "file_name": [
      "figures/fileoutpart1.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_03.png"
  },
  "results": {
    "page": 5,
    "bbox": [
      113.81649780273438,
      580.9592132568359,
      298.32215881347656,
      661.9739837646484
    ],
    "caption": "to more effective marginalization over documents. Furthermore, RAG can generate correct answers even when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such cases for NQ, where an extractive model would score 0%.",
    "file_name": [
      "tables/fileoutpart6.xlsx",
      "tables/fileoutpart7.png"
    ],
    "output_file": "assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/table_01.png"
  },
  "results_2": null,
  "markdown": "### Main Architecture\n![Architecture](/assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/fig_03.png)\n캡션: Figure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end. For query x, we use Maximum Inner Product Search (MIPS) to find the top-K documents zi. For final prediction y, we treat z as a latent variable and marginalize over seq2seq predictions given different documents.\n\n### Main Results Table\n![Results](/assets/images/paper/Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks/table_01.png)\n캡션: to more effective marginalization over documents. Furthermore, RAG can generate correct answers even when the correct answer is not in any retrieved document, achieving 11.8% accuracy in such cases for NQ, where an extractive model would score 0%."
}