[
  {
    "page": -1,
    "bbox": [
      66.96499633789062,
      757.9490051269531,
      110.23399353027344,
      786.4609985351562
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_01.png"
  },
  {
    "page": -1,
    "bbox": [
      270.72645568847656,
      392.6515197753906,
      616.1552886962891,
      587.0339050292969
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart1.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_02.png"
  },
  {
    "page": -1,
    "bbox": [
      270.72645568847656,
      392.6515197753906,
      616.1552886962891,
      587.0339050292969
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      101.70907592773438,
      765.0739135742188,
      379.3846740722656,
      837.8549041748047
    ],
    "caption": "Projector Patch EmbeddingVision Transformer Blocks EB Block Vision Transformer Blocks EB Block Prediction Block 0.15 0.32 0.42 0.77 Gene Expression Slide Image Window ExtractorDecoderReconstructed Slide Image Window Dataset Unsupervised Exemplar Retrieval (Sec. 3.1) with Retrieve Exemplar Learning (Sec. 3.2) with Discarded",
    "file_name": [
      "figures/fileoutpart2.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_04.png"
  },
  {
    "page": 2,
    "bbox": [
      101.70907592773438,
      765.0739135742188,
      379.3846740722656,
      837.8549041748047
    ],
    "caption": "Projector Patch EmbeddingVision Transformer Blocks EB Block Vision Transformer Blocks EB Block Prediction Block 0.15 0.32 0.42 0.77 Gene Expression Slide Image Window ExtractorDecoderReconstructed Slide Image Window Dataset Unsupervised Exemplar Retrieval (Sec. 3.1) with Retrieve Exemplar Learning (Sec. 3.2) with Discarded",
    "file_name": ""
  },
  {
    "page": 2,
    "bbox": [
      76.71612548828125,
      524.8915100097656,
      519.4253540039062,
      719.1414642333984
    ],
    "caption": "Figure 2: EGN framework. Our networks are trained in a two-stage manner. In the stage of unsupervised exemplar retrieval (Sec. 3.1), we learn an extractor E(·) and a decoder G(·) with image reconstruction objectives. After convergence, we use the extractor E(·) with a distance metric for unsupervised exemplar retrieval. For example, given Xi, we obtain the global view of Xi, i.e., ei and ei = E(Xi), and construct the nearest exemplar set KXi = {ej , yj }, where ej is the exemplar global view, and yj is the exemplar gene expression. In the stage of exemplar learning (Sec. 3.2), we train a network C(·, ·, ·) to predict gene expression yi from Xi, ei, and KXi . We use a vision transformer (ViT) as our backbone. The proposed EB block is interleaved with the vision transformer blocks. With a projector, we refine ei and KXi = {ej , yj} to h0 , {r0}, and {s0}. Then, they are used by the EB block to revise the ViT patch representation and are updated to ht , {rt}, and {st}, where 1 ≤ t ≤ T, and T is the number of layers. Finally, we have a prediction block that concatenates the refined global view hT of Xi and the attention-pooled ViT patch representation, to achieve the gene expression prediction task.",
    "file_name": [
      "figures/fileoutpart3.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_06.png"
  },
  {
    "page": 2,
    "bbox": [
      76.71612548828125,
      524.8915100097656,
      519.4253540039062,
      719.1414642333984
    ],
    "caption": "Figure 2: EGN framework. Our networks are trained in a two-stage manner. In the stage of unsupervised exemplar retrieval (Sec. 3.1), we learn an extractor E(·) and a decoder G(·) with image reconstruction objectives. After convergence, we use the extractor E(·) with a distance metric for unsupervised exemplar retrieval. For example, given Xi, we obtain the global view of Xi, i.e., ei and ei = E(Xi), and construct the nearest exemplar set KXi = {ej , yj }, where ej is the exemplar global view, and yj is the exemplar gene expression. In the stage of exemplar learning (Sec. 3.2), we train a network C(·, ·, ·) to predict gene expression yi from Xi, ei, and KXi . We use a vision transformer (ViT) as our backbone. The proposed EB block is interleaved with the vision transformer blocks. With a projector, we refine ei and KXi = {ej , yj} to h0 , {r0}, and {s0}. Then, they are used by the EB block to revise the ViT patch representation and are updated to ht , {rt}, and {st}, where 1 ≤ t ≤ T, and T is the number of layers. Finally, we have a prediction block that concatenates the refined global view hT of Xi and the attention-pooled ViT patch representation, to achieve the gene expression prediction task.",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      68.91172790527344,
      655.8545989990234,
      198.12452697753906,
      720.8799896240234
    ],
    "caption": "Figure 3: Gene expression distributions of STNet dataset [13]. Each gene expression is log-transformed. (a) is well distributed expression of gene RPS18. (b) and (c) are long-tail distributed expression of gene S100A8 and gene RPS10.",
    "file_name": [
      "figures/fileoutpart4.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_08.png"
  },
  {
    "page": 3,
    "bbox": [
      68.91172790527344,
      655.8545989990234,
      198.12452697753906,
      720.8799896240234
    ],
    "caption": "Figure 3: Gene expression distributions of STNet dataset [13]. Each gene expression is log-transformed. (a) is well distributed expression of gene RPS18. (b) and (c) are long-tail distributed expression of gene S100A8 and gene RPS10.",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      79.57611083984375,
      175.20152282714844,
      259.3836364746094,
      239.54177856445312
    ],
    "caption": "LE = min G,E max F EXi∼X  L1 + LLPIPS + LF  .",
    "file_name": [
      "figures/fileoutpart5.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_10.png"
  },
  {
    "page": 3,
    "bbox": [
      79.57611083984375,
      175.20152282714844,
      259.3836364746094,
      239.54177856445312
    ],
    "caption": "LE = min G,E max F EXi∼X  L1 + LLPIPS + LF  .",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      76.52273559570312,
      107.74952697753906,
      262.45103454589844,
      149.17578125
    ],
    "caption": "L1 = |Xi − G(E(Xi))|, LLPIPS = ∥ϕ(Xi) − ϕ(G(E(Xi)))∥2, LF =u  F  Xi  +u  − F  G(E(Xi))  ,",
    "file_name": [
      "figures/fileoutpart6.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_12.png"
  },
  {
    "page": 3,
    "bbox": [
      76.52273559570312,
      107.74952697753906,
      262.45103454589844,
      149.17578125
    ],
    "caption": "L1 = |Xi − G(E(Xi))|, LLPIPS = ∥ϕ(Xi) − ϕ(G(E(Xi)))∥2, LF =u  F  Xi  +u  − F  G(E(Xi))  ,",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      329.8334655761719,
      646.9701995849609,
      524.2707672119141,
      718.8274536132812
    ],
    "caption": "Figure 4: Overview of the exemplar retrieval. For example, blue cycles are pre encoded global views. Given Xi, we extract ei with E(·) and retrieve the nearest exemplars.",
    "file_name": [
      "figures/fileoutpart7.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_14.png"
  },
  {
    "page": 3,
    "bbox": [
      329.8334655761719,
      646.9701995849609,
      524.2707672119141,
      718.8274536132812
    ],
    "caption": "Figure 4: Overview of the exemplar retrieval. For example, blue cycles are pre encoded global views. Given Xi, we extract ei with E(·) and retrieve the nearest exemplars.",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      308.86199951171875,
      159.99002075195312,
      553.5510711669922,
      174.6516571044922
    ],
    "caption": "where the superscript of h0i , r0j , and sj0 denotes that they are initial refined global view, and [·, ·] is a concatenation operator. MLP0h(·) and MLPs0(·) are two layer perceptrons with a ReLU activation function. MLPr0(·) shares the same parameters with MLP0h(·) but has an extra linear layer on top of it.",
    "file_name": [
      "figures/fileoutpart8.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_16.png"
  },
  {
    "page": 3,
    "bbox": [
      308.86199951171875,
      159.99002075195312,
      553.5510711669922,
      174.6516571044922
    ],
    "caption": "where the superscript of h0i , r0j , and sj0 denotes that they are initial refined global view, and [·, ·] is a concatenation operator. MLP0h(·) and MLPs0(·) are two layer perceptrons with a ReLU activation function. MLPr0(·) shares the same parameters with MLP0h(·) but has an extra linear layer on top of it.",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      -63.3741455078125,
      538.3408813476562,
      731.7394561767578,
      1200.4962615966797
    ],
    "caption": "Figure 5: EB block architecture. The inputs are hi, {rtj | j ∈ Υi}, and {stj | j ∈ Υi}, and Zt . Firstly, we project sj to sit+1 and have interactions between hi and rj . This interaction is assisted by and obtains and Secondly, hˆit is projected to the number of patches in the ViT backbone, to scale the magnitude of the ViT patch representation Zt . By their interactions, hˆit+1 and Zt are updated to hti +1 and Zt+1 .",
    "file_name": [
      "figures/fileoutpart9.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_18.png"
  },
  {
    "page": 4,
    "bbox": [
      -63.3741455078125,
      538.3408813476562,
      731.7394561767578,
      1200.4962615966797
    ],
    "caption": "Figure 5: EB block architecture. The inputs are hi, {rtj | j ∈ Υi}, and {stj | j ∈ Υi}, and Zt . Firstly, we project sj to sit+1 and have interactions between hi and rj . This interaction is assisted by and obtains and Secondly, hˆit is projected to the number of patches in the ViT backbone, to scale the magnitude of the ViT patch representation Zt . By their interactions, hˆit+1 and Zt are updated to hti +1 and Zt+1 .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      132.47352600097656,
      476.11773681640625,
      151.83865356445312,
      491.16064453125
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": [
      "figures/fileoutpart10.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_20.png"
  },
  {
    "page": 4,
    "bbox": [
      136.99099731445312,
      483.1544952392578,
      151.83865356445312,
      491.16064453125
    ],
    "caption": "i",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      136.99099731445312,
      476.11773681640625,
      139.8085479736328,
      483.09173583984375
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      132.47352600097656,
      476.11773681640625,
      151.83865356445312,
      491.16064453125
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      201.5593719482422,
      477.3977966308594,
      226.080322265625,
      491.1868133544922
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": [
      "figures/fileoutpart11.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_24.png"
  },
  {
    "page": 4,
    "bbox": [
      207.927001953125,
      481.77049255371094,
      210.9398193359375,
      488.7445068359375
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      210.93280029296875,
      477.3977966308594,
      226.080322265625,
      489.7766571044922
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      201.5593719482422,
      477.3977966308594,
      226.080322265625,
      491.1868133544922
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      244.42791748046875,
      476.11773681640625,
      267.72450256347656,
      491.16064453125
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": [
      "figures/fileoutpart12.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_28.png"
  },
  {
    "page": 4,
    "bbox": [
      249.1479949951172,
      483.1544952392578,
      263.9956512451172,
      491.16064453125
    ],
    "caption": "i",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      249.1479949951172,
      476.11773681640625,
      251.96554565429688,
      483.09173583984375
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      244.42791748046875,
      476.11773681640625,
      267.72450256347656,
      491.16064453125
    ],
    "caption": "Backbone. We use the ViT as our backbone [9]. It has a patch embedding layer and vision transformer blocks. The patch embedding layer tiles the slide image window Xi into non-overlapping patches before flattening and feeding to a linear layer. The outputs are Z0 = [zl0 | l ∈ 1, · · · , L], where L is the total number of patches, and Z0 is a matrix representation of the projected patches. Each vision transformer block composes of a self-attention layer and a feed-forward layer, which performs global interaction among Z0 . Assuming there are T layers, and let t ∈ [1, · · · , T]. We denote the lth patch representation at tth layer as ztl .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      50.11518859863281,
      111.75872802734375,
      75.05349731445312,
      126.80165100097656
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart13.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_32.png"
  },
  {
    "page": 4,
    "bbox": [
      56.47700500488281,
      111.75872802734375,
      59.29454040527344,
      118.73272705078125
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      50.11518859863281,
      111.75872802734375,
      75.05349731445312,
      126.80165100097656
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      234.50135803222656,
      111.71249389648438,
      248.08450317382812,
      125.48381042480469
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart14.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_35.png"
  },
  {
    "page": 4,
    "bbox": [
      239.59500122070312,
      118.14950561523438,
      242.60781860351562,
      125.12350463867188
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      239.59500122070312,
      111.71249389648438,
      243.85610961914062,
      119.71864318847656
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      234.50135803222656,
      111.71249389648438,
      248.08450317382812,
      125.48381042480469
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      331.96620178222656,
      551.5335235595703,
      510.0647888183594,
      588.4966583251953
    ],
    "caption": "where MLPm t (·) is a Multi-layer perceptron, the Chunk(·) operator equally splits the input into two outputs, and σ(·) is a Sigmoid function. To avoid notation overloading, we remain to use MLPst (·) as a single-layer perceptron. Secondly, hˆit+1 and Zt reciprocate each other by scaling the magnitude of each patch representation zlt ∈ Zt:",
    "file_name": [
      "figures/fileoutpart15.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_39.png"
  },
  {
    "page": 4,
    "bbox": [
      331.96620178222656,
      551.5335235595703,
      510.0647888183594,
      588.4966583251953
    ],
    "caption": "where MLPm t (·) is a Multi-layer perceptron, the Chunk(·) operator equally splits the input into two outputs, and σ(·) is a Sigmoid function. To avoid notation overloading, we remain to use MLPst (·) as a single-layer perceptron. Secondly, hˆit+1 and Zt reciprocate each other by scaling the magnitude of each patch representation zlt ∈ Zt:",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      331.96531677246094,
      523.4197387695312,
      524.5002899169922,
      554.9526519775391
    ],
    "caption": "where MLPm t (·) is a Multi-layer perceptron, the Chunk(·) operator equally splits the input into two outputs, and σ(·) is a Sigmoid function. To avoid notation overloading, we remain to use MLPst (·) as a single-layer perceptron. Secondly, hˆit+1 and Zt reciprocate each other by scaling the magnitude of each patch representation zlt ∈ Zt:",
    "file_name": [
      "figures/fileoutpart16.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_41.png"
  },
  {
    "page": 4,
    "bbox": [
      331.96531677246094,
      523.4197387695312,
      524.5002899169922,
      554.9526519775391
    ],
    "caption": "where MLPm t (·) is a Multi-layer perceptron, the Chunk(·) operator equally splits the input into two outputs, and σ(·) is a Sigmoid function. To avoid notation overloading, we remain to use MLPst (·) as a single-layer perceptron. Secondly, hˆit+1 and Zt reciprocate each other by scaling the magnitude of each patch representation zlt ∈ Zt:",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      327.3473205566406,
      417.3860168457031,
      435.19207763671875,
      432.04664611816406
    ],
    "caption": "h t+1 i = ˆht+1 i + MLPt h(Avg(O t h)),",
    "file_name": [
      "figures/fileoutpart17.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_43.png"
  },
  {
    "page": 4,
    "bbox": [
      327.3473205566406,
      417.3860168457031,
      435.19207763671875,
      432.04664611816406
    ],
    "caption": "h t+1 i = ˆht+1 i + MLPt h(Avg(O t h)),",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      327.34259033203125,
      399.95472717285156,
      469.3176727294922,
      414.9976501464844
    ],
    "caption": "Ot h, Ot z = Chunk(MLPt o(Zt) · σ(MLPt ˆh(ˆht+1 i ))),",
    "file_name": [
      "figures/fileoutpart18.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_45.png"
  },
  {
    "page": 4,
    "bbox": [
      327.34259033203125,
      399.95472717285156,
      469.3176727294922,
      414.9976501464844
    ],
    "caption": "Ot h, Ot z = Chunk(MLPt o(Zt) · σ(MLPt ˆh(ˆht+1 i ))),",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      327.3449249267578,
      377.7895202636719,
      529.1252899169922,
      397.87864685058594
    ],
    "caption": "t",
    "file_name": [
      "figures/fileoutpart19.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_47.png"
  },
  {
    "page": 4,
    "bbox": [
      327.3449249267578,
      377.7895202636719,
      529.1252899169922,
      397.87864685058594
    ],
    "caption": "t",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      338.59288024902344,
      354.2635192871094,
      467.9854278564453,
      374.28265380859375
    ],
    "caption": "z",
    "file_name": [
      "figures/fileoutpart20.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_49.png"
  },
  {
    "page": 4,
    "bbox": [
      359.0780029296875,
      366.27650451660156,
      363.8342742919922,
      374.28265380859375
    ],
    "caption": "Ot h, Ot z = Chunk(MLPt o(Zt) · σ(MLPt ˆh(ˆht+1 i ))),",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      359.0780029296875,
      359.62330627441406,
      362.8858337402344,
      366.59730529785156
    ],
    "caption": "Ot h, Ot z = Chunk(MLPt o(Zt) · σ(MLPt ˆh(ˆht+1 i ))),",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      403.2790069580078,
      366.27650451660156,
      408.03526306152344,
      374.28265380859375
    ],
    "caption": "t",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      403.2790069580078,
      359.62330627441406,
      407.9446563720703,
      366.59730529785156
    ],
    "caption": "t",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      448.052001953125,
      366.27650451660156,
      452.8082733154297,
      374.28265380859375
    ],
    "caption": "O",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      448.052001953125,
      359.62330627441406,
      451.9853057861328,
      366.59730529785156
    ],
    "caption": "ˆht+1 .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      338.59288024902344,
      354.2635192871094,
      467.9854278564453,
      374.28265380859375
    ],
    "caption": "z",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      491.3984832763672,
      354.2635192871094,
      530.0486755371094,
      373.25050354003906
    ],
    "caption": "Ot h, Ot z = Chunk(MLPt o(Zt) · σ(MLPt ˆh(ˆht+1 i ))),",
    "file_name": [
      "figures/fileoutpart21.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_57.png"
  },
  {
    "page": 4,
    "bbox": [
      511.8739929199219,
      366.27650451660156,
      514.8868103027344,
      373.25050354003906
    ],
    "caption": "Ot h, Ot z = Chunk(MLPt o(Zt) · σ(MLPt ˆh(ˆht+1 i ))),",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      512.0065002441406,
      359.83949279785156,
      517.7251892089844,
      367.8456573486328
    ],
    "caption": "Ot h, Ot z = Chunk(MLPt o(Zt) · σ(MLPt ˆh(ˆht+1 i ))),",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      491.3984832763672,
      354.2635192871094,
      530.0486755371094,
      373.25050354003906
    ],
    "caption": "Ot h, Ot z = Chunk(MLPt o(Zt) · σ(MLPt ˆh(ˆht+1 i ))),",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      412.6845397949219,
      346.27650451660156,
      426.04527282714844,
      360.7196502685547
    ],
    "caption": "MLP(·)",
    "file_name": [
      "figures/fileoutpart22.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_61.png"
  },
  {
    "page": 4,
    "bbox": [
      421.28900146484375,
      352.7135009765625,
      426.04527282714844,
      360.7196502685547
    ],
    "caption": "MLP(Z).",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      421.28900146484375,
      346.27650451660156,
      425.95465087890625,
      353.25050354003906
    ],
    "caption": "MLP(Z).",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      412.6845397949219,
      346.27650451660156,
      426.04527282714844,
      360.7196502685547
    ],
    "caption": "MLP(·)",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      446.93824768066406,
      346.6321716308594,
      460.3032684326172,
      360.7196502685547
    ],
    "caption": "i",
    "file_name": [
      "figures/fileoutpart23.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_65.png"
  },
  {
    "page": 4,
    "bbox": [
      455.5469970703125,
      352.7135009765625,
      460.3032684326172,
      360.7196502685547
    ],
    "caption": "ˆht+1 .",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      455.5469970703125,
      346.6321716308594,
      459.35484313964844,
      353.6061706542969
    ],
    "caption": "ˆht+1",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      446.93824768066406,
      346.6321716308594,
      460.3032684326172,
      360.7196502685547
    ],
    "caption": "i",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      445.12513732910156,
      332.9577331542969,
      470.0605010986328,
      348.0006561279297
    ],
    "caption": "ˆht+1",
    "file_name": [
      "figures/fileoutpart24.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_69.png"
  },
  {
    "page": 4,
    "bbox": [
      451.48399353027344,
      332.9577331542969,
      454.3015441894531,
      339.9317321777344
    ],
    "caption": "ˆht+1",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      445.12513732910156,
      332.9577331542969,
      470.0605010986328,
      348.0006561279297
    ],
    "caption": "ˆht+1",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      380.685302734375,
      315.9565124511719,
      418.60768127441406,
      335.97564697265625
    ],
    "caption": "t",
    "file_name": [
      "figures/fileoutpart25.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_72.png"
  },
  {
    "page": 4,
    "bbox": [
      401.16600036621094,
      327.96949768066406,
      405.9222717285156,
      335.97564697265625
    ],
    "caption": "MLP(Z).",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      401.16600036621094,
      321.31629943847656,
      405.09930419921875,
      328.29029846191406
    ],
    "caption": "MLP(Z).",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      380.685302734375,
      315.9565124511719,
      418.60768127441406,
      335.97564697265625
    ],
    "caption": "t",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      392.4548034667969,
      297.40631103515625,
      440.60011291503906,
      312.06565856933594
    ],
    "caption": "MLP(·)",
    "file_name": [
      "figures/fileoutpart26.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_76.png"
  },
  {
    "page": 4,
    "bbox": [
      412.9290008544922,
      304.0594940185547,
      417.6852722167969,
      312.06565856933594
    ],
    "caption": "MLP(·)",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      412.9290008544922,
      297.40631103515625,
      416.8623046875,
      304.38031005859375
    ],
    "caption": "MLP(·)",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      428.2359924316406,
      303.4824981689453,
      431.2488098144531,
      310.4564971923828
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      392.4548034667969,
      297.40631103515625,
      440.60011291503906,
      312.06565856933594
    ],
    "caption": "MLP(·)",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      442.18421936035156,
      261.2267303466797,
      463.39964294433594,
      276.2696533203125
    ],
    "caption": "Prediction Block. Following [38], each ViT patch representation shows different priorities toward the gene expression prediction task. We apply an attention pooling layer AttPool(·) to aggregate Moreover, h is a pro-Xi, which captures high-level attributes of Xi. We con-T i catenate h and AttPool(ZT) for the prediction. We have gressively refined global view of the slide image window T i",
    "file_name": [
      "figures/fileoutpart27.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_81.png"
  },
  {
    "page": 4,
    "bbox": [
      448.552001953125,
      261.2267303466797,
      451.3695373535156,
      268.2007293701172
    ],
    "caption": "Prediction Block. Following [38], each ViT patch representation shows different priorities toward the gene expression prediction task. We apply an attention pooling layer AttPool(·) to aggregate Moreover, h is a pro-Xi, which captures high-level attributes of Xi. We con-T i catenate h and AttPool(ZT) for the prediction. We have gressively refined global view of the slide image window T i",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      442.18421936035156,
      261.2267303466797,
      463.39964294433594,
      276.2696533203125
    ],
    "caption": "Prediction Block. Following [38], each ViT patch representation shows different priorities toward the gene expression prediction task. We apply an attention pooling layer AttPool(·) to aggregate Moreover, h is a pro-Xi, which captures high-level attributes of Xi. We con-T i catenate h and AttPool(ZT) for the prediction. We have gressively refined global view of the slide image window T i",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      509.68927001953125,
      208.3605194091797,
      547.6076812744141,
      228.37965393066406
    ],
    "caption": "Prediction Block. Following [38], each ViT patch representation shows different priorities toward the gene expression prediction task. We apply an attention pooling layer AttPool(·) to aggregate Moreover, h is a pro-Xi, which captures high-level attributes of Xi. We con-T i catenate h and AttPool(ZT) for the prediction. We have gressively refined global view of the slide image window T i",
    "file_name": [
      "figures/fileoutpart28.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_84.png"
  },
  {
    "page": 4,
    "bbox": [
      530.1649932861328,
      220.37350463867188,
      534.9212646484375,
      228.37965393066406
    ],
    "caption": "Prediction Block. Following [38], each ViT patch representation shows different priorities toward the gene expression prediction task. We apply an attention pooling layer AttPool(·) to aggregate Moreover, h is a pro-Xi, which captures high-level attributes of Xi. We con-T i catenate h and AttPool(ZT) for the prediction. We have gressively refined global view of the slide image window T i",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      530.1649932861328,
      213.72030639648438,
      534.0982971191406,
      220.69430541992188
    ],
    "caption": "Prediction Block. Following [38], each ViT patch representation shows different priorities toward the gene expression prediction task. We apply an attention pooling layer AttPool(·) to aggregate Moreover, h is a pro-Xi, which captures high-level attributes of Xi. We con-T i catenate h and AttPool(ZT) for the prediction. We have gressively refined global view of the slide image window T i",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      509.68927001953125,
      208.3605194091797,
      547.6076812744141,
      228.37965393066406
    ],
    "caption": "Prediction Block. Following [38], each ViT patch representation shows different priorities toward the gene expression prediction task. We apply an attention pooling layer AttPool(·) to aggregate Moreover, h is a pro-Xi, which captures high-level attributes of Xi. We con-T i catenate h and AttPool(ZT) for the prediction. We have gressively refined global view of the slide image window T i",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      406.1529998779297,
      148.5845184326172,
      449.0084991455078,
      168.0266571044922
    ],
    "caption": "yi = MLPg([h T i , AttPool(Z T )]),",
    "file_name": [
      "figures/fileoutpart29.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_88.png"
  },
  {
    "page": 4,
    "bbox": [
      438.46800231933594,
      160.02049255371094,
      445.2746276855469,
      168.0266571044922
    ],
    "caption": "yi = MLPg([h T i , AttPool(Z T )]),",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      406.1529998779297,
      148.5845184326172,
      449.0084991455078,
      168.0266571044922
    ],
    "caption": "yi = MLPg([h T i , AttPool(Z T )]),",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      361.2444305419922,
      84.20402526855469,
      495.2253875732422,
      98.78665161132812
    ],
    "caption": "Prediction Block. Following [38], each ViT patch representation shows different priorities toward the gene expression prediction task. We apply an attention pooling layer AttPool(·) to aggregate Moreover, h is a pro-Xi, which captures high-level attributes of Xi. We con-T i catenate h and AttPool(ZT) for the prediction. We have gressively refined global view of the slide image window T i",
    "file_name": [
      "figures/fileoutpart30.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_91.png"
  },
  {
    "page": 4,
    "bbox": [
      361.2444305419922,
      84.20402526855469,
      495.2253875732422,
      98.78665161132812
    ],
    "caption": "Prediction Block. Following [38], each ViT patch representation shows different priorities toward the gene expression prediction task. We apply an attention pooling layer AttPool(·) to aggregate Moreover, h is a pro-Xi, which captures high-level attributes of Xi. We con-T i catenate h and AttPool(ZT) for the prediction. We have gressively refined global view of the slide image window T i",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      128.15927124023438,
      417.2345275878906,
      209.55361938476562,
      435.7457733154297
    ],
    "caption": "4. Experiments",
    "file_name": [
      "figures/fileoutpart33.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_93.png"
  },
  {
    "page": 5,
    "bbox": [
      128.15927124023438,
      417.2345275878906,
      209.55361938476562,
      435.7457733154297
    ],
    "caption": "4. Experiments",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      53.297271728515625,
      640.6892700195312,
      542.7133331298828,
      717.6798706054688
    ],
    "caption": "Figure 6: Quantitative evaluation of the top performed models from Tab. 1 and Tab. 4. We employ t-SNE [29] for dimension reduction of model latent space. We use the extra labels (i.e., tumour and normal) from the STNet dataset for annotations.",
    "file_name": [
      "figures/fileoutpart34.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_95.png"
  },
  {
    "page": 6,
    "bbox": [
      53.297271728515625,
      640.6892700195312,
      542.7133331298828,
      717.6798706054688
    ],
    "caption": "Figure 6: Quantitative evaluation of the top performed models from Tab. 1 and Tab. 4. We employ t-SNE [29] for dimension reduction of model latent space. We use the extra labels (i.e., tumour and normal) from the STNet dataset for annotations.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      47.73908996582031,
      629.5087127685547,
      324.9206237792969,
      721.9880676269531
    ],
    "caption": "Figure 7: Ablation study on number of exemplar used in EB block. This number is varied from one to fifteen, and we present PCC@M, MSE, and MAE in sub-figure (a), (b), and (c).",
    "file_name": [
      "figures/fileoutpart35.png"
    ],
    "output_file": "assets/images/paper/EGN_Exemplar_Guided_DNN_for_Spatial_Transcriptomics_WACV2023/fig_97.png"
  },
  {
    "page": 7,
    "bbox": [
      47.73908996582031,
      629.5087127685547,
      324.9206237792969,
      721.9880676269531
    ],
    "caption": "Figure 7: Ablation study on number of exemplar used in EB block. This number is varied from one to fifteen, and we present PCC@M, MSE, and MAE in sub-figure (a), (b), and (c).",
    "file_name": ""
  }
]