[
  {
    "page": 1,
    "bbox": [
      131.6522216796875,
      548.6652679443359,
      477.9058380126953,
      721.0239868164062
    ],
    "caption": "Figure 1: Test-time Prompt Tuning (TPT) for image classification. We tune adaptive prompts on the fly with a single test sample, without the need for additional training data or annotations. TPT optimizes the prompt to encourage consistent predictions across augmented views by minimizing the marginal entropy. We introduce confidence selection to filter out noisy augmentations.",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_01.png"
  },
  {
    "page": 1,
    "bbox": [
      131.6522216796875,
      548.6652679443359,
      477.9058380126953,
      721.0239868164062
    ],
    "caption": "Figure 1: Test-time Prompt Tuning (TPT) for image classification. We tune adaptive prompts on the fly with a single test sample, without the need for additional training data or annotations. TPT optimizes the prompt to encourage consistent predictions across augmented views by minimizing the marginal entropy. We introduce confidence selection to filter out noisy augmentations.",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      108.0,
      226.5633087158203,
      501.3025817871094,
      257.2854766845703
    ],
    "caption": "p ∗ = arg min p E(X,y)∼Dtrain L(F p(X), y),",
    "file_name": [
      "figures/fileoutpart1.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_03.png"
  },
  {
    "page": 3,
    "bbox": [
      180.15199279785156,
      242.95355224609375,
      182.96946716308594,
      249.92735290527344
    ],
    "caption": "Prompt tuning using downstream training data. Instead of using a hand-crafted prompt, prompt tuning methods train a prompt to maximize performance on a downstream task for which labeled data is available. Prompt tuning optimizes the prompt p ∈ RL×D in the text embedding space, with the number of tokens L and embedding size D, using training data with annotations Dtrain = {(Xi, yi)} from the downstream task. The goal is to obtain text inputs {p; Y} = {{p; yi} for yi ∈ Y} that can provide the model with the most helpful context information about the task. For image classification with cross-entropy loss L, the problem can be formulated as:",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      256.1840057373047,
      248.72067260742188,
      259.15281677246094,
      253.7069549560547
    ],
    "caption": "Prompt tuning using downstream training data. Instead of using a hand-crafted prompt, prompt tuning methods train a prompt to maximize performance on a downstream task for which labeled data is available. Prompt tuning optimizes the prompt p ∈ RL×D in the text embedding space, with the number of tokens L and embedding size D, using training data with annotations Dtrain = {(Xi, yi)} from the downstream task. The goal is to obtain text inputs {p; Y} = {{p; yi} for yi ∈ Y} that can provide the model with the most helpful context information about the task. For image classification with cross-entropy loss L, the problem can be formulated as:",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      224.6540069580078,
      238.42567443847656,
      234.40737915039062,
      244.1442108154297
    ],
    "caption": "Prompt tuning using downstream training data. Instead of using a hand-crafted prompt, prompt tuning methods train a prompt to maximize performance on a downstream task for which labeled data is available. Prompt tuning optimizes the prompt p ∈ RL×D in the text embedding space, with the number of tokens L and embedding size D, using training data with annotations Dtrain = {(Xi, yi)} from the downstream task. The goal is to obtain text inputs {p; Y} = {{p; yi} for yi ∈ Y} that can provide the model with the most helpful context information about the task. For image classification with cross-entropy loss L, the problem can be formulated as:",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      266.88299560546875,
      239.6106719970703,
      269.85182189941406,
      244.59695434570312
    ],
    "caption": "Prompt tuning using downstream training data. Instead of using a hand-crafted prompt, prompt tuning methods train a prompt to maximize performance on a downstream task for which labeled data is available. Prompt tuning optimizes the prompt p ∈ RL×D in the text embedding space, with the number of tokens L and embedding size D, using training data with annotations Dtrain = {(Xi, yi)} from the downstream task. The goal is to obtain text inputs {p; Y} = {{p; yi} for yi ∈ Y} that can provide the model with the most helpful context information about the task. For image classification with cross-entropy loss L, the problem can be formulated as:",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      108.0,
      226.5633087158203,
      501.3025817871094,
      257.2854766845703
    ],
    "caption": "p ∗ = arg min p E(X,y)∼Dtrain L(F p(X), y),",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      222.93817138671875,
      127.17190551757812,
      386.2173767089844,
      147.1124725341797
    ],
    "caption": "where F p(X) = sim(Etext({p; Y}), Evisual(X)).",
    "file_name": [
      "figures/fileoutpart2.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_09.png"
  },
  {
    "page": 3,
    "bbox": [
      222.93817138671875,
      127.17190551757812,
      386.2173767089844,
      147.1124725341797
    ],
    "caption": "where F p(X) = sim(Etext({p; Y}), Evisual(X)).",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      203.27413940429688,
      107.21681213378906,
      411.2296905517578,
      125.98635864257812
    ],
    "caption": "Context-dependent visual reasoning. For the task of context-dependent visual reasoning, such as Bongard-HOI [(<>)15], a test sample contains two sets of support images and a query image for evaluation. The two sets of support images exemplify the presence and the absence of a human-object interaction",
    "file_name": [
      "figures/fileoutpart3.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_11.png"
  },
  {
    "page": 3,
    "bbox": [
      203.27413940429688,
      107.21681213378906,
      411.2296905517578,
      125.98635864257812
    ],
    "caption": "Context-dependent visual reasoning. For the task of context-dependent visual reasoning, such as Bongard-HOI [(<>)15], a test sample contains two sets of support images and a query image for evaluation. The two sets of support images exemplify the presence and the absence of a human-object interaction",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      249.81761169433594,
      366.0009002685547,
      364.6761016845703,
      385.9404754638672
    ],
    "caption": "for some carefully constructed loss. Note that, unlike equation ((<>)1), our method does not require any labels or any data beyond the zero-shot test sample.",
    "file_name": [
      "figures/fileoutpart4.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_13.png"
  },
  {
    "page": 4,
    "bbox": [
      249.81761169433594,
      366.0009002685547,
      364.6761016845703,
      385.9404754638672
    ],
    "caption": "for some carefully constructed loss. Note that, unlike equation ((<>)1), our method does not require any labels or any data beyond the zero-shot test sample.",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      208.1739501953125,
      220.647705078125,
      406.31671142578125,
      259.0834197998047
    ],
    "caption": "Here, pp(y|Ai(Xtest)) is the vector of class probabilities produced by the model when provided with prompt p and the i-th augmented view of the test image.",
    "file_name": [
      "figures/fileoutpart5.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_15.png"
  },
  {
    "page": 4,
    "bbox": [
      208.1739501953125,
      220.647705078125,
      406.31671142578125,
      259.0834197998047
    ],
    "caption": "Here, pp(y|Ai(Xtest)) is the vector of class probabilities produced by the model when provided with prompt p and the i-th augmented view of the test image.",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      217.74099731445312,
      185.6967010498047,
      406.2401580810547,
      224.13241577148438
    ],
    "caption": "Here, pp(y|Ai(Xtest)) is the vector of class probabilities produced by the model when provided with prompt p and the i-th augmented view of the test image.",
    "file_name": [
      "figures/fileoutpart6.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_17.png"
  },
  {
    "page": 4,
    "bbox": [
      217.74099731445312,
      185.6967010498047,
      406.2401580810547,
      224.13241577148438
    ],
    "caption": "Here, pp(y|Ai(Xtest)) is the vector of class probabilities produced by the model when provided with prompt p and the i-th augmented view of the test image.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      203.03713989257812,
      665.0545196533203,
      411.4576721191406,
      703.4917755126953
    ],
    "caption": "TPT for context-dependent visual reasoning. Different from image classification, where every image has one and only ground-truth label, the correctness of the prediction in Bongard-HOI depends on the context (i.e., example images), which is binary (containing the concept c or not). In the case of binary labels, a straightforward prompting strategy is to hand-craft “labels\" for positive and negative examples, such as “True/False\" or “Yes/No\". With our proposed TPT, on the other hand, we can directly learn an optimal label token cls on the example images in the test sample. More importantly, for visual reasoning, TPT can explicitly learn the context (i.e., visual concept) in the form of text prompts, and assists visual reasoning of vision-language models with language context. Formally, given M support images in each test sample, the TPT objective for context-dependent reasoning can be written as:",
    "file_name": [
      "figures/fileoutpart7.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_19.png"
  },
  {
    "page": 5,
    "bbox": [
      203.03713989257812,
      665.0545196533203,
      411.4576721191406,
      703.4917755126953
    ],
    "caption": "TPT for context-dependent visual reasoning. Different from image classification, where every image has one and only ground-truth label, the correctness of the prediction in Bongard-HOI depends on the context (i.e., example images), which is binary (containing the concept c or not). In the case of binary labels, a straightforward prompting strategy is to hand-craft “labels\" for positive and negative examples, such as “True/False\" or “Yes/No\". With our proposed TPT, on the other hand, we can directly learn an optimal label token cls on the example images in the test sample. More importantly, for visual reasoning, TPT can explicitly learn the context (i.e., visual concept) in the form of text prompts, and assists visual reasoning of vision-language models with language context. Formally, given M support images in each test sample, the TPT objective for context-dependent reasoning can be written as:",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      209.91400146484375,
      519.3499908447266,
      404.5778350830078,
      557.7872467041016
    ],
    "caption": "Note that the support set is an essential part of a Bongard-HOI sample, which provides the context for this context-dependent task. Therefore, our approach is still considered to work purely at test time, without training data or annotations (i.e., TPT has not been trained on a collection of similar tasks from the Bongard-HOI training split).",
    "file_name": [
      "figures/fileoutpart8.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_21.png"
  },
  {
    "page": 5,
    "bbox": [
      209.91400146484375,
      519.3499908447266,
      404.5778350830078,
      557.7872467041016
    ],
    "caption": "Note that the support set is an essential part of a Bongard-HOI sample, which provides the context for this context-dependent task. Therefore, our approach is still considered to work purely at test time, without training data or annotations (i.e., TPT has not been trained on a collection of similar tasks from the Bongard-HOI training split).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      149.29798889160156,
      225.8152618408203,
      465.3992462158203,
      412.0107727050781
    ],
    "caption": "Figure 2: Test-time Prompt Tuning (TPT) for context-dependent visual reasoning on Bongard-HOI benchmark. A test sample in Bonagrd-HOI consists of several support images that exemplify a visual concept, and the model needs to predict whether the query image contains the concept. TPT tunes the prompt and class tokens simultaneously on the support images using the cross-entropy loss.",
    "file_name": [
      "figures/fileoutpart9.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_23.png"
  },
  {
    "page": 5,
    "bbox": [
      149.29798889160156,
      225.8152618408203,
      465.3992462158203,
      412.0107727050781
    ],
    "caption": "Figure 2: Test-time Prompt Tuning (TPT) for context-dependent visual reasoning on Bongard-HOI benchmark. A test sample in Bonagrd-HOI consists of several support images that exemplify a visual concept, and the model needs to predict whether the query image contains the concept. TPT tunes the prompt and class tokens simultaneously on the support images using the cross-entropy loss.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      110.58549499511719,
      350.7375030517578,
      283.783203125,
      516.8350677490234
    ],
    "caption": "(a) CoOp with CLIP-RN50.",
    "file_name": [
      "figures/fileoutpart12.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_25.png"
  },
  {
    "page": 7,
    "bbox": [
      110.58549499511719,
      350.7375030517578,
      283.783203125,
      516.8350677490234
    ],
    "caption": "(a) CoOp with CLIP-RN50.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      307.11749267578125,
      350.7375030517578,
      514.52001953125,
      516.8350677490234
    ],
    "caption": "(b) CoCoOp with CLIP-RN50.",
    "file_name": [
      "figures/fileoutpart13.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_27.png"
  },
  {
    "page": 7,
    "bbox": [
      307.11749267578125,
      350.7375030517578,
      514.52001953125,
      516.8350677490234
    ],
    "caption": "(b) CoCoOp with CLIP-RN50.",
    "file_name": ""
  },
  {
    "page": 9,
    "bbox": [
      121.34800720214844,
      53.92906188964844,
      296.0594787597656,
      304.7398986816406
    ],
    "caption": "From the results, we see that optimizing text prompts achieves the most performance gain compared to other parameter groups. In addition, we find optimizing the visual encoder to have the worst result. This observation is in alignment with previous work that suggests fine-tuning the image encoder can distort pre-trained features [(<>)68, (<>)51].",
    "file_name": [
      "figures/fileoutpart18.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_29.png"
  },
  {
    "page": 9,
    "bbox": [
      121.34800720214844,
      53.92906188964844,
      296.0594787597656,
      304.7398986816406
    ],
    "caption": "From the results, we see that optimizing text prompts achieves the most performance gain compared to other parameter groups. In addition, we find optimizing the visual encoder to have the worst result. This observation is in alignment with previous work that suggests fine-tuning the image encoder can distort pre-trained features [(<>)68, (<>)51].",
    "file_name": ""
  },
  {
    "page": 9,
    "bbox": [
      331.14088439941406,
      203.25450134277344,
      476.7358856201172,
      304.57496643066406
    ],
    "caption": "(b) Different cutoff percentile in confidence selection.",
    "file_name": [
      "figures/fileoutpart19.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_31.png"
  },
  {
    "page": 9,
    "bbox": [
      331.14088439941406,
      203.25450134277344,
      476.7358856201172,
      304.57496643066406
    ],
    "caption": "(b) Different cutoff percentile in confidence selection.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      140.03799438476562,
      329.695556640625,
      475.76800537109375,
      446.4356994628906
    ],
    "caption": "Figure 5: Analysis on the trade-off between efficiency and accuracy. We evaluate the top-1 accuracy on the distribution shifts benchmarks in section (<>)4.1. Results are based on a CLIP-RN50.",
    "file_name": [
      "figures/fileoutpart22.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_33.png"
  },
  {
    "page": 10,
    "bbox": [
      140.03799438476562,
      329.695556640625,
      475.76800537109375,
      446.4356994628906
    ],
    "caption": "Figure 5: Analysis on the trade-off between efficiency and accuracy. We evaluate the top-1 accuracy on the distribution shifts benchmarks in section (<>)4.1. Results are based on a CLIP-RN50.",
    "file_name": ""
  },
  {
    "page": 18,
    "bbox": [
      156.83226013183594,
      215.69781494140625,
      452.6773986816406,
      382.16685485839844
    ],
    "caption": "In this section, we provide a qualitative analysis of the effect of TPT on the probability distribution of the augmented views of a test sample. In each figure, the top left panel shows the test image, and the bar plot on the top right shows CLIP’s prediction on the test image before (on the left) and after (on the right) we apply TPT. The bottom two panels show the probability distribution among 200 classes (of ImageNet-R) of 64 augmented views. Each peak of a prediction curve indicates a high probability in the corresponding class. The prediction probability of the original test sample is at the bottom, and we mark the index of the ground-truth class on the x-axis. From the example images, we find that TPT can effectively make the predictions more consistent across different augmented views.",
    "file_name": [
      "figures/fileoutpart37.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_35.png"
  },
  {
    "page": 18,
    "bbox": [
      156.83226013183594,
      215.69781494140625,
      452.6773986816406,
      382.16685485839844
    ],
    "caption": "In this section, we provide a qualitative analysis of the effect of TPT on the probability distribution of the augmented views of a test sample. In each figure, the top left panel shows the test image, and the bar plot on the top right shows CLIP’s prediction on the test image before (on the left) and after (on the right) we apply TPT. The bottom two panels show the probability distribution among 200 classes (of ImageNet-R) of 64 augmented views. Each peak of a prediction curve indicates a high probability in the corresponding class. The prediction probability of the original test sample is at the bottom, and we mark the index of the ground-truth class on the x-axis. From the example images, we find that TPT can effectively make the predictions more consistent across different augmented views.",
    "file_name": ""
  },
  {
    "page": 19,
    "bbox": [
      156.83226013183594,
      94.10882568359375,
      452.6773986816406,
      697.8918609619141
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart38.png"
    ],
    "output_file": "assets/images/paper/TPT-Test-Time-Prompt-Tuning-for-Zero-Shot-Generalization/fig_37.png"
  },
  {
    "page": 19,
    "bbox": [
      156.83226013183594,
      94.10882568359375,
      452.6773986816406,
      697.8918609619141
    ],
    "caption": "",
    "file_name": ""
  }
]