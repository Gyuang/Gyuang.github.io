{
  "architecture": {
    "page": 1,
    "bbox": [
      134.76499938964844,
      525.1940002441406,
      480.58470153808594,
      676.1647491455078
    ],
    "caption": "Fig. 1: The comparison between V2T-CoT and existing Med-VQA methods. A employs a combined vision and text encoding strategy with regional attention for medical diagnosis. In contrast, previous methods (B & C) either lack reasoning or utilize it in a text-only context. D demonstrates the pipeline of V2T-CoT.",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/V2T-CoT-From-Vision-to-Text-Chain-of-Thought-for-Medical-Reasoning-and-Diagnosis/fig_01.png"
  },
  "results": {
    "page": 7,
    "bbox": [
      140.74200439453125,
      297.7159423828125,
      336.7882385253906,
      368.7991485595703
    ],
    "caption": "Table 3: Comparison of different Vision Detection method performance and the effect on Related Med-VQA.",
    "file_name": [
      "tables/fileoutpart17.xlsx",
      "tables/fileoutpart18.png"
    ],
    "output_file": "assets/images/paper/V2T-CoT-From-Vision-to-Text-Chain-of-Thought-for-Medical-Reasoning-and-Diagnosis/table_288.png"
  },
  "results_2": null,
  "markdown": "### Main Architecture\n![Architecture](/assets/images/paper/V2T-CoT-From-Vision-to-Text-Chain-of-Thought-for-Medical-Reasoning-and-Diagnosis/fig_01.png)\n캡션: Fig. 1: The comparison between V2T-CoT and existing Med-VQA methods. A employs a combined vision and text encoding strategy with regional attention for medical diagnosis. In contrast, previous methods (B & C) either lack reasoning or utilize it in a text-only context. D demonstrates the pipeline of V2T-CoT.\n\n### Main Results Table\n![Results](/assets/images/paper/V2T-CoT-From-Vision-to-Text-Chain-of-Thought-for-Medical-Reasoning-and-Diagnosis/table_288.png)\n캡션: Table 3: Comparison of different Vision Detection method performance and the effect on Related Med-VQA."
}