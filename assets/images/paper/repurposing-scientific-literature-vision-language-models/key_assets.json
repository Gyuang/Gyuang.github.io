{
  "architecture": {
    "page": 2,
    "bbox": [
      42.0,
      415.9537353515625,
      570.0,
      739.9537353515625
    ],
    "caption": "Fig. 1. Overview of key contributions. (A) We developed a pipeline for the acquisition, extraction, and filtering of figures, captions, and in-text mentions from a family of biomedical journals. We converted this data from unstructured biomedical texts and images into publication-, education-, and task-specific AI training datasets. (B) We trained CNS-Obsidian, a 34B parameter autoregressive vision-language model, to be tailored to domain-specific needs for neurosurgery by implementing a novel training step designed to specifically entrain capabilities in differential diagnosis while maintaining the ability to converse and answer questions. (C) We conducted a blinded, randomized, controlled trial comparing CNS Obsidian to GPT-4o as diagnostic copilots on a busy inpatient surgical service.",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/Repurposing-Scientific-Literature-Vision-Language-Models/fig_01.png"
  },
  "results": {
    "page": 28,
    "bbox": [
      81.0,
      402.453125,
      530.9999694824219,
      739.953125
    ],
    "caption": "Fig. S8. Ablation studies of three-stage training using Claude-generated evaluations. Configuration [X, Y, Z] denotes number of epochs in Stages 1, 2, and 3. (A) Impact of Stage 1 (alignment) and Stage 2 (general fine-tuning) epochs on model accuracy using Claude generated MCQs dataset (n=1,239), with Stage 3 fixed at 0. Darker red indicates higher accuracy. Baseline [0, 0, 0] achieves 46.53%. Alignment-only training [1, 0, 0] decreases performance to 43.54%. (B) Performance comparison across configurations showing each stage's contribution. Error bars represent standard error. The full three-stage model [1, 3, 3] shows substantial improvement, with Stage 3 providing the largest gain (+13.33%, p < 10-12). (C) Temporal evolution of model performance across training stages. Solid lines represent measurements, dashed lines show interpolated trajectories. (D) Optimization of Stage 3 duration using configuration [1, 3, X]. Performance peaks at X = 10 epochs (70.92%) before plateauing. (E) Effect of Stage 2 duration [1, X, 10]. Performance remains stable, with [1, 10, 10] achieving slightly better results (71.08%, p=0.9647). (F) Joint optimization of Stage 1 and Stage 2/3 durations (configurations [X, Y, Y]). Longer training shows improvements, leading to selection of [5, 10, 10] for final evaluation using both datasets.",
    "file_name": [
      "figures/fileoutpart12.png"
    ],
    "output_file": "assets/images/paper/Repurposing-Scientific-Literature-Vision-Language-Models/fig_13.png"
  },
  "results_2": null,
  "markdown": "### Main Architecture\n![Architecture](/assets/images/paper/Repurposing-Scientific-Literature-Vision-Language-Models/fig_01.png)\n캡션: Fig. 1. Overview of key contributions. (A) We developed a pipeline for the acquisition, extraction, and filtering of figures, captions, and in-text mentions from a family of biomedical journals. We converted this data from unstructured biomedical texts and images into publication-, education-, and task-specific AI training datasets. (B) We trained CNS-Obsidian, a 34B parameter autoregressive visio…\n\n### Main Results Table\n![Results](/assets/images/paper/Repurposing-Scientific-Literature-Vision-Language-Models/fig_13.png)\n캡션: Fig. S8. Ablation studies of three-stage training using Claude-generated evaluations. Configuration [X, Y, Z] denotes number of epochs in Stages 1, 2, and 3. (A) Impact of Stage 1 (alignment) and Stage 2 (general fine-tuning) epochs on model accuracy using Claude generated MCQs dataset (n=1,239), with Stage 3 fixed at 0. Darker red indicates higher accuracy. Baseline [0, 0, 0] achieves 46.53%. Ali…"
}