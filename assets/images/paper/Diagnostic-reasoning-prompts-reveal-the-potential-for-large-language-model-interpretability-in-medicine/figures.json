[
  {
    "page": 4,
    "bbox": [
      120.01383972167969,
      580.3077545166016,
      468.9252471923828,
      722.8025817871094
    ],
    "caption": "Fig. 1: Examining biases in LAION-5B, Stable Diffusion XL (SDXL), and our SDXL-Inc. Comparing gender and race distributions in LAION-5B, SDXL, and our SDXL-Inc based on a sample of 88,714 images from the LAION-5B dataset, 10,000 images generated by SDXL, and 10,000 generated by SDXL-Inc. For the latter 20,000 images, we used the prompt: “a photo of a person”.",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_01.png"
  },
  {
    "page": 4,
    "bbox": [
      120.01383972167969,
      580.3077545166016,
      468.9252471923828,
      722.8025817871094
    ],
    "caption": "Fig. 1: Examining biases in LAION-5B, Stable Diffusion XL (SDXL), and our SDXL-Inc. Comparing gender and race distributions in LAION-5B, SDXL, and our SDXL-Inc based on a sample of 88,714 images from the LAION-5B dataset, 10,000 images generated by SDXL, and 10,000 generated by SDXL-Inc. For the latter 20,000 images, we used the prompt: “a photo of a person”.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      142.12474060058594,
      364.03883361816406,
      494.2167663574219,
      726.9488830566406
    ],
    "caption": "the results for the 25 professions, while Supplementary Figure 2 depicts the remaining seven professions. Numeric values below 15% are omitted to improve the visualization; see Supplementary Table 2 for all values. As can be seen, White is the most frequently generated race in 21 out of the 25 professions. As for the remaining four, two of them are among the least prestige occupations, namely Cleaner and Security Guard [30], and both are mostly represented by images depicting Black individuals. Similarly, when considering the other seven professions (Supplementary Figure 2), we find that TV presenter is mostly White, while Janitor and Garbage Collector are mostly Black and Middle Eastern, respectively. These findings confirm the findings of [9], showing that prestigious, high-paying professions are often represented as White.",
    "file_name": [
      "figures/fileoutpart1.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_03.png"
  },
  {
    "page": 5,
    "bbox": [
      142.12474060058594,
      364.03883361816406,
      494.2167663574219,
      726.9488830566406
    ],
    "caption": "the results for the 25 professions, while Supplementary Figure 2 depicts the remaining seven professions. Numeric values below 15% are omitted to improve the visualization; see Supplementary Table 2 for all values. As can be seen, White is the most frequently generated race in 21 out of the 25 professions. As for the remaining four, two of them are among the least prestige occupations, namely Cleaner and Security Guard [30], and both are mostly represented by images depicting Black individuals. Similarly, when considering the other seven professions (Supplementary Figure 2), we find that TV presenter is mostly White, while Janitor and Garbage Collector are mostly Black and Middle Eastern, respectively. These findings confirm the findings of [9], showing that prestigious, high-paying professions are often represented as White.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      110.57260131835938,
      375.6824645996094,
      497.3115539550781,
      721.7544097900391
    ],
    "caption": "Fig. 3: Results of SDXL-Inc. Given eight attributes and eight professions, both SDXL and SDXL-Inc were used to generate 10,000 images per profession and per attribute. a, Race distribution per attribute, with the upper row corresponding to SDXL, and the lower row corresponding to SDXL-Inc. b, The same as (a) but for professions instead of attributes. c, Gender distribution per profession and per attribute for SDXL and SDXL-Inc. The standard deviation(s) corresponding to each subplot is denoted by σ followed by a subscript indicating the model.",
    "file_name": [
      "figures/fileoutpart2.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_05.png"
  },
  {
    "page": 7,
    "bbox": [
      110.57260131835938,
      375.6824645996094,
      497.3115539550781,
      721.7544097900391
    ],
    "caption": "Fig. 3: Results of SDXL-Inc. Given eight attributes and eight professions, both SDXL and SDXL-Inc were used to generate 10,000 images per profession and per attribute. a, Race distribution per attribute, with the upper row corresponding to SDXL, and the lower row corresponding to SDXL-Inc. b, The same as (a) but for professions instead of attributes. c, Gender distribution per profession and per attribute for SDXL and SDXL-Inc. The standard deviation(s) corresponding to each subplot is denoted by σ followed by a subscript indicating the model.",
    "file_name": ""
  },
  {
    "page": 9,
    "bbox": [
      143.20460510253906,
      440.71714782714844,
      490.12062072753906,
      726.9488830566406
    ],
    "caption": "Fig. 4: Quantifying and addressing racial homogenization. a, Sample images of Middle Eastern individuals generated using SDXL. b, For each race, the distribution of the average cosine similarity between a given image and all other images of that race (dashed lines represent the means). c, Comparing the distributions produced by SDXL (solid) to those produced by SDXL-Div (dashed). d, Sample images of Middle Eastern individuals generated using SDXL-Div. P values are from t-tests; *** p < .001.",
    "file_name": [
      "figures/fileoutpart3.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_07.png"
  },
  {
    "page": 9,
    "bbox": [
      143.20460510253906,
      440.71714782714844,
      490.12062072753906,
      726.9488830566406
    ],
    "caption": "Fig. 4: Quantifying and addressing racial homogenization. a, Sample images of Middle Eastern individuals generated using SDXL. b, For each race, the distribution of the average cosine similarity between a given image and all other images of that race (dashed lines represent the means). c, Comparing the distributions produced by SDXL (solid) to those produced by SDXL-Div (dashed). d, Sample images of Middle Eastern individuals generated using SDXL-Div. P values are from t-tests; *** p < .001.",
    "file_name": ""
  },
  {
    "page": 12,
    "bbox": [
      120.75846862792969,
      373.93214416503906,
      468.16754150390625,
      722.7801818847656
    ],
    "caption": "Fig. 5: Survey experiment results. Subfigures a to d summarize the participants’ responses in Studies 1 to 4, respectively. Boxes extend from the lower to upper quartile values, with a horizontal line at the median; whiskers extend to the most extreme values no further than 1.5 times the interquartile range from the box. P values are calculated using the t-test, unless one of the groups does not pass the Shapiro–Wilk test, in which case P values are calculated using the Mann-Whitney U test. ∗ p<0.05; ∗∗ p<0.01; ∗∗∗ p<0.001; ∗∗∗∗ p<0.0001; ns = not significant).",
    "file_name": [
      "figures/fileoutpart4.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_09.png"
  },
  {
    "page": 12,
    "bbox": [
      120.75846862792969,
      373.93214416503906,
      468.16754150390625,
      722.7801818847656
    ],
    "caption": "Fig. 5: Survey experiment results. Subfigures a to d summarize the participants’ responses in Studies 1 to 4, respectively. Boxes extend from the lower to upper quartile values, with a horizontal line at the median; whiskers extend to the most extreme values no further than 1.5 times the interquartile range from the box. P values are calculated using the t-test, unless one of the groups does not pass the Shapiro–Wilk test, in which case P values are calculated using the Mann-Whitney U test. ∗ p<0.05; ∗∗ p<0.01; ∗∗∗ p<0.001; ∗∗∗∗ p<0.0001; ns = not significant).",
    "file_name": ""
  },
  {
    "page": 25,
    "bbox": [
      50.82539367675781,
      557.2538299560547,
      559.0255432128906,
      690.9972229003906
    ],
    "caption": "Supplementary Figure 1: Race and Gender distribution obtained by the retrained ITI-GEN model. Comparing the representation of different races and genders in a sample of 1200 images generated by the retrained ITI-GEN model using the prompt: “a photo of a person”.",
    "file_name": [
      "figures/fileoutpart5.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_11.png"
  },
  {
    "page": 25,
    "bbox": [
      50.82539367675781,
      557.2538299560547,
      559.0255432128906,
      690.9972229003906
    ],
    "caption": "Supplementary Figure 1: Race and Gender distribution obtained by the retrained ITI-GEN model. Comparing the representation of different races and genders in a sample of 1200 images generated by the retrained ITI-GEN model using the prompt: “a photo of a person”.",
    "file_name": ""
  },
  {
    "page": 25,
    "bbox": [
      49.42265319824219,
      92.73550415039062,
      561.6056213378906,
      484.1757507324219
    ],
    "caption": "Supplementary Figure 1: Race and Gender distribution obtained by the retrained ITI-GEN model. Comparing the representation of different races and genders in a sample of 1200 images generated by the retrained ITI-GEN model using the prompt: “a photo of a person”.",
    "file_name": [
      "figures/fileoutpart6.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_13.png"
  },
  {
    "page": 25,
    "bbox": [
      49.42265319824219,
      92.73550415039062,
      561.6056213378906,
      484.1757507324219
    ],
    "caption": "Supplementary Figure 1: Race and Gender distribution obtained by the retrained ITI-GEN model. Comparing the representation of different races and genders in a sample of 1200 images generated by the retrained ITI-GEN model using the prompt: “a photo of a person”.",
    "file_name": ""
  },
  {
    "page": 26,
    "bbox": [
      3.47222900390625,
      189.42991638183594,
      561.322265625,
      683.2861938476562
    ],
    "caption": "Supplementary Figure 3: Results of SDXL-Inc. Given the remaining 24 professions that were not shown in Figure 4 of the main article, SDXL-Inc was used to generate 10,000 images per profession. a, Race distribution. b, Gender distribution. The standard deviation(s) corresponding to each subplot is denoted by σ followed by a subscript indicating the model.",
    "file_name": [
      "figures/fileoutpart7.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_15.png"
  },
  {
    "page": 26,
    "bbox": [
      3.47222900390625,
      189.42991638183594,
      561.322265625,
      683.2861938476562
    ],
    "caption": "Supplementary Figure 3: Results of SDXL-Inc. Given the remaining 24 professions that were not shown in Figure 4 of the main article, SDXL-Inc was used to generate 10,000 images per profession. a, Race distribution. b, Gender distribution. The standard deviation(s) corresponding to each subplot is denoted by σ followed by a subscript indicating the model.",
    "file_name": ""
  },
  {
    "page": 27,
    "bbox": [
      49.42304992675781,
      254.91758728027344,
      561.6193542480469,
      286.1846466064453
    ],
    "caption": "Accountant",
    "file_name": [
      "figures/fileoutpart10.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_17.png"
  },
  {
    "page": 27,
    "bbox": [
      60.35240173339844,
      254.91758728027344,
      81.68650817871094,
      266.3859405517578
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 27,
    "bbox": [
      85.7091064453125,
      255.62008666992188,
      119.32975769042969,
      267.08843994140625
    ],
    "caption": "Secretary",
    "file_name": ""
  },
  {
    "page": 27,
    "bbox": [
      218.89610290527344,
      255.62008666992188,
      231.3381805419922,
      267.08843994140625
    ],
    "caption": "Pharmacist",
    "file_name": ""
  },
  {
    "page": 27,
    "bbox": [
      295.0030975341797,
      255.62008666992188,
      402.5865173339844,
      267.08843994140625
    ],
    "caption": "Professor",
    "file_name": ""
  },
  {
    "page": 27,
    "bbox": [
      428.19029235839844,
      255.62008666992188,
      438.9418487548828,
      267.08843994140625
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 27,
    "bbox": [
      466.243896484375,
      255.62008666992188,
      515.0519866943359,
      267.08843994140625
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 27,
    "bbox": [
      49.42304992675781,
      254.91758728027344,
      561.6193542480469,
      286.1846466064453
    ],
    "caption": "Accountant",
    "file_name": ""
  },
  {
    "page": 33,
    "bbox": [
      50.86515808105469,
      159.41403198242188,
      546.4038848876953,
      527.6744842529297
    ],
    "caption": "Supplementary Figure 5: Evaluating our classifier. a, Confusion matrices of race and gender prediction based on the FairFace validation set, along with sample images representing different cells. b, Similar to (a), but based on images generated by Stable Diffusion XL (SDXL).",
    "file_name": [
      "figures/fileoutpart27.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_25.png"
  },
  {
    "page": 33,
    "bbox": [
      50.86515808105469,
      159.41403198242188,
      546.4038848876953,
      527.6744842529297
    ],
    "caption": "Supplementary Figure 5: Evaluating our classifier. a, Confusion matrices of race and gender prediction based on the FairFace validation set, along with sample images representing different cells. b, Similar to (a), but based on images generated by Stable Diffusion XL (SDXL).",
    "file_name": ""
  },
  {
    "page": 35,
    "bbox": [
      50.82749938964844,
      203.5180206298828,
      559.0242767333984,
      685.1258392333984
    ],
    "caption": "Supplementary Figure 6: SDXL vs. ITI-GEN vs. SDXL-Inc Comparing the distribution of race and gender across the three models, given five prompts. Each row corresponds to a different prompt. The standard deviation(s) corresponding to each subplot is denoted by σ followed by a subscript indicating the model. Gender results are omitted from the bottom row since the generated images depict families rather than individuals.",
    "file_name": [
      "figures/fileoutpart28.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_27.png"
  },
  {
    "page": 35,
    "bbox": [
      50.82749938964844,
      203.5180206298828,
      559.0242767333984,
      685.1258392333984
    ],
    "caption": "Supplementary Figure 6: SDXL vs. ITI-GEN vs. SDXL-Inc Comparing the distribution of race and gender across the three models, given five prompts. Each row corresponds to a different prompt. The standard deviation(s) corresponding to each subplot is denoted by σ followed by a subscript indicating the model. Gender results are omitted from the bottom row since the generated images depict families rather than individuals.",
    "file_name": ""
  },
  {
    "page": 38,
    "bbox": [
      58.223602294921875,
      418.4879455566406,
      551.1148376464844,
      664.2053070068359
    ],
    "caption": "b",
    "file_name": [
      "figures/fileoutpart31.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_29.png"
  },
  {
    "page": 38,
    "bbox": [
      58.71183776855469,
      147.353759765625,
      552.5785217285156,
      393.0711212158203
    ],
    "caption": "Supplementary Figure 7: Study 1 images (racial). a, SDXL. b, SDXL-Inclusive.",
    "file_name": [
      "figures/fileoutpart32.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_30.png"
  },
  {
    "page": 39,
    "bbox": [
      51.00018310546875,
      185.6538543701172,
      558.8403015136719,
      659.6379547119141
    ],
    "caption": "Supplementary Figure 8: Study 1 sample screenshots. (1) welcome screen, (2) loading screen, (3) per image questions, and (4)/(5) Final questions after seeing all six images.",
    "file_name": [
      "figures/fileoutpart33.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_31.png"
  },
  {
    "page": 40,
    "bbox": [
      58.223602294921875,
      418.4879455566406,
      551.1148376464844,
      664.2053070068359
    ],
    "caption": "b",
    "file_name": [
      "figures/fileoutpart34.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_32.png"
  },
  {
    "page": 40,
    "bbox": [
      58.71183776855469,
      147.353759765625,
      552.5785217285156,
      393.0711212158203
    ],
    "caption": "Supplementary Figure 9: Study 2 images (gender). a, SDXL. b, SDXL-Inclusive.",
    "file_name": [
      "figures/fileoutpart35.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_33.png"
  },
  {
    "page": 41,
    "bbox": [
      51.00018310546875,
      185.6538543701172,
      558.8403015136719,
      659.6379547119141
    ],
    "caption": "Supplementary Figure 10: Study 2 sample screenshots. (1) welcome screen, (2) loading screen, (3) per image questions, and (4)/(5) Final questions after seeing all six images.",
    "file_name": [
      "figures/fileoutpart36.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_34.png"
  },
  {
    "page": 42,
    "bbox": [
      56.75990295410156,
      634.0498657226562,
      549.1629028320312,
      715.2914733886719
    ],
    "caption": "b",
    "file_name": [
      "figures/fileoutpart37.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_35.png"
  },
  {
    "page": 42,
    "bbox": [
      58.71183776855469,
      527.3914337158203,
      551.1148376464844,
      608.6330413818359
    ],
    "caption": "Supplementary Figure 11: Study 3 images (Middle eastern men). a, SDXL. b, SDXL-Inclusive.",
    "file_name": [
      "figures/fileoutpart38.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_36.png"
  },
  {
    "page": 43,
    "bbox": [
      51.00018310546875,
      185.6538543701172,
      558.8403015136719,
      659.6379547119141
    ],
    "caption": "Supplementary Figure 12: Study 3 sample screenshots. (1) welcome screen, (2) loading screen, (3) per image questions, and (4)/(5) Final questions after seeing all six images.",
    "file_name": [
      "figures/fileoutpart39.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_37.png"
  },
  {
    "page": 44,
    "bbox": [
      56.75990295410156,
      418.4879455566406,
      549.1629028320312,
      499.72955322265625
    ],
    "caption": "b",
    "file_name": [
      "figures/fileoutpart40.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_38.png"
  },
  {
    "page": 44,
    "bbox": [
      58.71183776855469,
      311.8295135498047,
      551.1148376464844,
      393.0711212158203
    ],
    "caption": "Supplementary Figure 13: Study 4 images (Middle eastern women). a, SDXL. b, SDXL-Inclusive.",
    "file_name": [
      "figures/fileoutpart41.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_39.png"
  },
  {
    "page": 45,
    "bbox": [
      51.00018310546875,
      185.6538543701172,
      558.8403015136719,
      659.6379547119141
    ],
    "caption": "Supplementary Figure 14: Study 4 sample screenshots. (1) welcome screen, (2) loading screen, (3) per image questions, and (4)/(5) Final questions after seeing all six images.",
    "file_name": [
      "figures/fileoutpart42.png"
    ],
    "output_file": "assets/images/paper/Diagnostic-reasoning-prompts-reveal-the-potential-for-large-language-model-interpretability-in-medicine/fig_40.png"
  }
]