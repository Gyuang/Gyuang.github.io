[
  {
    "page": -1,
    "bbox": [
      118.625,
      588.0215911865234,
      491.87864685058594,
      630.7721557617188
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_01.png"
  },
  {
    "page": -1,
    "bbox": [
      118.625,
      588.0215911865234,
      491.87864685058594,
      630.7721557617188
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      83.25199890136719,
      605.8609924316406,
      528.7601318359375,
      720.0007019042969
    ],
    "caption": "Figure 1. Feature distribution visualization of LLavA-1.5 (left) and MAVL (right) on the RSNA dataset.",
    "file_name": [
      "figures/fileoutpart1.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_03.png"
  },
  {
    "page": 2,
    "bbox": [
      117.9010009765625,
      630.2729949951172,
      494.0961608886719,
      719.9994964599609
    ],
    "caption": "Figure 2. Comparison of Feature Distributions between MAVL and LLaVA-RadZ on the RSNA Dataset.",
    "file_name": [
      "figures/fileoutpart2.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_04.png"
  },
  {
    "page": 4,
    "bbox": [
      70.87600708007812,
      426.1929931640625,
      541.1163940429688,
      719.9998168945312
    ],
    "caption": "Figure 3. The LLaVA-RadZ framework consists of three components. (A) Construct a category semantic vector repository using the domain knowledge anchoring module (DKAM). (B) Encode medical images and text, appending ⟨ImgCls⟩ and ⟨TxtCls⟩ tokens before feeding them into the LLM. (C) Extract global and local features, optimizing with cross-entropy loss, while leveraging the semantic repository for category-level alignment.",
    "file_name": [
      "figures/fileoutpart5.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_05.png"
  },
  {
    "page": 4,
    "bbox": [
      84.61117553710938,
      296.8845520019531,
      271.1372528076172,
      311.5522766113281
    ],
    "caption": "˜Y prompt =Y prompt + < TxtClsi >(i=0,..,8). (2)",
    "file_name": [
      "figures/fileoutpart6.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_06.png"
  },
  {
    "page": 4,
    "bbox": [
      84.61117553710938,
      296.8845520019531,
      271.1372528076172,
      311.5522766113281
    ],
    "caption": "˜Y prompt =Y prompt + < TxtClsi >(i=0,..,8). (2)",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      85.36465454101562,
      273.9165496826172,
      297.2414245605469,
      287.6442413330078
    ],
    "caption": "When an image and its corresponding prompt X˜ prompt are input into the MLLM F to generate a response Rˆ img. Similarly, when a text sample and its corresponding feature extraction prompt Y˜ prompt are provided as input, the model produces a response Rˆ txt. This process can be formally expressed as:",
    "file_name": [
      "figures/fileoutpart7.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_08.png"
  },
  {
    "page": 4,
    "bbox": [
      85.36465454101562,
      273.9165496826172,
      297.2414245605469,
      287.6442413330078
    ],
    "caption": "When an image and its corresponding prompt X˜ prompt are input into the MLLM F to generate a response Rˆ img. Similarly, when a text sample and its corresponding feature extraction prompt Y˜ prompt are provided as input, the model produces a response Rˆ txt. This process can be formally expressed as:",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      64.68304443359375,
      164.9748992919922,
      297.23890686035156,
      184.91546630859375
    ],
    "caption": "Due to the autoregressive nature of the decoder architecture, when the LLM processes visual and textual information to generate responses, its internal representations are stored in the designated special tokens. Specifically, we extract the penultimate layer embedding ˜himg corresponding to the special token < ImgClsi >, which stores the global image features Himg global ∈ RB×I×K . Here, B denotes the",
    "file_name": [
      "figures/fileoutpart8.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_10.png"
  },
  {
    "page": 4,
    "bbox": [
      64.68304443359375,
      164.9748992919922,
      297.23890686035156,
      184.91546630859375
    ],
    "caption": "Due to the autoregressive nature of the decoder architecture, when the LLM processes visual and textual information to generate responses, its internal representations are stored in the designated special tokens. Specifically, we extract the penultimate layer embedding ˜himg corresponding to the special token < ImgClsi >, which stores the global image features Himg global ∈ RB×I×K . Here, B denotes the",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      370.49302673339844,
      218.19825744628906,
      502.74916076660156,
      250.60546875
    ],
    "caption": "Similarly, we extract the global text representation Yg ∈ RB×K and the local text representation Yl ∈ RB×K using the same methodology:",
    "file_name": [
      "figures/fileoutpart9.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_12.png"
  },
  {
    "page": 4,
    "bbox": [
      370.49302673339844,
      218.19825744628906,
      502.74916076660156,
      250.60546875
    ],
    "caption": "Similarly, we extract the global text representation Yg ∈ RB×K and the local text representation Yl ∈ RB×K using the same methodology:",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      371.72235107421875,
      133.80825805664062,
      501.5161590576172,
      165.59347534179688
    ],
    "caption": "To further enhance fine-grained alignment across different modalities, we introduce a cross-modal contrastive loss, LCA. Specifically, for the i-th image-text pair (Xi , Yi ) in a batch, we alternately align the global and local fea-",
    "file_name": [
      "figures/fileoutpart10.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_14.png"
  },
  {
    "page": 4,
    "bbox": [
      371.72235107421875,
      133.80825805664062,
      501.5161590576172,
      165.59347534179688
    ],
    "caption": "To further enhance fine-grained alignment across different modalities, we introduce a cross-modal contrastive loss, LCA. Specifically, for the i-th image-text pair (Xi , Yi ) in a batch, we alternately align the global and local fea-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      58.5,
      608.2545471191406,
      91.73953247070312,
      623.5895080566406
    ],
    "caption": "S Xg →Yl i = X g,i ·YT l,i τ , S Yl →Xg i = Yl,i · XT g,i τ .",
    "file_name": [
      "figures/fileoutpart11.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_16.png"
  },
  {
    "page": 5,
    "bbox": [
      65.29400634765625,
      611.5039215087891,
      91.73953247070312,
      623.5895080566406
    ],
    "caption": "S Xg →Yl i = X g,i ·YT l,i τ , S Yl →Xg i = Yl,i · XT g,i τ .",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      64.10099792480469,
      608.2545471191406,
      66.66732788085938,
      615.2283477783203
    ],
    "caption": "where τ is the temperature hyperparameter. Subsequently, we compute the contrastive loss between the global image and the local text, with the following formula:",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      58.5,
      608.2545471191406,
      91.73953247070312,
      623.5895080566406
    ],
    "caption": "S Xg →Yl i = X g,i ·YT l,i τ , S Yl →Xg i = Yl,i · XT g,i τ .",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      111.31764221191406,
      608.2545471191406,
      149.75030517578125,
      623.5895080566406
    ],
    "caption": "S Xg →Yl i = X g,i ·YT l,i τ , S Yl →Xg i = Yl,i · XT g,i τ .",
    "file_name": [
      "figures/fileoutpart12.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_20.png"
  },
  {
    "page": 5,
    "bbox": [
      118.11199951171875,
      611.5039215087891,
      144.59413146972656,
      623.5895080566406
    ],
    "caption": "S Xg →Yl i = X g,i ·YT l,i τ , S Yl →Xg i = Yl,i · XT g,i τ .",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      116.91900634765625,
      608.2545471191406,
      119.48533630371094,
      615.2283477783203
    ],
    "caption": "S Xg →Yl i = X g,i ·YT l,i τ , S Yl →Xg i = Yl,i · XT g,i τ .",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      111.31764221191406,
      608.2545471191406,
      149.75030517578125,
      623.5895080566406
    ],
    "caption": "S Xg →Yl i = X g,i ·YT l,i τ , S Yl →Xg i = Yl,i · XT g,i τ .",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      73.6929931640625,
      572.6033477783203,
      270.4297332763672,
      599.8684692382812
    ],
    "caption": "where τ is the temperature hyperparameter. Subsequently, we compute the contrastive loss between the global image and the local text, with the following formula:",
    "file_name": [
      "figures/fileoutpart13.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_24.png"
  },
  {
    "page": 5,
    "bbox": [
      73.6929931640625,
      572.6033477783203,
      270.4297332763672,
      599.8684692382812
    ],
    "caption": "where τ is the temperature hyperparameter. Subsequently, we compute the contrastive loss between the global image and the local text, with the following formula:",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      86.82806396484375,
      412.5967102050781,
      268.9109191894531,
      525.8354187011719
    ],
    "caption": "Similarly, for the alignment between local image features and global text features, we compute the contrastive loss between the local image and global text.",
    "file_name": [
      "figures/fileoutpart14.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_26.png"
  },
  {
    "page": 5,
    "bbox": [
      86.82806396484375,
      412.5967102050781,
      268.9109191894531,
      525.8354187011719
    ],
    "caption": "Similarly, for the alignment between local image features and global text features, we compute the contrastive loss between the local image and global text.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      83.75700378417969,
      280.18870544433594,
      271.9803009033203,
      369.9309539794922
    ],
    "caption": "LCA = 1 2  L Xg →Yl CA +L Xl→Yg CA  .",
    "file_name": [
      "figures/fileoutpart15.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_28.png"
  },
  {
    "page": 5,
    "bbox": [
      83.75700378417969,
      280.18870544433594,
      271.9803009033203,
      369.9309539794922
    ],
    "caption": "LCA = 1 2  L Xg →Yl CA +L Xl→Yg CA  .",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      108.40499877929688,
      234.91152954101562,
      247.33868408203125,
      273.347412109375
    ],
    "caption": "In aligning medical images with text reports, we observed that the critical entity of the medical disease categories was merely encoded as features by the model, without considering the underlying semantics. To address this limitation and further enhance fine-grained alignment capabilities, we introduce the Domain Knowledge Anchoring Module (DKAM). Initially, we leverage the inherent medical domain expertise of an LLM to generate descriptive explanations for each disease category. These generated disease descriptions serve as an intermediary bridge to guide the alignment between medical images and text reports. Specifically, we input the disease list Dlist from the training dataset along",
    "file_name": [
      "figures/fileoutpart16.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_30.png"
  },
  {
    "page": 5,
    "bbox": [
      108.40499877929688,
      234.91152954101562,
      247.33868408203125,
      273.347412109375
    ],
    "caption": "In aligning medical images with text reports, we observed that the critical entity of the medical disease categories was merely encoded as features by the model, without considering the underlying semantics. To address this limitation and further enhance fine-grained alignment capabilities, we introduce the Domain Knowledge Anchoring Module (DKAM). Initially, we leverage the inherent medical domain expertise of an LLM to generate descriptive explanations for each disease category. These generated disease descriptions serve as an intermediary bridge to guide the alignment between medical images and text reports. Specifically, we input the disease list Dlist from the training dataset along",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      382.14625549316406,
      667.9909057617188,
      491.0967102050781,
      687.5414428710938
    ],
    "caption": "By fully harnessing the LLM’s exceptional semantic understanding, we prompt the model to explore the underlying semantics of the disease categories and discern their distinctions, ultimately producing a refined disease description. The features extracted from the LLM’s response are then mapped via a multi-layer perceptron (MLP) to yield the disease description vector Dˆ , which is represented as:",
    "file_name": [
      "figures/fileoutpart17.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_32.png"
  },
  {
    "page": 5,
    "bbox": [
      382.14625549316406,
      667.9909057617188,
      491.0967102050781,
      687.5414428710938
    ],
    "caption": "By fully harnessing the LLM’s exceptional semantic understanding, we prompt the model to explore the underlying semantics of the disease categories and discern their distinctions, ultimately producing a refined disease description. The features extracted from the LLM’s response are then mapped via a multi-layer perceptron (MLP) to yield the disease description vector Dˆ , which is represented as:",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      398.9824981689453,
      544.9857025146484,
      474.2566833496094,
      583.4214172363281
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart18.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_34.png"
  },
  {
    "page": 5,
    "bbox": [
      398.9824981689453,
      544.9857025146484,
      474.2566833496094,
      583.4214172363281
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      330.21800231933594,
      335.189697265625,
      555.9860382080078,
      447.532470703125
    ],
    "caption": "LCG = 1 2 Bi=1  Ltxt CG,i +L img CG,i  .",
    "file_name": [
      "figures/fileoutpart19.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_36.png"
  },
  {
    "page": 5,
    "bbox": [
      330.21800231933594,
      335.189697265625,
      555.9860382080078,
      447.532470703125
    ],
    "caption": "LCG = 1 2 Bi=1  Ltxt CG,i +L img CG,i  .",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      372.96800231933594,
      255.63670349121094,
      500.2729187011719,
      295.6664123535156
    ],
    "caption": "Ltotal = λLCA + (1 − λ)LCG,",
    "file_name": [
      "figures/fileoutpart20.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_38.png"
  },
  {
    "page": 5,
    "bbox": [
      372.96800231933594,
      255.63670349121094,
      500.2729187011719,
      295.6664123535156
    ],
    "caption": "Ltotal = λLCA + (1 − λ)LCG,",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      376.1853332519531,
      193.51390075683594,
      497.0502471923828,
      212.0244140625
    ],
    "caption": "where λ is a balancing factor used to adjust the weights of the two losses, and it is set to 0.5 by default.",
    "file_name": [
      "figures/fileoutpart21.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_40.png"
  },
  {
    "page": 5,
    "bbox": [
      376.1853332519531,
      193.51390075683594,
      497.0502471923828,
      212.0244140625
    ],
    "caption": "where λ is a balancing factor used to adjust the weights of the two losses, and it is set to 0.5 by default.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      112.94999694824219,
      614.7209930419922,
      499.05430603027344,
      720.0003051757812
    ],
    "caption": "Figure 4. Effect of Special Token Numbers and Hidden Layer Depth on ChestXray-14 Classification.",
    "file_name": [
      "figures/fileoutpart26.png"
    ],
    "output_file": "assets/images/paper/LLaVA-RadZ-Can-Multimodal-Large-Language-Models-Effectively-Tackle-Zero-shot-Radiology-Recognition/fig_42.png"
  }
]