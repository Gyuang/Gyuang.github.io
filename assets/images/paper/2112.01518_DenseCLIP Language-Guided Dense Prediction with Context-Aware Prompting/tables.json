[
  {
    "page": 5,
    "bbox": [
      60.07499694824219,
      426.970458984375,
      537.4355316162109,
      669.7679595947266
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": [
      "tables/fileoutpart14.xlsx",
      "tables/fileoutpart15.png"
    ],
    "output_file": "assets/images/paper/2112.01518_DenseCLIP Language-Guided Dense Prediction with Context-Aware Prompting/table_01.png"
  },
  {
    "page": 5,
    "bbox": [
      60.07499694824219,
      658.9634399414062,
      98.17323303222656,
      669.7679595947266
    ],
    "caption": "ResNet-50",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      60.07499694824219,
      658.9634399414062,
      98.17323303222656,
      669.7679595947266
    ],
    "caption": "ResNet-50",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      658.9634399414062,
      152.9680633544922,
      669.7679595947266
    ],
    "caption": "FCN [(<>)30]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      658.9634399414062,
      152.9680633544922,
      669.7679595947266
    ],
    "caption": "FCN [(<>)30]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      658.9634399414062,
      279.8067626953125,
      669.7679595947266
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      658.9634399414062,
      279.8067626953125,
      669.7679595947266
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      319.8955383300781,
      658.9634399414062,
      361.23960876464844,
      669.7679595947266
    ],
    "caption": "36.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      319.8955383300781,
      658.9634399414062,
      361.23960876464844,
      669.7679595947266
    ],
    "caption": "36.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      378.9213562011719,
      658.9634399414062,
      423.25123596191406,
      669.7679595947266
    ],
    "caption": "38.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      378.9213562011719,
      658.9634399414062,
      423.25123596191406,
      669.7679595947266
    ],
    "caption": "38.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      440.9419403076172,
      658.9634399414062,
      475.06805419921875,
      669.7679595947266
    ],
    "caption": "793.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      440.9419403076172,
      658.9634399414062,
      475.06805419921875,
      669.7679595947266
    ],
    "caption": "793.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      492.7469940185547,
      658.9634399414062,
      537.4355316162109,
      669.7679595947266
    ],
    "caption": "49.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      492.7469940185547,
      658.9634399414062,
      537.4355316162109,
      669.7679595947266
    ],
    "caption": "49.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      60.07499694824219,
      608.2084350585938,
      100.6658935546875,
      619.0129547119141
    ],
    "caption": "Backbone",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      60.07499694824219,
      608.2084350585938,
      100.6658935546875,
      619.0129547119141
    ],
    "caption": "Backbone",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      645.6434478759766,
      159.69287109375,
      656.4479522705078
    ],
    "caption": "PSPNet [(<>)57]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      645.6434478759766,
      159.69287109375,
      656.4479522705078
    ],
    "caption": "PSPNet [(<>)57]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      645.6434478759766,
      283.787841796875,
      656.4479522705078
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      645.6434478759766,
      283.787841796875,
      656.4479522705078
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      645.6434478759766,
      361.23960876464844,
      656.4479522705078
    ],
    "caption": "41.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      645.6434478759766,
      361.23960876464844,
      656.4479522705078
    ],
    "caption": "41.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      645.6434478759766,
      423.25123596191406,
      656.4479522705078
    ],
    "caption": "41.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      645.6434478759766,
      423.25123596191406,
      656.4479522705078
    ],
    "caption": "41.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      645.6434478759766,
      475.06805419921875,
      656.4479522705078
    ],
    "caption": "716.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      645.6434478759766,
      475.06805419921875,
      656.4479522705078
    ],
    "caption": "716.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      645.6434478759766,
      537.4347991943359,
      656.4479522705078
    ],
    "caption": "49.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      645.6434478759766,
      537.4347991943359,
      656.4479522705078
    ],
    "caption": "49.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      637.325439453125,
      169.14346313476562,
      648.1299591064453
    ],
    "caption": "CCNet [(<>)20]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      637.325439453125,
      169.14346313476562,
      648.1299591064453
    ],
    "caption": "CCNet [(<>)20]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      637.325439453125,
      283.787841796875,
      648.1299591064453
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      637.325439453125,
      283.787841796875,
      648.1299591064453
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      637.325439453125,
      361.23960876464844,
      648.1299591064453
    ],
    "caption": "42.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      637.325439453125,
      361.23960876464844,
      648.1299591064453
    ],
    "caption": "42.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      637.325439453125,
      423.25123596191406,
      648.1299591064453
    ],
    "caption": "43.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      637.325439453125,
      423.25123596191406,
      648.1299591064453
    ],
    "caption": "43.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      637.325439453125,
      475.06805419921875,
      648.1299591064453
    ],
    "caption": "804.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      637.325439453125,
      475.06805419921875,
      648.1299591064453
    ],
    "caption": "804.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      637.325439453125,
      537.4347991943359,
      648.1299591064453
    ],
    "caption": "49.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      637.325439453125,
      537.4347991943359,
      648.1299591064453
    ],
    "caption": "49.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      629.0084381103516,
      170.1566619873047,
      639.8129577636719
    ],
    "caption": "DeeplabV3+ [(<>)7]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      629.0084381103516,
      170.1566619873047,
      639.8129577636719
    ],
    "caption": "DeeplabV3+ [(<>)7]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      629.0084381103516,
      283.787841796875,
      639.8129577636719
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      629.0084381103516,
      283.787841796875,
      639.8129577636719
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      629.0084381103516,
      361.23960876464844,
      639.8129577636719
    ],
    "caption": "42.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      629.0084381103516,
      361.23960876464844,
      639.8129577636719
    ],
    "caption": "42.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      629.0084381103516,
      423.25123596191406,
      639.8129577636719
    ],
    "caption": "43.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      629.0084381103516,
      423.25123596191406,
      639.8129577636719
    ],
    "caption": "43.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      629.0084381103516,
      475.06805419921875,
      639.8129577636719
    ],
    "caption": "711.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      629.0084381103516,
      475.06805419921875,
      639.8129577636719
    ],
    "caption": "711.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      629.0084381103516,
      537.4347991943359,
      639.8129577636719
    ],
    "caption": "43.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      629.0084381103516,
      537.4347991943359,
      639.8129577636719
    ],
    "caption": "43.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      620.6904449462891,
      167.16188049316406,
      631.4949493408203
    ],
    "caption": "UperNet [(<>)45]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      620.6904449462891,
      167.16188049316406,
      631.4949493408203
    ],
    "caption": "UperNet [(<>)45]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      620.6904449462891,
      283.787841796875,
      631.4949493408203
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      620.6904449462891,
      283.787841796875,
      631.4949493408203
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      620.6904449462891,
      361.23960876464844,
      631.4949493408203
    ],
    "caption": "42.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      620.6904449462891,
      361.23960876464844,
      631.4949493408203
    ],
    "caption": "42.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      620.6904449462891,
      423.25123596191406,
      631.4949493408203
    ],
    "caption": "42.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      620.6904449462891,
      423.25123596191406,
      631.4949493408203
    ],
    "caption": "42.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      620.6904449462891,
      475.06805419921875,
      631.4949493408203
    ],
    "caption": "953.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      620.6904449462891,
      475.06805419921875,
      631.4949493408203
    ],
    "caption": "953.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      620.6904449462891,
      537.4347991943359,
      631.4949493408203
    ],
    "caption": "66.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      620.6904449462891,
      537.4347991943359,
      631.4949493408203
    ],
    "caption": "66.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      612.3724365234375,
      183.66006469726562,
      623.1769561767578
    ],
    "caption": "DNL [(<>)52]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      612.3724365234375,
      183.66006469726562,
      623.1769561767578
    ],
    "caption": "DNL [(<>)52]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      612.3724365234375,
      283.787841796875,
      623.1769561767578
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      612.3724365234375,
      283.787841796875,
      623.1769561767578
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      612.3724365234375,
      361.23960876464844,
      623.1769561767578
    ],
    "caption": "41.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      612.3724365234375,
      361.23960876464844,
      623.1769561767578
    ],
    "caption": "41.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      612.3724365234375,
      423.25123596191406,
      623.1769561767578
    ],
    "caption": "43.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      612.3724365234375,
      423.25123596191406,
      623.1769561767578
    ],
    "caption": "43.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      612.3724365234375,
      475.06805419921875,
      623.1769561767578
    ],
    "caption": "939.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      612.3724365234375,
      475.06805419921875,
      623.1769561767578
    ],
    "caption": "939.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      612.3724365234375,
      537.4347991943359,
      623.1769561767578
    ],
    "caption": "50.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      612.3724365234375,
      537.4347991943359,
      623.1769561767578
    ],
    "caption": "50.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      604.0554351806641,
      173.12454223632812,
      614.8599548339844
    ],
    "caption": "Semantic FPN [(<>)21]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      604.0554351806641,
      173.12454223632812,
      614.8599548339844
    ],
    "caption": "Semantic FPN [(<>)21]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      604.0554351806641,
      283.787841796875,
      614.8599548339844
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      604.0554351806641,
      283.787841796875,
      614.8599548339844
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      604.0554351806641,
      361.23960876464844,
      614.8599548339844
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      604.0554351806641,
      361.23960876464844,
      614.8599548339844
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      604.0554351806641,
      423.25123596191406,
      614.8599548339844
    ],
    "caption": "40.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      604.0554351806641,
      423.25123596191406,
      614.8599548339844
    ],
    "caption": "40.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      604.0554351806641,
      475.06805419921875,
      614.8599548339844
    ],
    "caption": "227.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      604.0554351806641,
      475.06805419921875,
      614.8599548339844
    ],
    "caption": "227.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      604.0554351806641,
      537.4347991943359,
      614.8599548339844
    ],
    "caption": "31.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      604.0554351806641,
      537.4347991943359,
      614.8599548339844
    ],
    "caption": "31.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      595.7374420166016,
      160.67916870117188,
      606.5419464111328
    ],
    "caption": "CLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      595.7374420166016,
      160.67916870117188,
      606.5419464111328
    ],
    "caption": "CLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      595.7374420166016,
      283.787841796875,
      606.5419464111328
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      595.7374420166016,
      283.787841796875,
      606.5419464111328
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      595.7374420166016,
      361.23960876464844,
      606.5419464111328
    ],
    "caption": "39.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      595.7374420166016,
      361.23960876464844,
      606.5419464111328
    ],
    "caption": "39.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      595.7374420166016,
      423.25123596191406,
      606.5419464111328
    ],
    "caption": "41.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      595.7374420166016,
      423.25123596191406,
      606.5419464111328
    ],
    "caption": "41.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      595.7374420166016,
      475.06805419921875,
      606.5419464111328
    ],
    "caption": "248.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      595.7374420166016,
      475.06805419921875,
      606.5419464111328
    ],
    "caption": "248.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      595.7374420166016,
      537.4347991943359,
      606.5419464111328
    ],
    "caption": "31.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      595.7374420166016,
      537.4347991943359,
      606.5419464111328
    ],
    "caption": "31.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      587.4194488525391,
      194.3121337890625,
      598.2239532470703
    ],
    "caption": "DenseCLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      587.4194488525391,
      194.3121337890625,
      598.2239532470703
    ],
    "caption": "DenseCLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      587.4194488525391,
      283.7881164550781,
      598.2239532470703
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      587.4194488525391,
      283.7881164550781,
      598.2239532470703
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      587.4194488525391,
      361.2407989501953,
      598.2239532470703
    ],
    "caption": "43.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      587.4194488525391,
      361.2407989501953,
      598.2239532470703
    ],
    "caption": "43.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      587.4194488525391,
      423.25379943847656,
      598.2239532470703
    ],
    "caption": "44.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      587.4194488525391,
      423.25379943847656,
      598.2239532470703
    ],
    "caption": "44.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      587.4194488525391,
      475.06300354003906,
      598.2239532470703
    ],
    "caption": "269.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      587.4194488525391,
      475.06300354003906,
      598.2239532470703
    ],
    "caption": "269.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      587.4194488525391,
      537.4347991943359,
      598.2239532470703
    ],
    "caption": "50.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      587.4194488525391,
      537.4347991943359,
      598.2239532470703
    ],
    "caption": "50.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      579.1014404296875,
      206.1029510498047,
      589.9059600830078
    ],
    "caption": "FCN [(<>)30]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      579.1014404296875,
      206.1029510498047,
      589.9059600830078
    ],
    "caption": "FCN [(<>)30]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      579.1014404296875,
      267.86378479003906,
      589.9059600830078
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      579.1014404296875,
      267.86378479003906,
      589.9059600830078
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      579.1014404296875,
      361.2407989501953,
      589.9059600830078
    ],
    "caption": "39.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      579.1014404296875,
      361.2407989501953,
      589.9059600830078
    ],
    "caption": "39.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      579.1014404296875,
      423.25379943847656,
      589.9059600830078
    ],
    "caption": "41.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      579.1014404296875,
      423.25379943847656,
      589.9059600830078
    ],
    "caption": "41.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      579.1014404296875,
      475.06300354003906,
      589.9059600830078
    ],
    "caption": "1104.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      579.1014404296875,
      475.06300354003906,
      589.9059600830078
    ],
    "caption": "1104.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      579.1014404296875,
      537.4347991943359,
      589.9059600830078
    ],
    "caption": "68.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      579.1014404296875,
      537.4347991943359,
      589.9059600830078
    ],
    "caption": "68.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      570.721435546875,
      228.50999450683594,
      581.5259552001953
    ],
    "caption": "FCN [(<>)30]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      570.721435546875,
      228.50999450683594,
      581.5259552001953
    ],
    "caption": "FCN [(<>)30]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      570.721435546875,
      267.86378479003906,
      581.5259552001953
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      570.721435546875,
      267.86378479003906,
      581.5259552001953
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      570.1834564208984,
      361.2407989501953,
      581.8487396240234
    ],
    "caption": "39.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      570.1834564208984,
      361.2407989501953,
      581.8487396240234
    ],
    "caption": "39.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      570.1834564208984,
      423.25379943847656,
      581.8487396240234
    ],
    "caption": "41.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      570.1834564208984,
      423.25379943847656,
      581.8487396240234
    ],
    "caption": "41.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      570.721435546875,
      475.06300354003906,
      581.5259552001953
    ],
    "caption": "1104.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      570.721435546875,
      475.06300354003906,
      581.5259552001953
    ],
    "caption": "1104.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      570.721435546875,
      537.4347991943359,
      581.5259552001953
    ],
    "caption": "68.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      570.721435546875,
      537.4347991943359,
      581.5259552001953
    ],
    "caption": "68.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      60.07499694824219,
      516.2954406738281,
      105.14909362792969,
      527.0999603271484
    ],
    "caption": "ViT-B",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      60.07499694824219,
      516.2954406738281,
      105.14909362792969,
      527.0999603271484
    ],
    "caption": "ViT-B",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      557.4014434814453,
      159.69287109375,
      568.2059478759766
    ],
    "caption": "PSPNet [(<>)57]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      557.4014434814453,
      159.69287109375,
      568.2059478759766
    ],
    "caption": "PSPNet [(<>)57]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      557.4014434814453,
      283.787841796875,
      568.2059478759766
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      557.4014434814453,
      283.787841796875,
      568.2059478759766
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      557.4014434814453,
      361.23960876464844,
      568.2059478759766
    ],
    "caption": "43.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      557.4014434814453,
      361.23960876464844,
      568.2059478759766
    ],
    "caption": "43.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      557.4014434814453,
      423.25123596191406,
      568.2059478759766
    ],
    "caption": "44.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      557.4014434814453,
      423.25123596191406,
      568.2059478759766
    ],
    "caption": "44.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      557.4014434814453,
      475.06805419921875,
      568.2059478759766
    ],
    "caption": "1027.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      557.4014434814453,
      475.06805419921875,
      568.2059478759766
    ],
    "caption": "1027.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      557.4014434814453,
      537.4347991943359,
      568.2059478759766
    ],
    "caption": "68.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      557.4014434814453,
      537.4347991943359,
      568.2059478759766
    ],
    "caption": "68.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      549.0834350585938,
      169.14346313476562,
      559.8879547119141
    ],
    "caption": "CCNet [(<>)20]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      549.0834350585938,
      169.14346313476562,
      559.8879547119141
    ],
    "caption": "CCNet [(<>)20]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      549.0834350585938,
      283.787841796875,
      559.8879547119141
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      549.0834350585938,
      283.787841796875,
      559.8879547119141
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      549.0834350585938,
      361.23960876464844,
      559.8879547119141
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      549.0834350585938,
      361.23960876464844,
      559.8879547119141
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      549.0834350585938,
      423.25123596191406,
      559.8879547119141
    ],
    "caption": "45.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      549.0834350585938,
      423.25123596191406,
      559.8879547119141
    ],
    "caption": "45.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      549.0834350585938,
      475.06805419921875,
      559.8879547119141
    ],
    "caption": "1115.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      549.0834350585938,
      475.06805419921875,
      559.8879547119141
    ],
    "caption": "1115.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      549.0834350585938,
      537.4347991943359,
      559.8879547119141
    ],
    "caption": "68.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      549.0834350585938,
      537.4347991943359,
      559.8879547119141
    ],
    "caption": "68.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      540.7664489746094,
      170.1566619873047,
      551.5709533691406
    ],
    "caption": "DeeplabV3+ [(<>)7]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      540.7664489746094,
      170.1566619873047,
      551.5709533691406
    ],
    "caption": "DeeplabV3+ [(<>)7]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      540.7664489746094,
      283.787841796875,
      551.5709533691406
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      540.7664489746094,
      283.787841796875,
      551.5709533691406
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      540.7664489746094,
      361.23960876464844,
      551.5709533691406
    ],
    "caption": "44.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      540.7664489746094,
      361.23960876464844,
      551.5709533691406
    ],
    "caption": "44.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      540.7664489746094,
      423.25123596191406,
      551.5709533691406
    ],
    "caption": "46.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      540.7664489746094,
      423.25123596191406,
      551.5709533691406
    ],
    "caption": "46.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      540.7664489746094,
      475.06805419921875,
      551.5709533691406
    ],
    "caption": "1022.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      540.7664489746094,
      475.06805419921875,
      551.5709533691406
    ],
    "caption": "1022.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      540.7664489746094,
      537.4347991943359,
      551.5709533691406
    ],
    "caption": "62.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      540.7664489746094,
      537.4347991943359,
      551.5709533691406
    ],
    "caption": "62.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      532.4484405517578,
      167.16188049316406,
      543.2529602050781
    ],
    "caption": "UperNet [(<>)45]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      532.4484405517578,
      167.16188049316406,
      543.2529602050781
    ],
    "caption": "UperNet [(<>)45]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      532.4484405517578,
      283.787841796875,
      543.2529602050781
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      532.4484405517578,
      283.787841796875,
      543.2529602050781
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      532.4484405517578,
      361.23960876464844,
      543.2529602050781
    ],
    "caption": "43.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      532.4484405517578,
      361.23960876464844,
      543.2529602050781
    ],
    "caption": "43.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      532.4484405517578,
      423.25123596191406,
      543.2529602050781
    ],
    "caption": "44.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      532.4484405517578,
      423.25123596191406,
      543.2529602050781
    ],
    "caption": "44.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      532.4484405517578,
      475.06805419921875,
      543.2529602050781
    ],
    "caption": "1031.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      532.4484405517578,
      475.06805419921875,
      543.2529602050781
    ],
    "caption": "1031.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      532.4484405517578,
      537.4347991943359,
      543.2529602050781
    ],
    "caption": "85.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      532.4484405517578,
      537.4347991943359,
      543.2529602050781
    ],
    "caption": "85.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      524.1304473876953,
      183.66006469726562,
      534.9349517822266
    ],
    "caption": "OCRNet [(<>)54]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      524.1304473876953,
      183.66006469726562,
      534.9349517822266
    ],
    "caption": "OCRNet [(<>)54]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      524.1304473876953,
      283.787841796875,
      534.9349517822266
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      524.1304473876953,
      283.787841796875,
      534.9349517822266
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      524.1304473876953,
      361.23960876464844,
      534.9349517822266
    ],
    "caption": "45.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      524.1304473876953,
      361.23960876464844,
      534.9349517822266
    ],
    "caption": "45.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      524.1304473876953,
      423.25123596191406,
      534.9349517822266
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      524.1304473876953,
      423.25123596191406,
      534.9349517822266
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      524.1304473876953,
      475.06805419921875,
      534.9349517822266
    ],
    "caption": "923.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      524.1304473876953,
      475.06805419921875,
      534.9349517822266
    ],
    "caption": "923.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      524.1304473876953,
      537.4347991943359,
      534.9349517822266
    ],
    "caption": "55.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      524.1304473876953,
      537.4347991943359,
      534.9349517822266
    ],
    "caption": "55.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      515.8134460449219,
      173.12454223632812,
      526.6179504394531
    ],
    "caption": "DNL [(<>)52]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      515.8134460449219,
      173.12454223632812,
      526.6179504394531
    ],
    "caption": "DNL [(<>)52]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      515.8134460449219,
      283.787841796875,
      526.6179504394531
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      515.8134460449219,
      283.787841796875,
      526.6179504394531
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      515.8134460449219,
      361.23960876464844,
      526.6179504394531
    ],
    "caption": "44.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      515.8134460449219,
      361.23960876464844,
      526.6179504394531
    ],
    "caption": "44.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      515.8134460449219,
      423.25123596191406,
      526.6179504394531
    ],
    "caption": "45.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      515.8134460449219,
      423.25123596191406,
      526.6179504394531
    ],
    "caption": "45.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      515.8134460449219,
      475.06805419921875,
      526.6179504394531
    ],
    "caption": "1250.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      515.8134460449219,
      475.06805419921875,
      526.6179504394531
    ],
    "caption": "1250.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      515.8134460449219,
      537.4347991943359,
      526.6179504394531
    ],
    "caption": "69.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      515.8134460449219,
      537.4347991943359,
      526.6179504394531
    ],
    "caption": "69.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      507.4954376220703,
      173.6356201171875,
      518.2999572753906
    ],
    "caption": "Semantic FPN [(<>)21]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      507.4954376220703,
      173.6356201171875,
      518.2999572753906
    ],
    "caption": "Semantic FPN [(<>)21]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      507.4954376220703,
      283.787841796875,
      518.2999572753906
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      507.4954376220703,
      283.787841796875,
      518.2999572753906
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      507.4954376220703,
      361.23960876464844,
      518.2999572753906
    ],
    "caption": "40.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      507.4954376220703,
      361.23960876464844,
      518.2999572753906
    ],
    "caption": "40.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      418.02381896972656,
      507.4954376220703,
      421.0095672607422,
      518.2999572753906
    ],
    "caption": "42.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      418.02381896972656,
      507.4954376220703,
      421.0095672607422,
      518.2999572753906
    ],
    "caption": "42.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      507.4954376220703,
      475.06805419921875,
      518.2999572753906
    ],
    "caption": "304.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6520538330078,
      507.4954376220703,
      475.06805419921875,
      518.2999572753906
    ],
    "caption": "304.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      507.4954376220703,
      537.4347991943359,
      518.2999572753906
    ],
    "caption": "50.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      507.4954376220703,
      537.4347991943359,
      518.2999572753906
    ],
    "caption": "50.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      499.1774444580078,
      160.67916870117188,
      509.98194885253906
    ],
    "caption": "CLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      499.1774444580078,
      160.67916870117188,
      509.98194885253906
    ],
    "caption": "CLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      499.1774444580078,
      283.787841796875,
      509.98194885253906
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      499.1774444580078,
      283.787841796875,
      509.98194885253906
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      499.1774444580078,
      361.23960876464844,
      509.98194885253906
    ],
    "caption": "42.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      499.1774444580078,
      361.23960876464844,
      509.98194885253906
    ],
    "caption": "42.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      499.1774444580078,
      423.25123596191406,
      509.98194885253906
    ],
    "caption": "44.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      499.1774444580078,
      423.25123596191406,
      509.98194885253906
    ],
    "caption": "44.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      499.1774444580078,
      475.06805419921875,
      509.98194885253906
    ],
    "caption": "326.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.1688537597656,
      499.1774444580078,
      475.06805419921875,
      509.98194885253906
    ],
    "caption": "326.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      499.1774444580078,
      537.4347991943359,
      509.98194885253906
    ],
    "caption": "50.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      499.1774444580078,
      537.4347991943359,
      509.98194885253906
    ],
    "caption": "50.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      490.85943603515625,
      194.3121337890625,
      501.66395568847656
    ],
    "caption": "DenseCLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      490.85943603515625,
      194.3121337890625,
      501.66395568847656
    ],
    "caption": "DenseCLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      490.85943603515625,
      283.7881164550781,
      501.66395568847656
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      490.85943603515625,
      283.7881164550781,
      501.66395568847656
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      490.85943603515625,
      361.2407989501953,
      501.66395568847656
    ],
    "caption": "45.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      490.85943603515625,
      361.2407989501953,
      501.66395568847656
    ],
    "caption": "45.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      490.85943603515625,
      423.25379943847656,
      501.66395568847656
    ],
    "caption": "46.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      490.85943603515625,
      423.25379943847656,
      501.66395568847656
    ],
    "caption": "46.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      490.85943603515625,
      475.06300354003906,
      501.66395568847656
    ],
    "caption": "346.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      490.85943603515625,
      475.06300354003906,
      501.66395568847656
    ],
    "caption": "346.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      490.85943603515625,
      537.4347991943359,
      501.66395568847656
    ],
    "caption": "67.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      490.85943603515625,
      537.4347991943359,
      501.66395568847656
    ],
    "caption": "67.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      482.5424346923828,
      206.1029510498047,
      493.3469543457031
    ],
    "caption": "SETR-MLA-DeiT [(<>)58]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      482.5424346923828,
      206.1029510498047,
      493.3469543457031
    ],
    "caption": "SETR-MLA-DeiT [(<>)58]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      482.5424346923828,
      267.86378479003906,
      493.3469543457031
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      482.5424346923828,
      267.86378479003906,
      493.3469543457031
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      482.5424346923828,
      361.2407989501953,
      493.3469543457031
    ],
    "caption": "46.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      482.5424346923828,
      361.2407989501953,
      493.3469543457031
    ],
    "caption": "46.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      482.5424346923828,
      423.25379943847656,
      493.3469543457031
    ],
    "caption": "47.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      482.5424346923828,
      423.25379943847656,
      493.3469543457031
    ],
    "caption": "47.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      482.5424346923828,
      475.06300354003906,
      493.3469543457031
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      482.5424346923828,
      475.06300354003906,
      493.3469543457031
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      482.5424346923828,
      537.4347991943359,
      493.3469543457031
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      482.5424346923828,
      537.4347991943359,
      493.3469543457031
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      474.16143798828125,
      228.50999450683594,
      484.96595764160156
    ],
    "caption": "SETR-MLA-DeiT [(<>)58]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      474.16143798828125,
      228.50999450683594,
      484.96595764160156
    ],
    "caption": "SETR-MLA-DeiT [(<>)58]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      474.16143798828125,
      267.86378479003906,
      484.96595764160156
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      474.16143798828125,
      267.86378479003906,
      484.96595764160156
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      473.6234588623047,
      361.2407989501953,
      485.2887420654297
    ],
    "caption": "46.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      473.6234588623047,
      361.2407989501953,
      485.2887420654297
    ],
    "caption": "46.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      473.6234588623047,
      423.25379943847656,
      485.2887420654297
    ],
    "caption": "47.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      473.6234588623047,
      423.25379943847656,
      485.2887420654297
    ],
    "caption": "47.7",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      474.16143798828125,
      475.06300354003906,
      484.96595764160156
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      452.6470031738281,
      474.16143798828125,
      475.06300354003906,
      484.96595764160156
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      474.16143798828125,
      537.4347991943359,
      484.96595764160156
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      519.5019989013672,
      474.16143798828125,
      537.4347991943359,
      484.96595764160156
    ],
    "caption": "-",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      60.07499694824219,
      445.4334411621094,
      84.36497497558594,
      456.2379608154297
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      60.07499694824219,
      445.4334411621094,
      84.36497497558594,
      456.2379608154297
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      460.84144592285156,
      208.49697875976562,
      471.6459503173828
    ],
    "caption": "Semantic FPN [(<>)21]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      460.84144592285156,
      208.49697875976562,
      471.6459503173828
    ],
    "caption": "Semantic FPN [(<>)21]",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      460.84144592285156,
      283.787841796875,
      471.6459503173828
    ],
    "caption": "ImageNet-21K",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.1917266845703,
      460.84144592285156,
      283.787841796875,
      471.6459503173828
    ],
    "caption": "ImageNet-21K",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      460.84144592285156,
      361.23960876464844,
      471.6459503173828
    ],
    "caption": "49.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.3068084716797,
      460.84144592285156,
      361.23960876464844,
      471.6459503173828
    ],
    "caption": "49.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      460.84144592285156,
      423.25123596191406,
      471.6459503173828
    ],
    "caption": "50.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3184356689453,
      460.84144592285156,
      423.25123596191406,
      471.6459503173828
    ],
    "caption": "50.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      469.8406524658203,
      460.84144592285156,
      472.8263854980469,
      471.6459503173828
    ],
    "caption": "1037.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      469.8406524658203,
      460.84144592285156,
      472.8263854980469,
      471.6459503173828
    ],
    "caption": "1037.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      532.2070007324219,
      460.84144592285156,
      535.1927490234375,
      471.6459503173828
    ],
    "caption": "100.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      532.2070007324219,
      460.84144592285156,
      535.1927490234375,
      471.6459503173828
    ],
    "caption": "100.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      452.5244445800781,
      194.3121337890625,
      463.3289489746094
    ],
    "caption": "CLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      452.5244445800781,
      194.3121337890625,
      463.3289489746094
    ],
    "caption": "CLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      452.5244445800781,
      283.7881164550781,
      463.3289489746094
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      452.5244445800781,
      283.7881164550781,
      463.3289489746094
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      452.5244445800781,
      361.2407989501953,
      463.3289489746094
    ],
    "caption": "49.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      452.5244445800781,
      361.2407989501953,
      463.3289489746094
    ],
    "caption": "49.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      452.5244445800781,
      423.25379943847656,
      463.3289489746094
    ],
    "caption": "50.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      452.5244445800781,
      423.25379943847656,
      463.3289489746094
    ],
    "caption": "50.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.16400146484375,
      452.5244445800781,
      475.0632019042969,
      463.3289489746094
    ],
    "caption": "1037.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.16400146484375,
      452.5244445800781,
      475.0632019042969,
      463.3289489746094
    ],
    "caption": "1037.4",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      515.0189971923828,
      452.5244445800781,
      537.4349975585938,
      463.3289489746094
    ],
    "caption": "100.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      515.0189971923828,
      452.5244445800781,
      537.4349975585938,
      463.3289489746094
    ],
    "caption": "100.8",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      444.20643615722656,
      194.3121337890625,
      455.0109558105469
    ],
    "caption": "DenseCLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      444.20643615722656,
      194.3121337890625,
      455.0109558105469
    ],
    "caption": "DenseCLIP + Semantic FPN",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      444.20643615722656,
      302.2140655517578,
      455.0109558105469
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      444.20643615722656,
      302.2140655517578,
      455.0109558105469
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      444.20643615722656,
      361.2407989501953,
      455.0109558105469
    ],
    "caption": "50.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      444.20643615722656,
      361.2407989501953,
      455.0109558105469
    ],
    "caption": "50.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      444.20643615722656,
      423.25379943847656,
      455.0109558105469
    ],
    "caption": "51.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      444.20643615722656,
      423.25379943847656,
      455.0109558105469
    ],
    "caption": "51.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.16400146484375,
      444.20643615722656,
      475.0632019042969,
      455.0109558105469
    ],
    "caption": "1043.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.16400146484375,
      444.20643615722656,
      475.0632019042969,
      455.0109558105469
    ],
    "caption": "1043.1",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      515.0189971923828,
      444.20643615722656,
      537.4349975585938,
      455.0109558105469
    ],
    "caption": "105.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      515.0189971923828,
      444.20643615722656,
      537.4349975585938,
      455.0109558105469
    ],
    "caption": "105.3",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      435.88844299316406,
      206.1029510498047,
      446.6929473876953
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      435.88844299316406,
      206.1029510498047,
      446.6929473876953
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      435.88844299316406,
      267.86378479003906,
      446.6929473876953
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      435.88844299316406,
      267.86378479003906,
      446.6929473876953
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      435.88844299316406,
      361.2407989501953,
      446.6929473876953
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      435.88844299316406,
      361.2407989501953,
      446.6929473876953
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      435.88844299316406,
      423.25379943847656,
      446.6929473876953
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      435.88844299316406,
      423.25379943847656,
      446.6929473876953
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.16400146484375,
      435.88844299316406,
      475.0632019042969,
      446.6929473876953
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.16400146484375,
      435.88844299316406,
      475.0632019042969,
      446.6929473876953
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      515.0189971923828,
      435.88844299316406,
      537.4349975585938,
      446.6929473876953
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      515.0189971923828,
      435.88844299316406,
      537.4349975585938,
      446.6929473876953
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      427.50843811035156,
      228.50999450683594,
      438.3129577636719
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      122.83200073242188,
      427.50843811035156,
      228.50999450683594,
      438.3129577636719
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      427.50843811035156,
      267.86378479003906,
      438.3129577636719
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      246.19200134277344,
      427.50843811035156,
      267.86378479003906,
      438.3129577636719
    ],
    "caption": "Table 2. Ablation study. We demonstrate that performing post-model vision-to-language prompting can yield the better performance with fewer extra FLOPs and parameters.",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      426.970458984375,
      361.2407989501953,
      438.6357421875
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      343.30799865722656,
      426.970458984375,
      361.2407989501953,
      438.6357421875
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      426.970458984375,
      423.25379943847656,
      438.6357421875
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      405.3209991455078,
      426.970458984375,
      423.25379943847656,
      438.6357421875
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.16400146484375,
      427.50843811035156,
      475.0632019042969,
      438.3129577636719
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      448.16400146484375,
      427.50843811035156,
      475.0632019042969,
      438.3129577636719
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      515.0189971923828,
      427.50843811035156,
      537.4349975585938,
      438.3129577636719
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      515.0189971923828,
      427.50843811035156,
      537.4349975585938,
      438.3129577636719
    ],
    "caption": "Main results. We report the semantic segmentation results of our DenseCLIP with three different backbones on ADE20K in Table (<>)1. We include the FLOPs, the number of parameters, and the mIoU in both single-scale (SS) and multi-scale (MS) testings. The experiments results show that for the same backbone, our DenseCLIP with a simple Semantic FPN can outperform the state-of-the-art methods that use more sophisticated decoders by large margins. Unlike previous works that use dilated backbones (ResNetD8 [(<>)20, (<>)53, (<>)54, (<>)57]), the ResNet encoder in DenseCLIP is more close to standard ResNet thus our DenseCLIP has much fewer FLOPs. Besides, our DenseCLIP is +4.9%, +4.7%, and +2.3% mIoU (SS) higher than the original ImageNet pre-trained baselines on ResNet-50, ResNet-101 and ViT-B backbones with acceptable extra computation cost. Dense-CLIP is also +3.9%, +2.4%, and +1.2% mIoU higher than the vanilla fine-tuning strategy (CLIP + Semantic FPN).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.186004638671875,
      281.62351989746094,
      284.2902374267578,
      373.52342224121094
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": [
      "tables/fileoutpart16.xlsx",
      "tables/fileoutpart17.png"
    ],
    "output_file": "assets/images/paper/2112.01518_DenseCLIP Language-Guided Dense Prediction with Context-Aware Prompting/table_334.png"
  },
  {
    "page": 5,
    "bbox": [
      54.177001953125,
      357.2404479980469,
      87.79203796386719,
      368.0449523925781
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      54.177001953125,
      357.2404479980469,
      87.79203796386719,
      368.0449523925781
    ],
    "caption": "ImageNet",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      93.76365661621094,
      351.76197814941406,
      131.35977172851562,
      373.52342224121094
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      93.76365661621094,
      362.7189178466797,
      131.35977172851562,
      373.52342224121094
    ],
    "caption": "Prompt",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      98.23788452148438,
      351.76197814941406,
      126.88554382324219,
      362.5664825439453
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      133.09925842285156,
      356.64866638183594,
      185.15817260742188,
      373.52342224121094
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      133.09925842285156,
      356.64866638183594,
      185.15817260742188,
      373.52342224121094
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      189.13925170898438,
      351.76197814941406,
      212.29946899414062,
      373.52342224121094
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      189.13925170898438,
      351.76197814941406,
      212.29946899414062,
      373.52342224121094
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      224.13511657714844,
      351.76197814941406,
      251.78749084472656,
      373.52342224121094
    ],
    "caption": "227",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      224.13511657714844,
      362.7189178466797,
      251.78749084472656,
      373.52342224121094
    ],
    "caption": "(G)",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      230.61781311035156,
      351.76197814941406,
      245.30477905273438,
      362.5664825439453
    ],
    "caption": "227",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      255.76856994628906,
      351.76197814941406,
      284.2727508544922,
      373.52342224121094
    ],
    "caption": "31.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      255.76856994628906,
      362.7189178466797,
      284.2727508544922,
      373.52342224121094
    ],
    "caption": "(M)",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      261.92848205566406,
      351.76197814941406,
      278.1128387451172,
      362.5664825439453
    ],
    "caption": "31.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      133.1060028076172,
      346.9574432373047,
      146.79769897460938,
      357.76194763183594
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      133.1060028076172,
      346.9574432373047,
      146.79769897460938,
      357.76194763183594
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      158.25674438476562,
      346.9574432373047,
      175.44534301757812,
      357.76194763183594
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      158.25674438476562,
      346.9574432373047,
      175.44534301757812,
      357.76194763183594
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.186004638671875,
      330.99644470214844,
      89.78211975097656,
      341.8009490966797
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.186004638671875,
      330.99644470214844,
      89.78211975097656,
      341.8009490966797
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90615844726562,
      330.99644470214844,
      204.83895874023438,
      341.8009490966797
    ],
    "caption": "39.6(+1.0)",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90615844726562,
      330.99644470214844,
      204.83895874023438,
      341.8009490966797
    ],
    "caption": "39.6(+1.0)",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10479736328125,
      330.99644470214844,
      251.79598999023438,
      341.8009490966797
    ],
    "caption": "249",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10479736328125,
      330.99644470214844,
      251.79598999023438,
      341.8009490966797
    ],
    "caption": "249",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      266.35743713378906,
      330.99644470214844,
      284.2902374267578,
      341.8009490966797
    ],
    "caption": "31.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      266.35743713378906,
      330.99644470214844,
      284.2902374267578,
      341.8009490966797
    ],
    "caption": "31.0",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.186004638671875,
      315.0354461669922,
      73.8577880859375,
      325.83995056152344
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.186004638671875,
      315.0354461669922,
      73.8577880859375,
      325.83995056152344
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90615844726562,
      314.87928771972656,
      218.9158477783203,
      325.83995056152344
    ],
    "caption": "42.9(+4.3)",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90615844726562,
      314.87928771972656,
      218.9158477783203,
      325.83995056152344
    ],
    "caption": "42.9(+4.3)",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10699462890625,
      315.0354461669922,
      251.79820251464844,
      325.83995056152344
    ],
    "caption": "269",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10699462890625,
      315.0354461669922,
      251.79820251464844,
      325.83995056152344
    ],
    "caption": "269",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      266.3506622314453,
      315.0354461669922,
      284.28346252441406,
      325.83995056152344
    ],
    "caption": "46.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      266.3506622314453,
      315.0354461669922,
      284.28346252441406,
      325.83995056152344
    ],
    "caption": "46.5",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.188201904296875,
      304.07850646972656,
      73.8599853515625,
      314.8830108642578
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.188201904296875,
      304.07850646972656,
      73.8599853515625,
      314.8830108642578
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      106.93704223632812,
      305.31585693359375,
      113.70671081542969,
      313.94154357910156
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      106.93704223632812,
      305.31585693359375,
      113.70671081542969,
      313.94154357910156
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90835571289062,
      303.9202880859375,
      218.9158477783203,
      314.8830108642578
    ],
    "caption": "43.5(+4.9)",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90835571289062,
      303.9202880859375,
      218.9158477783203,
      314.8830108642578
    ],
    "caption": "43.5(+4.9)",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10699462890625,
      304.0774383544922,
      251.79820251464844,
      314.8819580078125
    ],
    "caption": "368",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10699462890625,
      304.0774383544922,
      251.79820251464844,
      314.8819580078125
    ],
    "caption": "368",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      266.3506622314453,
      304.0774383544922,
      284.28346252441406,
      314.8819580078125
    ],
    "caption": "116.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      266.3506622314453,
      304.0774383544922,
      284.28346252441406,
      314.8819580078125
    ],
    "caption": "116.9",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.188201904296875,
      293.12049865722656,
      73.8599853515625,
      303.9250183105469
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.188201904296875,
      293.12049865722656,
      73.8599853515625,
      303.9250183105469
    ],
    "caption": "CLIP",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      106.93704223632812,
      294.3578643798828,
      113.70671081542969,
      302.98353576660156
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      106.93704223632812,
      294.3578643798828,
      113.70671081542969,
      302.98353576660156
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      135.44122314453125,
      294.3578643798828,
      142.21090698242188,
      302.98353576660156
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      135.44122314453125,
      294.3578643798828,
      142.21090698242188,
      302.98353576660156
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90835571289062,
      292.96128845214844,
      218.9158477783203,
      303.9250183105469
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90835571289062,
      292.96128845214844,
      218.9158477783203,
      303.9250183105469
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10699462890625,
      293.1184387207031,
      251.79820251464844,
      303.92295837402344
    ],
    "caption": "269",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10699462890625,
      293.1184387207031,
      251.79820251464844,
      303.92295837402344
    ],
    "caption": "269",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      261.8674621582031,
      293.1184387207031,
      284.28346252441406,
      303.92295837402344
    ],
    "caption": "50.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      261.8674621582031,
      293.1184387207031,
      284.28346252441406,
      303.92295837402344
    ],
    "caption": "50.2",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.188201904296875,
      282.1614990234375,
      73.8599853515625,
      292.9660186767578
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      52.188201904296875,
      282.1614990234375,
      73.8599853515625,
      292.9660186767578
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      106.93704223632812,
      283.39886474609375,
      113.70671081542969,
      292.0245361328125
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      106.93704223632812,
      283.39886474609375,
      113.70671081542969,
      292.0245361328125
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      162.34042358398438,
      283.39886474609375,
      169.110107421875,
      292.0245361328125
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      162.34042358398438,
      283.39886474609375,
      169.110107421875,
      292.0245361328125
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90835571289062,
      281.62351989746094,
      218.9158477783203,
      293.28880310058594
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      186.90835571289062,
      281.62351989746094,
      218.9158477783203,
      293.28880310058594
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10699462890625,
      282.15943908691406,
      251.79820251464844,
      292.9639587402344
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      236.10699462890625,
      282.15943908691406,
      251.79820251464844,
      292.9639587402344
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      266.3506622314453,
      282.15943908691406,
      284.28346252441406,
      292.9639587402344
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 5,
    "bbox": [
      266.3506622314453,
      282.15943908691406,
      284.28346252441406,
      292.9639587402344
    ],
    "caption": "embeddings to a lower dim (256) before the Transformer module. We empirically find that directly fine-tuning CLIP models to dense prediction with the default training strategies in [(<>)10] will lead to unsatisfactory results (only 21.9% mIoU on ADE20K, which is 15.6% lower than its ImageNet pre-trained counterpart). Therefore, two key modifications are made compared to the default configurations: (1) we use AdamW [(<>)31] instead of the default SGD inspired by recent progress in vision Transformers [(<>)29, (<>)39, (<>)42]; (2) to better preserve the pre-trained weights, we set the learning rate of the image encoder as 1/10 of the other parameters. We also adopt the above training strategies to our baselines in ablation studies for fair comparisons (+1.1% mIoU over the ImageNet pre-trained ResNet-50 with the default settings in [(<>)10]).",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      568.1862487792969,
      544.7582702636719,
      652.6484527587891
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": [
      "tables/fileoutpart18.xlsx",
      "tables/fileoutpart19.png"
    ],
    "output_file": "assets/images/paper/2112.01518_DenseCLIP Language-Guided Dense Prediction with Context-Aware Prompting/table_414.png"
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      638.3703460693359,
      336.94212341308594,
      647.8133239746094
    ],
    "caption": "RN50-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      638.3703460693359,
      336.94212341308594,
      647.8133239746094
    ],
    "caption": "RN50-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      379.81561279296875,
      633.6292572021484,
      403.98338317871094,
      652.6484527587891
    ],
    "caption": "239",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      379.81561279296875,
      643.2054595947266,
      403.98338317871094,
      652.6484527587891
    ],
    "caption": "(G)",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.4814147949219,
      633.6292572021484,
      398.3175964355469,
      643.0722503662109
    ],
    "caption": "239",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      405.503662109375,
      633.6292572021484,
      430.4158935546875,
      652.6484527587891
    ],
    "caption": "38",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      405.503662109375,
      643.2054595947266,
      430.4158935546875,
      652.6484527587891
    ],
    "caption": "(M)",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      410.88734436035156,
      633.6292572021484,
      425.0322265625,
      643.0722503662109
    ],
    "caption": "38",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      433.7855987548828,
      638.3703460693359,
      445.759765625,
      647.8133239746094
    ],
    "caption": "36.3",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      433.7855987548828,
      638.3703460693359,
      445.759765625,
      647.8133239746094
    ],
    "caption": "36.3",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      449.12945556640625,
      638.3703460693359,
      466.84617614746094,
      647.8133239746094
    ],
    "caption": "55.3",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      449.12945556640625,
      638.3703460693359,
      466.84617614746094,
      647.8133239746094
    ],
    "caption": "55.3",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      469.4593048095703,
      638.3703460693359,
      487.1644744873047,
      647.8133239746094
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      469.4593048095703,
      638.3703460693359,
      487.1644744873047,
      647.8133239746094
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      489.77760314941406,
      638.3703460693359,
      505.0533752441406,
      647.8133239746094
    ],
    "caption": "19.3",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      489.77760314941406,
      638.3703460693359,
      505.0533752441406,
      647.8133239746094
    ],
    "caption": "19.3",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      507.9407043457031,
      638.3703460693359,
      525.3323059082031,
      647.8133239746094
    ],
    "caption": "40.0",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      507.9407043457031,
      638.3703460693359,
      525.3323059082031,
      647.8133239746094
    ],
    "caption": "40.0",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      528.5054016113281,
      638.3703460693359,
      544.2461395263672,
      647.8133239746094
    ],
    "caption": "48.8",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      528.5054016113281,
      638.3703460693359,
      544.2461395263672,
      647.8133239746094
    ],
    "caption": "48.8",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      620.9143371582031,
      370.67042541503906,
      630.3573303222656
    ],
    "caption": "RN50-CLIP [(<>)33]",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      620.9143371582031,
      370.67042541503906,
      630.3573303222656
    ],
    "caption": "RN50-CLIP [(<>)33]",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      620.9143371582031,
      398.7564392089844,
      630.3573303222656
    ],
    "caption": "265",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      620.9143371582031,
      398.7564392089844,
      630.3573303222656
    ],
    "caption": "265",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      620.9143371582031,
      422.86151123046875,
      630.3573303222656
    ],
    "caption": "38",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      620.9143371582031,
      422.86151123046875,
      630.3573303222656
    ],
    "caption": "38",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      620.9143371582031,
      447.6170196533203,
      630.3573303222656
    ],
    "caption": "36.9",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      620.9143371582031,
      447.6170196533203,
      630.3573303222656
    ],
    "caption": "36.9",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      620.9143371582031,
      466.3775939941406,
      630.3573303222656
    ],
    "caption": "57.7",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      620.9143371582031,
      466.3775939941406,
      630.3573303222656
    ],
    "caption": "57.7",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.02464294433594,
      620.9143371582031,
      486.69764709472656,
      630.3573303222656
    ],
    "caption": "39.1",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.02464294433594,
      620.9143371582031,
      486.69764709472656,
      630.3573303222656
    ],
    "caption": "39.1",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      620.9143371582031,
      505.9362487792969,
      630.3573303222656
    ],
    "caption": "22.5",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      620.9143371582031,
      505.9362487792969,
      630.3573303222656
    ],
    "caption": "22.5",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      620.9143371582031,
      525.3002471923828,
      630.3573303222656
    ],
    "caption": "40.7",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      620.9143371582031,
      525.3002471923828,
      630.3573303222656
    ],
    "caption": "40.7",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      620.9143371582031,
      544.7582702636719,
      630.3573303222656
    ],
    "caption": "47.1",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      620.9143371582031,
      544.7582702636719,
      630.3573303222656
    ],
    "caption": "47.1",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      611.338134765625,
      369.80841064453125,
      620.7811279296875
    ],
    "caption": "RN50-DenseCLIP",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      611.338134765625,
      369.80841064453125,
      620.7811279296875
    ],
    "caption": "RN50-DenseCLIP",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      611.338134765625,
      398.7564392089844,
      620.7811279296875
    ],
    "caption": "285",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      611.338134765625,
      398.7564392089844,
      620.7811279296875
    ],
    "caption": "285",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      611.338134765625,
      422.86151123046875,
      620.7811279296875
    ],
    "caption": "60",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      611.338134765625,
      422.86151123046875,
      620.7811279296875
    ],
    "caption": "60",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      611.338134765625,
      447.6170196533203,
      620.7811279296875
    ],
    "caption": "38.5",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      611.338134765625,
      447.6170196533203,
      620.7811279296875
    ],
    "caption": "38.5",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      611.338134765625,
      466.3775939941406,
      620.7811279296875
    ],
    "caption": "57.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      611.338134765625,
      466.3775939941406,
      620.7811279296875
    ],
    "caption": "57.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.02464294433594,
      611.338134765625,
      486.69764709472656,
      620.7811279296875
    ],
    "caption": "41.0",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.02464294433594,
      611.338134765625,
      486.69764709472656,
      620.7811279296875
    ],
    "caption": "41.0",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      611.338134765625,
      505.9362487792969,
      620.7811279296875
    ],
    "caption": "21.7",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      611.338134765625,
      505.9362487792969,
      620.7811279296875
    ],
    "caption": "21.7",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      611.338134765625,
      525.3002471923828,
      620.7811279296875
    ],
    "caption": "42.8",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      611.338134765625,
      525.3002471923828,
      620.7811279296875
    ],
    "caption": "42.8",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      611.338134765625,
      544.7582702636719,
      620.7811279296875
    ],
    "caption": "50.4",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      611.338134765625,
      544.7582702636719,
      620.7811279296875
    ],
    "caption": "50.4",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      601.7619323730469,
      374.37709045410156,
      611.2049255371094
    ],
    "caption": "RN101-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      601.7619323730469,
      374.37709045410156,
      611.2049255371094
    ],
    "caption": "RN101-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      601.7619323730469,
      398.7564392089844,
      611.2049255371094
    ],
    "caption": "315",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      601.7619323730469,
      398.7564392089844,
      611.2049255371094
    ],
    "caption": "315",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      601.7619323730469,
      422.86151123046875,
      611.2049255371094
    ],
    "caption": "57",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      601.7619323730469,
      422.86151123046875,
      611.2049255371094
    ],
    "caption": "57",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      601.291748046875,
      447.6170196533203,
      611.4870300292969
    ],
    "caption": "38.5",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      601.291748046875,
      447.6170196533203,
      611.4870300292969
    ],
    "caption": "38.5",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      601.291748046875,
      466.3775939941406,
      611.4870300292969
    ],
    "caption": "57.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      601.291748046875,
      466.3775939941406,
      611.4870300292969
    ],
    "caption": "57.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.0167999267578,
      601.291748046875,
      486.68980407714844,
      611.4870300292969
    ],
    "caption": "41.0",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.0167999267578,
      601.291748046875,
      486.68980407714844,
      611.4870300292969
    ],
    "caption": "41.0",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      601.291748046875,
      505.9362487792969,
      611.4870300292969
    ],
    "caption": "21.7",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      601.291748046875,
      505.9362487792969,
      611.4870300292969
    ],
    "caption": "21.7",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      508.6476745605469,
      601.291748046875,
      524.3206787109375,
      611.4870300292969
    ],
    "caption": "42.8",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      508.6476745605469,
      601.291748046875,
      524.3206787109375,
      611.4870300292969
    ],
    "caption": "42.8",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      601.291748046875,
      544.7582702636719,
      611.4870300292969
    ],
    "caption": "50.4",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      601.291748046875,
      544.7582702636719,
      611.4870300292969
    ],
    "caption": "50.4",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      587.808837890625,
      374.5886688232422,
      597.2518310546875
    ],
    "caption": "RN101-CLIP [(<>)33]",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      587.808837890625,
      374.5886688232422,
      597.2518310546875
    ],
    "caption": "RN101-CLIP [(<>)33]",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      587.808837890625,
      398.7564392089844,
      597.2518310546875
    ],
    "caption": "341",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      587.808837890625,
      398.7564392089844,
      597.2518310546875
    ],
    "caption": "341",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      587.808837890625,
      422.86151123046875,
      597.2518310546875
    ],
    "caption": "57",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      587.808837890625,
      422.86151123046875,
      597.2518310546875
    ],
    "caption": "57",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      587.808837890625,
      447.6170196533203,
      597.2518310546875
    ],
    "caption": "40.5",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      587.808837890625,
      447.6170196533203,
      597.2518310546875
    ],
    "caption": "40.5",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      587.808837890625,
      466.3775939941406,
      597.2518310546875
    ],
    "caption": "61.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      587.808837890625,
      466.3775939941406,
      597.2518310546875
    ],
    "caption": "61.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.02464294433594,
      587.808837890625,
      486.69764709472656,
      597.2518310546875
    ],
    "caption": "43.4",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.02464294433594,
      587.808837890625,
      486.69764709472656,
      597.2518310546875
    ],
    "caption": "43.4",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      587.808837890625,
      505.9362487792969,
      597.2518310546875
    ],
    "caption": "25.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      587.808837890625,
      505.9362487792969,
      597.2518310546875
    ],
    "caption": "25.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      587.808837890625,
      525.3002471923828,
      597.2518310546875
    ],
    "caption": "44.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      587.808837890625,
      525.3002471923828,
      597.2518310546875
    ],
    "caption": "44.6",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      587.808837890625,
      544.7582702636719,
      597.2518310546875
    ],
    "caption": "51.3",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      587.808837890625,
      544.7582702636719,
      597.2518310546875
    ],
    "caption": "51.3",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      578.2326354980469,
      373.7266540527344,
      587.6756286621094
    ],
    "caption": "RN101-DenseCLIP",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      578.2326354980469,
      373.7266540527344,
      587.6756286621094
    ],
    "caption": "RN101-DenseCLIP",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      578.2326354980469,
      398.7564392089844,
      587.6756286621094
    ],
    "caption": "360",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      578.2326354980469,
      398.7564392089844,
      587.6756286621094
    ],
    "caption": "360",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      578.2326354980469,
      422.86151123046875,
      587.6756286621094
    ],
    "caption": "78",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      578.2326354980469,
      422.86151123046875,
      587.6756286621094
    ],
    "caption": "78",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      578.2326354980469,
      447.6170196533203,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      578.2326354980469,
      447.6170196533203,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      578.2326354980469,
      466.3775939941406,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      578.2326354980469,
      466.3775939941406,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.02464294433594,
      578.2326354980469,
      486.69764709472656,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.02464294433594,
      578.2326354980469,
      486.69764709472656,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      578.2326354980469,
      505.9362487792969,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      578.2326354980469,
      505.9362487792969,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      578.2326354980469,
      525.3002471923828,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      578.2326354980469,
      525.3002471923828,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      578.2326354980469,
      544.7582702636719,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      578.2326354980469,
      544.7582702636719,
      587.6756286621094
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      568.6564331054688,
      378.2953338623047,
      578.0994262695312
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      314.5218963623047,
      568.6564331054688,
      378.2953338623047,
      578.0994262695312
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      568.6564331054688,
      398.7564392089844,
      578.0994262695312
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      385.0425567626953,
      568.6564331054688,
      398.7564392089844,
      578.0994262695312
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      568.6564331054688,
      422.86151123046875,
      578.0994262695312
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      413.0658874511719,
      568.6564331054688,
      422.86151123046875,
      578.0994262695312
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      568.1862487792969,
      447.6170196533203,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      431.9440155029297,
      568.1862487792969,
      447.6170196533203,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      568.1862487792969,
      466.3775939941406,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      450.70458984375,
      568.1862487792969,
      466.3775939941406,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.0167999267578,
      568.1862487792969,
      486.68980407714844,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      471.0167999267578,
      568.1862487792969,
      486.68980407714844,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      568.1862487792969,
      505.9362487792969,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      490.26324462890625,
      568.1862487792969,
      505.9362487792969,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      568.1862487792969,
      525.3002471923828,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      509.6272430419922,
      568.1862487792969,
      525.3002471923828,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      568.1862487792969,
      544.7582702636719,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 6,
    "bbox": [
      529.0852661132812,
      568.1862487792969,
      544.7582702636719,
      578.3815307617188
    ],
    "caption": "For Mask R-CNN, we observe that DenseCLIP achieves consistent improvement on both object detection and instance segmentation tasks within an affordable computational budget. Especially for instance segmentation, our DenseCLIP outperforms the ImageNet1K pre-trained model with +2.9% and +2.5% mask AP on both ResNet50 and ResNet101 backbones and also outperforms the vanilla fine-tuning strategy with +0.8% and +0.7% mask AP. The significant improvements of DenseCLIP on the instance segmentation task suggest that our pixel-text matching is conceptually suitable for segmentation.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15147399902344,
      591.9006195068359,
      535.9072113037109,
      685.3722381591797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": [
      "tables/fileoutpart20.xlsx",
      "tables/fileoutpart21.png"
    ],
    "output_file": "assets/images/paper/2112.01518_DenseCLIP Language-Guided Dense Prediction with Context-Aware Prompting/table_543.png"
  },
  {
    "page": 7,
    "bbox": [
      58.15299987792969,
      667.2893981933594,
      86.65715026855469,
      679.2948150634766
    ],
    "caption": "RN50-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15299987792969,
      667.2893981933594,
      86.65715026855469,
      679.2948150634766
    ],
    "caption": "RN50-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      143.71524047851562,
      661.4112243652344,
      174.44113159179688,
      685.3722381591797
    ],
    "caption": "275",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      143.71524047851562,
      673.3668212890625,
      174.44113159179688,
      685.3722381591797
    ],
    "caption": "275",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.91848754882812,
      661.4112243652344,
      167.23788452148438,
      673.4166412353516
    ],
    "caption": "275",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      178.9244842529297,
      661.4112243652344,
      210.59686279296875,
      685.3722381591797
    ],
    "caption": "44",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      178.9244842529297,
      673.3668212890625,
      210.59686279296875,
      685.3722381591797
    ],
    "caption": "44",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      185.76907348632812,
      661.4112243652344,
      203.75228881835938,
      673.4166412353516
    ],
    "caption": "44",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.4720001220703,
      667.2893981933594,
      234.3480987548828,
      679.9666595458984
    ],
    "caption": "38.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.4720001220703,
      667.2893981933594,
      234.3480987548828,
      679.9666595458984
    ],
    "caption": "38.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      240.0760040283203,
      665.8721923828125,
      262.49488830566406,
      679.9666595458984
    ],
    "caption": "58.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      240.0760040283203,
      667.2893981933594,
      258.95208740234375,
      679.9666595458984
    ],
    "caption": "58.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      252.80799865722656,
      665.8721923828125,
      262.49488830566406,
      673.8783569335938
    ],
    "caption": "58.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      268.22300720214844,
      665.8721923828125,
      290.6418914794922,
      679.9666595458984
    ],
    "caption": "41.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      268.22300720214844,
      667.2893981933594,
      287.0990905761719,
      679.9666595458984
    ],
    "caption": "41.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      280.9550018310547,
      665.8721923828125,
      290.6418914794922,
      673.8783569335938
    ],
    "caption": "41.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.36900329589844,
      665.6002044677734,
      315.7412414550781,
      679.2948150634766
    ],
    "caption": "21.9",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.36900329589844,
      665.6002044677734,
      315.7412414550781,
      679.2948150634766
    ],
    "caption": "21.9",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      321.8470001220703,
      665.6002044677734,
      343.9171905517578,
      679.2948150634766
    ],
    "caption": "40.9",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      321.8470001220703,
      665.6002044677734,
      343.9171905517578,
      679.2948150634766
    ],
    "caption": "40.9",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      350.39599609375,
      665.6002044677734,
      370.339111328125,
      679.2948150634766
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      350.39599609375,
      665.6002044677734,
      370.339111328125,
      679.2948150634766
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      376.46400451660156,
      667.2893981933594,
      397.4890899658203,
      679.9666595458984
    ],
    "caption": "34.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      376.46400451660156,
      667.2893981933594,
      397.4890899658203,
      679.9666595458984
    ],
    "caption": "34.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      403.21299743652344,
      665.8721923828125,
      425.6328887939453,
      679.9666595458984
    ],
    "caption": "55.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      403.21299743652344,
      667.2893981933594,
      424.2380828857422,
      679.9666595458984
    ],
    "caption": "55.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      415.9459991455078,
      665.8721923828125,
      425.6328887939453,
      673.8783569335938
    ],
    "caption": "55.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      431.36000061035156,
      665.8721923828125,
      453.7788848876953,
      679.9666595458984
    ],
    "caption": "37.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      431.36000061035156,
      667.2893981933594,
      452.3840789794922,
      679.9666595458984
    ],
    "caption": "37.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      444.0919952392578,
      665.8721923828125,
      453.7788848876953,
      673.8783569335938
    ],
    "caption": "37.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      459.5070037841797,
      665.6002044677734,
      480.5310821533203,
      679.9666595458984
    ],
    "caption": "18.3",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      459.5070037841797,
      665.6002044677734,
      480.5310821533203,
      679.9666595458984
    ],
    "caption": "18.3",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      486.25599670410156,
      665.6002044677734,
      508.32618713378906,
      679.9666595458984
    ],
    "caption": "37.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      486.25599670410156,
      665.6002044677734,
      508.32618713378906,
      679.9666595458984
    ],
    "caption": "37.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      514.8049926757812,
      665.6002044677734,
      535.8290863037109,
      679.9666595458984
    ],
    "caption": "47.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      514.8049926757812,
      665.6002044677734,
      535.8290863037109,
      679.9666595458984
    ],
    "caption": "47.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15299987792969,
      646.0283966064453,
      129.5378875732422,
      658.0338134765625
    ],
    "caption": "RN50-DenseCLIP",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15299987792969,
      646.0283966064453,
      129.5378875732422,
      658.0338134765625
    ],
    "caption": "RN50-DenseCLIP",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.36056518554688,
      646.0283966064453,
      167.7958221435547,
      658.0338134765625
    ],
    "caption": "327",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.36056518554688,
      646.0283966064453,
      167.7958221435547,
      658.0338134765625
    ],
    "caption": "327",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.52882385253906,
      646.0283966064453,
      200.98257446289062,
      658.0338134765625
    ],
    "caption": "67",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.52882385253906,
      646.0283966064453,
      200.98257446289062,
      658.0338134765625
    ],
    "caption": "67",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      646.0283966064453,
      235.49600219726562,
      658.0338134765625
    ],
    "caption": "40.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      646.0283966064453,
      235.49600219726562,
      658.0338134765625
    ],
    "caption": "40.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      646.0283966064453,
      261.86805725097656,
      658.0338134765625
    ],
    "caption": "63.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      646.0283966064453,
      261.86805725097656,
      658.0338134765625
    ],
    "caption": "63.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      646.0283966064453,
      290.02349853515625,
      658.0338134765625
    ],
    "caption": "43.9",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      646.0283966064453,
      290.02349853515625,
      658.0338134765625
    ],
    "caption": "43.9",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      646.0283966064453,
      316.8339385986328,
      658.0338134765625
    ],
    "caption": "26.3",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      646.0283966064453,
      316.8339385986328,
      658.0338134765625
    ],
    "caption": "26.3",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      646.0283966064453,
      343.8436279296875,
      658.0338134765625
    ],
    "caption": "44.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      646.0283966064453,
      343.8436279296875,
      658.0338134765625
    ],
    "caption": "44.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      646.0283966064453,
      370.96290588378906,
      658.0338134765625
    ],
    "caption": "51.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      646.0283966064453,
      370.96290588378906,
      658.0338134765625
    ],
    "caption": "51.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      646.0283966064453,
      397.5610046386719,
      658.0338134765625
    ],
    "caption": "37.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      646.0283966064453,
      397.5610046386719,
      658.0338134765625
    ],
    "caption": "37.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      646.0283966064453,
      425.0090637207031,
      658.0338134765625
    ],
    "caption": "60.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      646.0283966064453,
      425.0090637207031,
      658.0338134765625
    ],
    "caption": "60.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      646.0283966064453,
      453.154541015625,
      658.0338134765625
    ],
    "caption": "39.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      646.0283966064453,
      453.154541015625,
      658.0338134765625
    ],
    "caption": "39.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      646.0283966064453,
      480.60260009765625,
      658.0338134765625
    ],
    "caption": "20.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      646.0283966064453,
      480.60260009765625,
      658.0338134765625
    ],
    "caption": "20.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      646.0283966064453,
      508.2598876953125,
      658.0338134765625
    ],
    "caption": "40.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      646.0283966064453,
      508.2598876953125,
      658.0338134765625
    ],
    "caption": "40.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      646.0283966064453,
      535.9072113037109,
      658.0338134765625
    ],
    "caption": "53.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      646.0283966064453,
      535.9072113037109,
      658.0338134765625
    ],
    "caption": "53.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15147399902344,
      636.3642883300781,
      128.44044494628906,
      648.3697052001953
    ],
    "caption": "RN101-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15147399902344,
      636.3642883300781,
      128.44044494628906,
      648.3697052001953
    ],
    "caption": "RN101-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.35903930664062,
      636.3642883300781,
      167.79429626464844,
      648.3697052001953
    ],
    "caption": "351",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.35903930664062,
      636.3642883300781,
      167.79429626464844,
      648.3697052001953
    ],
    "caption": "351",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.5272979736328,
      636.3642883300781,
      200.98104858398438,
      648.3697052001953
    ],
    "caption": "63",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.5272979736328,
      636.3642883300781,
      200.98104858398438,
      648.3697052001953
    ],
    "caption": "63",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      636.3643951416016,
      235.49600219726562,
      648.3698120117188
    ],
    "caption": "40.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      636.3643951416016,
      235.49600219726562,
      648.3698120117188
    ],
    "caption": "40.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      636.3643951416016,
      261.86805725097656,
      648.3698120117188
    ],
    "caption": "60.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      636.3643951416016,
      261.86805725097656,
      648.3698120117188
    ],
    "caption": "60.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      636.3643951416016,
      290.02349853515625,
      648.3698120117188
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      636.3643951416016,
      290.02349853515625,
      648.3698120117188
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      636.3643951416016,
      316.8339385986328,
      648.3698120117188
    ],
    "caption": "22.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      636.3643951416016,
      316.8339385986328,
      648.3698120117188
    ],
    "caption": "22.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      636.3643951416016,
      343.8436279296875,
      648.3698120117188
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      636.3643951416016,
      343.8436279296875,
      648.3698120117188
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      636.3643951416016,
      370.96290588378906,
      648.3698120117188
    ],
    "caption": "52.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      636.3643951416016,
      370.96290588378906,
      648.3698120117188
    ],
    "caption": "52.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      636.3643951416016,
      397.5610046386719,
      648.3698120117188
    ],
    "caption": "36.1",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      636.3643951416016,
      397.5610046386719,
      648.3698120117188
    ],
    "caption": "36.1",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      636.3643951416016,
      425.0090637207031,
      648.3698120117188
    ],
    "caption": "57.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      636.3643951416016,
      425.0090637207031,
      648.3698120117188
    ],
    "caption": "57.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      636.3643951416016,
      453.154541015625,
      648.3698120117188
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      636.3643951416016,
      453.154541015625,
      648.3698120117188
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      636.3643951416016,
      480.60260009765625,
      648.3698120117188
    ],
    "caption": "18.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      636.3643951416016,
      480.60260009765625,
      648.3698120117188
    ],
    "caption": "18.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      636.3643951416016,
      508.2598876953125,
      648.3698120117188
    ],
    "caption": "39.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      636.3643951416016,
      508.2598876953125,
      648.3698120117188
    ],
    "caption": "39.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      636.3643951416016,
      535.9072113037109,
      648.3698120117188
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      636.3643951416016,
      535.9072113037109,
      648.3698120117188
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15147399902344,
      626.6305389404297,
      134.24887084960938,
      638.6359558105469
    ],
    "caption": "RN101-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15147399902344,
      626.6305389404297,
      134.24887084960938,
      638.6359558105469
    ],
    "caption": "RN101-IN1K [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.35903930664062,
      626.6305389404297,
      167.79429626464844,
      638.6359558105469
    ],
    "caption": "351",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.35903930664062,
      626.6305389404297,
      167.79429626464844,
      638.6359558105469
    ],
    "caption": "351",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.5272979736328,
      626.6305389404297,
      200.98104858398438,
      638.6359558105469
    ],
    "caption": "63",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.5272979736328,
      626.6305389404297,
      200.98104858398438,
      638.6359558105469
    ],
    "caption": "63",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      626.0326232910156,
      235.49600219726562,
      638.9944763183594
    ],
    "caption": "40.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      626.0326232910156,
      235.49600219726562,
      638.9944763183594
    ],
    "caption": "40.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      626.0326232910156,
      261.86805725097656,
      638.9944763183594
    ],
    "caption": "60.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      626.0326232910156,
      261.86805725097656,
      638.9944763183594
    ],
    "caption": "60.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      626.0326232910156,
      290.02349853515625,
      638.9944763183594
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      626.0326232910156,
      290.02349853515625,
      638.9944763183594
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      626.0326232910156,
      316.8339385986328,
      638.9944763183594
    ],
    "caption": "22.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      626.0326232910156,
      316.8339385986328,
      638.9944763183594
    ],
    "caption": "22.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      626.0326232910156,
      343.8436279296875,
      638.9944763183594
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      626.0326232910156,
      343.8436279296875,
      638.9944763183594
    ],
    "caption": "44.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      626.0326232910156,
      370.96290588378906,
      638.9944763183594
    ],
    "caption": "52.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      626.0326232910156,
      370.96290588378906,
      638.9944763183594
    ],
    "caption": "52.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      626.0326232910156,
      397.5610046386719,
      638.9944763183594
    ],
    "caption": "36.1",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      626.0326232910156,
      397.5610046386719,
      638.9944763183594
    ],
    "caption": "36.1",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      626.0326232910156,
      425.0090637207031,
      638.9944763183594
    ],
    "caption": "57.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      626.0326232910156,
      425.0090637207031,
      638.9944763183594
    ],
    "caption": "57.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      626.0326232910156,
      453.154541015625,
      638.9944763183594
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      626.0326232910156,
      453.154541015625,
      638.9944763183594
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      626.0326232910156,
      480.60260009765625,
      638.9944763183594
    ],
    "caption": "18.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      626.0326232910156,
      480.60260009765625,
      638.9944763183594
    ],
    "caption": "18.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      626.0326232910156,
      508.2598876953125,
      638.9944763183594
    ],
    "caption": "39.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      626.0326232910156,
      508.2598876953125,
      638.9944763183594
    ],
    "caption": "39.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      626.0326232910156,
      535.9072113037109,
      638.9944763183594
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      626.0326232910156,
      535.9072113037109,
      638.9944763183594
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15299987792969,
      611.9653930664062,
      134.51939392089844,
      623.9708099365234
    ],
    "caption": "RN101-DenseCLIP",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15299987792969,
      611.9653930664062,
      134.51939392089844,
      623.9708099365234
    ],
    "caption": "RN101-DenseCLIP",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.36056518554688,
      611.9653930664062,
      167.7958221435547,
      623.9708099365234
    ],
    "caption": "399",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.36056518554688,
      611.9653930664062,
      167.7958221435547,
      623.9708099365234
    ],
    "caption": "399",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.52882385253906,
      611.9653930664062,
      200.98257446289062,
      623.9708099365234
    ],
    "caption": "84",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.52882385253906,
      611.9653930664062,
      200.98257446289062,
      623.9708099365234
    ],
    "caption": "84",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      611.9653930664062,
      235.49600219726562,
      623.9708099365234
    ],
    "caption": "42.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      611.9653930664062,
      235.49600219726562,
      623.9708099365234
    ],
    "caption": "42.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      611.9653930664062,
      261.86805725097656,
      623.9708099365234
    ],
    "caption": "65.1",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      611.9653930664062,
      261.86805725097656,
      623.9708099365234
    ],
    "caption": "65.1",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      611.9653930664062,
      290.02349853515625,
      623.9708099365234
    ],
    "caption": "46.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      611.9653930664062,
      290.02349853515625,
      623.9708099365234
    ],
    "caption": "46.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      611.9653930664062,
      316.8339385986328,
      623.9708099365234
    ],
    "caption": "27.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      611.9653930664062,
      316.8339385986328,
      623.9708099365234
    ],
    "caption": "27.7",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      611.9653930664062,
      343.8436279296875,
      623.9708099365234
    ],
    "caption": "46.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      611.9653930664062,
      343.8436279296875,
      623.9708099365234
    ],
    "caption": "46.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      611.9653930664062,
      370.96290588378906,
      623.9708099365234
    ],
    "caption": "54.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      611.9653930664062,
      370.96290588378906,
      623.9708099365234
    ],
    "caption": "54.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      611.9653930664062,
      397.5610046386719,
      623.9708099365234
    ],
    "caption": "39.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      611.9653930664062,
      397.5610046386719,
      623.9708099365234
    ],
    "caption": "39.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      611.9653930664062,
      425.0090637207031,
      623.9708099365234
    ],
    "caption": "62.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      611.9653930664062,
      425.0090637207031,
      623.9708099365234
    ],
    "caption": "62.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      611.9653930664062,
      453.154541015625,
      623.9708099365234
    ],
    "caption": "42.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      611.9653930664062,
      453.154541015625,
      623.9708099365234
    ],
    "caption": "42.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      611.9653930664062,
      480.60260009765625,
      623.9708099365234
    ],
    "caption": "21.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      611.9653930664062,
      480.60260009765625,
      623.9708099365234
    ],
    "caption": "21.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      611.9653930664062,
      508.2598876953125,
      623.9708099365234
    ],
    "caption": "43.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      611.9653930664062,
      508.2598876953125,
      623.9708099365234
    ],
    "caption": "43.0",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      611.9653930664062,
      535.9072113037109,
      623.9708099365234
    ],
    "caption": "56.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      611.9653930664062,
      535.9072113037109,
      623.9708099365234
    ],
    "caption": "56.2",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15147399902344,
      602.2315521240234,
      133.4219512939453,
      614.2369537353516
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15147399902344,
      602.2315521240234,
      133.4219512939453,
      614.2369537353516
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.35903930664062,
      602.2315521240234,
      167.79429626464844,
      614.2369537353516
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.35903930664062,
      602.2315521240234,
      167.79429626464844,
      614.2369537353516
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.5272979736328,
      602.2315521240234,
      200.98104858398438,
      614.2369537353516
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.5272979736328,
      602.2315521240234,
      200.98104858398438,
      614.2369537353516
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      602.2313995361328,
      235.49600219726562,
      614.23681640625
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      602.2313995361328,
      235.49600219726562,
      614.23681640625
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      602.2313995361328,
      261.86805725097656,
      614.23681640625
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      602.2313995361328,
      261.86805725097656,
      614.23681640625
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.08753967285156,
      601.6336212158203,
      290.01353454589844,
      614.5954742431641
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.08753967285156,
      601.6336212158203,
      290.01353454589844,
      614.5954742431641
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.89796447753906,
      602.2313995361328,
      316.823974609375,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.89796447753906,
      602.2313995361328,
      316.823974609375,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.9076690673828,
      602.2313995361328,
      343.8336639404297,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.9076690673828,
      602.2313995361328,
      343.8336639404297,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0269470214844,
      602.2313995361328,
      370.95294189453125,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0269470214844,
      602.2313995361328,
      370.95294189453125,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      602.2313995361328,
      397.5610046386719,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      602.2313995361328,
      397.5610046386719,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      602.2313995361328,
      425.0090637207031,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      602.2313995361328,
      425.0090637207031,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      602.2313995361328,
      453.154541015625,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      602.2313995361328,
      453.154541015625,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      602.2313995361328,
      480.60260009765625,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      602.2313995361328,
      480.60260009765625,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      602.2313995361328,
      508.2598876953125,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      602.2313995361328,
      508.2598876953125,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      602.2313995361328,
      535.9072113037109,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      602.2313995361328,
      535.9072113037109,
      614.23681640625
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15147399902344,
      592.4975433349609,
      139.23037719726562,
      604.5029602050781
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      58.15147399902344,
      592.4975433349609,
      139.23037719726562,
      604.5029602050781
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.35903930664062,
      592.4975433349609,
      167.79429626464844,
      604.5029602050781
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      150.35903930664062,
      592.4975433349609,
      167.79429626464844,
      604.5029602050781
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.5272979736328,
      592.4975433349609,
      200.98104858398438,
      604.5029602050781
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      188.5272979736328,
      592.4975433349609,
      200.98104858398438,
      604.5029602050781
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      591.9006195068359,
      235.49600219726562,
      604.8624725341797
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      215.57000732421875,
      591.9006195068359,
      235.49600219726562,
      604.8624725341797
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      591.9006195068359,
      261.86805725097656,
      604.8624725341797
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      241.9420623779297,
      591.9006195068359,
      261.86805725097656,
      604.8624725341797
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      591.9006195068359,
      290.02349853515625,
      604.8624725341797
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      270.0975036621094,
      591.9006195068359,
      290.02349853515625,
      604.8624725341797
    ],
    "caption": "input ImageNet CLIP DenseCLIP ground-truth",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      591.9006195068359,
      316.8339385986328,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      296.9079284667969,
      591.9006195068359,
      316.8339385986328,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      591.9006195068359,
      343.8436279296875,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      323.91761779785156,
      591.9006195068359,
      343.8436279296875,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      591.9006195068359,
      370.96290588378906,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      351.0369110107422,
      591.9006195068359,
      370.96290588378906,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      591.9006195068359,
      397.5610046386719,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      377.63499450683594,
      591.9006195068359,
      397.5610046386719,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      591.9006195068359,
      425.0090637207031,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      405.08306884765625,
      591.9006195068359,
      425.0090637207031,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      591.9006195068359,
      453.154541015625,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      433.2285461425781,
      591.9006195068359,
      453.154541015625,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      591.9006195068359,
      480.60260009765625,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      460.6766052246094,
      591.9006195068359,
      480.60260009765625,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      591.9006195068359,
      508.2598876953125,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      488.3338928222656,
      591.9006195068359,
      508.2598876953125,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      591.9006195068359,
      535.9072113037109,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      515.9812164306641,
      591.9006195068359,
      535.9072113037109,
      604.8624725341797
    ],
    "caption": "Table 5. Applying DenseCLIP to any backbone. Image backbones (such as ImageNet pre-trained ResNet [(<>)18] and Swin [(<>)29]) equipped with our DenseCLIP benefit from the language priors and enjoy significant performance boost. We report mIoU on ADE20K dataset for both single-scale (SS) and multi-scale (MS) testing.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      315.9228057861328,
      396.2995147705078,
      542.2087554931641,
      512.9058074951172
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": [
      "tables/fileoutpart23.xlsx",
      "tables/fileoutpart24.png"
    ],
    "output_file": "assets/images/paper/2112.01518_DenseCLIP Language-Guided Dense Prediction with Context-Aware Prompting/table_760.png"
  },
  {
    "page": 7,
    "bbox": [
      317.99949645996094,
      497.83006286621094,
      348.2091522216797,
      507.8390350341797
    ],
    "caption": "Semantic",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      317.99949645996094,
      497.83006286621094,
      348.2091522216797,
      507.8390350341797
    ],
    "caption": "Semantic",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.4798583984375,
      497.83006286621094,
      400.3970031738281,
      507.8390350341797
    ],
    "caption": "RN50 [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.4798583984375,
      497.83006286621094,
      400.3970031738281,
      507.8390350341797
    ],
    "caption": "RN50 [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.95213317871094,
      492.9293975830078,
      493.25201416015625,
      512.9058074951172
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.95213317871094,
      492.9293975830078,
      493.25201416015625,
      512.9058074951172
    ],
    "caption": "38.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1428985595703,
      492.9293975830078,
      542.2087554931641,
      512.9058074951172
    ],
    "caption": "40.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1428985595703,
      492.9293975830078,
      542.2087554931641,
      512.9058074951172
    ],
    "caption": "40.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      315.9228057861328,
      458.02728271484375,
      350.06959533691406,
      479.66493225097656
    ],
    "caption": "UperNet [(<>)45]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      315.9228057861328,
      469.6559600830078,
      348.91502380371094,
      479.66493225097656
    ],
    "caption": "FPN [(<>)21]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      316.84478759765625,
      458.02728271484375,
      350.06959533691406,
      468.0362548828125
    ],
    "caption": "UperNet [(<>)45]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.47972106933594,
      478.7927703857422,
      410.314453125,
      488.80174255371094
    ],
    "caption": "RN101 [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.47972106933594,
      478.7927703857422,
      410.314453125,
      488.80174255371094
    ],
    "caption": "RN101 [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9602813720703,
      478.7927703857422,
      471.5726776123047,
      488.80174255371094
    ],
    "caption": "40.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9602813720703,
      478.7927703857422,
      471.5726776123047,
      488.80174255371094
    ],
    "caption": "40.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.15106201171875,
      478.7927703857422,
      517.7634582519531,
      488.80174255371094
    ],
    "caption": "42.3",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.15106201171875,
      478.7927703857422,
      517.7634582519531,
      488.80174255371094
    ],
    "caption": "42.3",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.47972106933594,
      468.82533264160156,
      441.9943084716797,
      478.8343048095703
    ],
    "caption": "RN101 [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.47972106933594,
      468.82533264160156,
      441.9943084716797,
      478.8343048095703
    ],
    "caption": "RN101 [(<>)18]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9602813720703,
      468.2795104980469,
      485.3613586425781,
      479.1333312988281
    ],
    "caption": "40.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9602813720703,
      468.2795104980469,
      485.3613586425781,
      479.1333312988281
    ],
    "caption": "40.4",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1416931152344,
      468.2795104980469,
      531.5500640869141,
      479.13365173339844
    ],
    "caption": "42.3",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1416931152344,
      468.2795104980469,
      531.5500640869141,
      479.13365173339844
    ],
    "caption": "42.3",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.476806640625,
      454.8544616699219,
      414.4646453857422,
      464.8634338378906
    ],
    "caption": "Swin-T [(<>)29]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.476806640625,
      454.8544616699219,
      414.4646453857422,
      464.8634338378906
    ],
    "caption": "Swin-T [(<>)29]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9573669433594,
      454.8544616699219,
      471.56976318359375,
      464.8634338378906
    ],
    "caption": "44.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9573669433594,
      454.8544616699219,
      471.56976318359375,
      464.8634338378906
    ],
    "caption": "44.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1481475830078,
      454.8544616699219,
      517.7605438232422,
      464.8634338378906
    ],
    "caption": "45.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1481475830078,
      454.8544616699219,
      517.7605438232422,
      464.8634338378906
    ],
    "caption": "45.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.476806640625,
      444.88702392578125,
      446.1444854736328,
      454.89599609375
    ],
    "caption": "Swin-T [(<>)29]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.476806640625,
      444.88702392578125,
      446.1444854736328,
      454.89599609375
    ],
    "caption": "Swin-T [(<>)29]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9573669433594,
      444.34141540527344,
      485.3613586425781,
      455.19500732421875
    ],
    "caption": "44.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9573669433594,
      444.34141540527344,
      485.3613586425781,
      455.19500732421875
    ],
    "caption": "44.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1416931152344,
      444.34141540527344,
      531.5500640869141,
      455.195556640625
    ],
    "caption": "45.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1416931152344,
      444.34141540527344,
      531.5500640869141,
      455.195556640625
    ],
    "caption": "45.8",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      315.9228057861328,
      415.7998504638672,
      362.5122833251953,
      425.80882263183594
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      315.9228057861328,
      415.7998504638672,
      362.5122833251953,
      425.80882263183594
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.47972106933594,
      430.7510223388672,
      415.38954162597656,
      440.75999450683594
    ],
    "caption": "Swin-S [(<>)29]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.47972106933594,
      430.7510223388672,
      415.38954162597656,
      440.75999450683594
    ],
    "caption": "Swin-S [(<>)29]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9602813720703,
      430.7510223388672,
      471.5726776123047,
      440.75999450683594
    ],
    "caption": "47.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9602813720703,
      430.7510223388672,
      471.5726776123047,
      440.75999450683594
    ],
    "caption": "47.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.15106201171875,
      430.7510223388672,
      517.7634582519531,
      440.75999450683594
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.15106201171875,
      430.7510223388672,
      517.7634582519531,
      440.75999450683594
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.47972106933594,
      420.78358459472656,
      447.06939697265625,
      430.79254150390625
    ],
    "caption": "Swin-S [(<>)29]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.47972106933594,
      420.78358459472656,
      447.06939697265625,
      430.79254150390625
    ],
    "caption": "Swin-S [(<>)29]",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9602813720703,
      420.2375030517578,
      485.3613586425781,
      431.09156799316406
    ],
    "caption": "47.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9602813720703,
      420.2375030517578,
      485.3613586425781,
      431.09156799316406
    ],
    "caption": "47.6",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1416931152344,
      420.2375030517578,
      531.5500640869141,
      431.0908508300781
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1416931152344,
      420.2375030517578,
      531.5500640869141,
      431.0908508300781
    ],
    "caption": "49.5",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.476806640625,
      406.81166076660156,
      414.92979431152344,
      416.8206329345703
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.476806640625,
      406.81166076660156,
      414.92979431152344,
      416.8206329345703
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9573669433594,
      406.81166076660156,
      471.56976318359375,
      416.8206329345703
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9573669433594,
      406.81166076660156,
      471.56976318359375,
      416.8206329345703
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1481475830078,
      406.81166076660156,
      517.7605438232422,
      416.8206329345703
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1481475830078,
      406.81166076660156,
      517.7605438232422,
      416.8206329345703
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.476806640625,
      396.84422302246094,
      446.60963439941406,
      406.8531951904297
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      372.476806640625,
      396.84422302246094,
      446.60963439941406,
      406.8531951904297
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9573669433594,
      396.2995147705078,
      485.3613586425781,
      407.15220642089844
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      454.9573669433594,
      396.2995147705078,
      485.3613586425781,
      407.15220642089844
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1416931152344,
      396.2995147705078,
      531.5500640869141,
      407.1527557373047
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      501.1416931152344,
      396.2995147705078,
      531.5500640869141,
      407.1527557373047
    ],
    "caption": "tion tasks. DenseCLIP is a model-agnostic framework to use the pre-trained vision-language knowledge with the context-aware prompting strategy. The framework can be applied to various dense prediction tasks including semantic segmentation, object detection, and instance segmentation. We conducted extensive experiments to demonstrate the superior performance of our method.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      70.44200134277344,
      389.2025604248047,
      268.27833557128906,
      437.8819580078125
    ],
    "caption": "Effects of optimization of the textual contexts. Previous works [(<>)13, (<>)60] on transferring CLIP models to downstream classification tasks have clearly shown the importance of adapting the textual contexts for different datasets and tasks. We show the effects of optimizing the textual contexts compared to the original prompting strategy proposed in [(<>)33] in Table (<>)7. We see that although the learnable contexts will introduce additional computation during training (gradient computation for the text encoder), this strategy can bring notable improvement over the baseline. Therefore, we choose to add the learnable textual contexts for our models.",
    "file_name": [
      "tables/fileoutpart25.xlsx",
      "tables/fileoutpart26.png"
    ],
    "output_file": "assets/images/paper/2112.01518_DenseCLIP Language-Guided Dense Prediction with Context-Aware Prompting/table_822.png"
  },
  {
    "page": -1,
    "bbox": null,
    "caption": "",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      109.05299377441406,
      427.0774383544922,
      155.22996520996094,
      437.8819580078125
    ],
    "caption": "0.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      109.05299377441406,
      427.0774383544922,
      155.22996520996094,
      437.8819580078125
    ],
    "caption": "0.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      164.94056701660156,
      427.0774383544922,
      219.71630859375,
      437.8819580078125
    ],
    "caption": "0.1",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      164.94056701660156,
      427.0774383544922,
      219.71630859375,
      437.8819580078125
    ],
    "caption": "0.1",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      229.43588256835938,
      427.0774383544922,
      268.27833557128906,
      437.8819580078125
    ],
    "caption": "43.5",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      229.43588256835938,
      427.0774383544922,
      268.27833557128906,
      437.8819580078125
    ],
    "caption": "43.5",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      70.44200134277344,
      400.1574401855469,
      99.34071350097656,
      410.9619598388672
    ],
    "caption": "Effects of optimization of the textual contexts. Previous works [(<>)13, (<>)60] on transferring CLIP models to downstream classification tasks have clearly shown the importance of adapting the textual contexts for different datasets and tasks. We show the effects of optimizing the textual contexts compared to the original prompting strategy proposed in [(<>)33] in Table (<>)7. We see that although the learnable contexts will introduce additional computation during training (gradient computation for the text encoder), this strategy can bring notable improvement over the baseline. Therefore, we choose to add the learnable textual contexts for our models.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      70.44200134277344,
      400.1574401855469,
      99.34071350097656,
      410.9619598388672
    ],
    "caption": "Effects of optimization of the textual contexts. Previous works [(<>)13, (<>)60] on transferring CLIP models to downstream classification tasks have clearly shown the importance of adapting the textual contexts for different datasets and tasks. We show the effects of optimizing the textual contexts compared to the original prompting strategy proposed in [(<>)33] in Table (<>)7. We see that although the learnable contexts will introduce additional computation during training (gradient computation for the text encoder), this strategy can bring notable improvement over the baseline. Therefore, we choose to add the learnable textual contexts for our models.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      125.41700744628906,
      411.11643981933594,
      138.86659240722656,
      421.92095947265625
    ],
    "caption": "0.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      125.41700744628906,
      411.11643981933594,
      138.86659240722656,
      421.92095947265625
    ],
    "caption": "0.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      185.6060028076172,
      411.11643981933594,
      199.05560302734375,
      421.92095947265625
    ],
    "caption": "1.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      185.6060028076172,
      411.11643981933594,
      199.05560302734375,
      421.92095947265625
    ],
    "caption": "1.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      239.88699340820312,
      410.5784606933594,
      257.8197937011719,
      422.2437438964844
    ],
    "caption": "42.2",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      239.88699340820312,
      410.5784606933594,
      257.8197937011719,
      422.2437438964844
    ],
    "caption": "42.2",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      125.4129638671875,
      400.1595001220703,
      138.86256408691406,
      410.9640197753906
    ],
    "caption": "0.1",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      125.4129638671875,
      400.1595001220703,
      138.86256408691406,
      410.9640197753906
    ],
    "caption": "0.1",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      185.6044158935547,
      400.1595001220703,
      199.05401611328125,
      410.9640197753906
    ],
    "caption": "0.1",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      185.6044158935547,
      400.1595001220703,
      199.05401611328125,
      410.9640197753906
    ],
    "caption": "0.1",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      239.88699340820312,
      400.1595001220703,
      257.8197937011719,
      410.9640197753906
    ],
    "caption": "42.2",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      239.88699340820312,
      400.1595001220703,
      257.8197937011719,
      410.9640197753906
    ],
    "caption": "42.2",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      125.4129638671875,
      389.2025604248047,
      138.86256408691406,
      400.00706481933594
    ],
    "caption": "Effects of optimization of the textual contexts. Previous works [(<>)13, (<>)60] on transferring CLIP models to downstream classification tasks have clearly shown the importance of adapting the textual contexts for different datasets and tasks. We show the effects of optimizing the textual contexts compared to the original prompting strategy proposed in [(<>)33] in Table (<>)7. We see that although the learnable contexts will introduce additional computation during training (gradient computation for the text encoder), this strategy can bring notable improvement over the baseline. Therefore, we choose to add the learnable textual contexts for our models.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      125.4129638671875,
      389.2025604248047,
      138.86256408691406,
      400.00706481933594
    ],
    "caption": "Effects of optimization of the textual contexts. Previous works [(<>)13, (<>)60] on transferring CLIP models to downstream classification tasks have clearly shown the importance of adapting the textual contexts for different datasets and tasks. We show the effects of optimizing the textual contexts compared to the original prompting strategy proposed in [(<>)33] in Table (<>)7. We see that although the learnable contexts will introduce additional computation during training (gradient computation for the text encoder), this strategy can bring notable improvement over the baseline. Therefore, we choose to add the learnable textual contexts for our models.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      185.6044158935547,
      389.2025604248047,
      199.05401611328125,
      400.00706481933594
    ],
    "caption": "Effects of optimization of the textual contexts. Previous works [(<>)13, (<>)60] on transferring CLIP models to downstream classification tasks have clearly shown the importance of adapting the textual contexts for different datasets and tasks. We show the effects of optimizing the textual contexts compared to the original prompting strategy proposed in [(<>)33] in Table (<>)7. We see that although the learnable contexts will introduce additional computation during training (gradient computation for the text encoder), this strategy can bring notable improvement over the baseline. Therefore, we choose to add the learnable textual contexts for our models.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      185.6044158935547,
      389.2025604248047,
      199.05401611328125,
      400.00706481933594
    ],
    "caption": "Effects of optimization of the textual contexts. Previous works [(<>)13, (<>)60] on transferring CLIP models to downstream classification tasks have clearly shown the importance of adapting the textual contexts for different datasets and tasks. We show the effects of optimizing the textual contexts compared to the original prompting strategy proposed in [(<>)33] in Table (<>)7. We see that although the learnable contexts will introduce additional computation during training (gradient computation for the text encoder), this strategy can bring notable improvement over the baseline. Therefore, we choose to add the learnable textual contexts for our models.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      239.88699340820312,
      389.2025604248047,
      257.8197937011719,
      400.00706481933594
    ],
    "caption": "Effects of optimization of the textual contexts. Previous works [(<>)13, (<>)60] on transferring CLIP models to downstream classification tasks have clearly shown the importance of adapting the textual contexts for different datasets and tasks. We show the effects of optimizing the textual contexts compared to the original prompting strategy proposed in [(<>)33] in Table (<>)7. We see that although the learnable contexts will introduce additional computation during training (gradient computation for the text encoder), this strategy can bring notable improvement over the baseline. Therefore, we choose to add the learnable textual contexts for our models.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      239.88699340820312,
      389.2025604248047,
      257.8197937011719,
      400.00706481933594
    ],
    "caption": "Effects of optimization of the textual contexts. Previous works [(<>)13, (<>)60] on transferring CLIP models to downstream classification tasks have clearly shown the importance of adapting the textual contexts for different datasets and tasks. We show the effects of optimizing the textual contexts compared to the original prompting strategy proposed in [(<>)33] in Table (<>)7. We see that although the learnable contexts will introduce additional computation during training (gradient computation for the text encoder), this strategy can bring notable improvement over the baseline. Therefore, we choose to add the learnable textual contexts for our models.",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      91.72999572753906,
      123.50746154785156,
      244.74208068847656,
      161.76995849609375
    ],
    "caption": "Effects of . Table (<>)8 shows the effects of . We see a learnable  initialized with small values can improve the",
    "file_name": [
      "tables/fileoutpart27.xlsx",
      "tables/fileoutpart28.png"
    ],
    "output_file": "assets/images/paper/2112.01518_DenseCLIP Language-Guided Dense Prediction with Context-Aware Prompting/table_850.png"
  },
  {
    "page": 10,
    "bbox": [
      114.27200317382812,
      150.96543884277344,
      173.6475067138672,
      161.76995849609375
    ],
    "caption": "a photo of a [CLS].",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      114.27200317382812,
      150.96543884277344,
      173.6475067138672,
      161.76995849609375
    ],
    "caption": "a photo of a [CLS].",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      205.89964294433594,
      150.96543884277344,
      244.74208068847656,
      161.76995849609375
    ],
    "caption": "42.9",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      205.89964294433594,
      150.96543884277344,
      244.74208068847656,
      161.76995849609375
    ],
    "caption": "42.9",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      91.72999572753906,
      135.39895629882812,
      196.1885528564453,
      145.57582092285156
    ],
    "caption": "CoOp [(<>)60]",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      91.72999572753906,
      135.39895629882812,
      196.1885528564453,
      145.57582092285156
    ],
    "caption": "CoOp [(<>)60]",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      216.35398864746094,
      135.0044403076172,
      234.2867889404297,
      145.8089599609375
    ],
    "caption": "Effects of . Table (<>)8 shows the effects of . We see a learnable  initialized with small values can improve the",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      216.35398864746094,
      135.0044403076172,
      234.2867889404297,
      145.8089599609375
    ],
    "caption": "Effects of . Table (<>)8 shows the effects of . We see a learnable  initialized with small values can improve the",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      123.53799438476562,
      124.04544067382812,
      164.3799591064453,
      134.84996032714844
    ],
    "caption": "Effects of . Table (<>)8 shows the effects of . We see a learnable  initialized with small values can improve the",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      123.53799438476562,
      124.04544067382812,
      164.3799591064453,
      134.84996032714844
    ],
    "caption": "Effects of . Table (<>)8 shows the effects of . We see a learnable  initialized with small values can improve the",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      216.3560028076172,
      123.50746154785156,
      234.28880310058594,
      135.17274475097656
    ],
    "caption": "Effects of . Table (<>)8 shows the effects of . We see a learnable  initialized with small values can improve the",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      216.3560028076172,
      123.50746154785156,
      234.28880310058594,
      135.17274475097656
    ],
    "caption": "Effects of . Table (<>)8 shows the effects of . We see a learnable  initialized with small values can improve the",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      346.0,
      612.3925018310547,
      510.2106475830078,
      661.0739593505859
    ],
    "caption": "Table 8. Ablation study of the residual coefficient . The configuration used in our final models is highlighted in gray.",
    "file_name": [
      "tables/fileoutpart29.xlsx",
      "tables/fileoutpart30.png"
    ],
    "output_file": "assets/images/paper/2112.01518_DenseCLIP Language-Guided Dense Prediction with Context-Aware Prompting/table_863.png"
  },
  {
    "page": 10,
    "bbox": [
      346.0,
      650.2694396972656,
      407.9936828613281,
      661.0739593505859
    ],
    "caption": "104",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      346.0,
      650.2694396972656,
      407.9936828613281,
      661.0739593505859
    ],
    "caption": "104",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      418.29608154296875,
      650.2694396972656,
      461.6575927734375,
      661.0739593505859
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      418.29608154296875,
      650.2694396972656,
      461.6575927734375,
      661.0739593505859
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      471.3682098388672,
      650.2694396972656,
      510.2106475830078,
      661.0739593505859
    ],
    "caption": "42.6",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      471.3682098388672,
      650.2694396972656,
      510.2106475830078,
      661.0739593505859
    ],
    "caption": "42.6",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      366.6080017089844,
      634.5863952636719,
      386.7271423339844,
      646.0048828125
    ],
    "caption": "1.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      366.6080017089844,
      634.5863952636719,
      386.7271423339844,
      646.0048828125
    ],
    "caption": "1.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      436.29600524902344,
      635.5458068847656,
      441.4158020019531,
      644.1714782714844
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      436.29600524902344,
      635.5458068847656,
      441.4158020019531,
      644.1714782714844
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      481.82737731933594,
      634.3084411621094,
      499.7601776123047,
      645.1129608154297
    ],
    "caption": "42.8",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      481.82737731933594,
      634.3084411621094,
      499.7601776123047,
      645.1129608154297
    ],
    "caption": "42.8",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      366.6080017089844,
      623.6273956298828,
      386.7271423339844,
      635.0458831787109
    ],
    "caption": "1.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      366.6080017089844,
      623.6273956298828,
      386.7271423339844,
      635.0458831787109
    ],
    "caption": "1.0",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      435.4709930419922,
      624.5868072509766,
      442.2406768798828,
      633.2124786376953
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      435.4709930419922,
      624.5868072509766,
      442.2406768798828,
      633.2124786376953
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      481.8280029296875,
      622.8114624023438,
      499.76080322265625,
      634.4767456054688
    ],
    "caption": "mIoU (%)",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      481.8280029296875,
      622.8114624023438,
      499.76080322265625,
      634.4767456054688
    ],
    "caption": "mIoU (%)",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      370.56394958496094,
      612.3925018310547,
      384.0135498046875,
      623.1970062255859
    ],
    "caption": "104",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      370.56394958496094,
      612.3925018310547,
      384.0135498046875,
      623.1970062255859
    ],
    "caption": "104",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      435.4717102050781,
      613.6298675537109,
      442.24139404296875,
      622.2555389404297
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      435.4717102050781,
      613.6298675537109,
      442.24139404296875,
      622.2555389404297
    ],
    "caption": "",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      481.8280029296875,
      612.3925018310547,
      499.76080322265625,
      623.1970062255859
    ],
    "caption": "42.6",
    "file_name": ""
  },
  {
    "page": 10,
    "bbox": [
      481.8280029296875,
      612.3925018310547,
      499.76080322265625,
      623.1970062255859
    ],
    "caption": "42.6",
    "file_name": ""
  }
]