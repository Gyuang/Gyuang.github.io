[
  {
    "page": 1,
    "bbox": [
      59.4071044921875,
      570.4017486572266,
      139.01454162597656,
      665.3060760498047
    ],
    "caption": "Language Characterization",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_01.png"
  },
  {
    "page": 1,
    "bbox": [
      59.4071044921875,
      570.4017486572266,
      139.01454162597656,
      665.3060760498047
    ],
    "caption": "Language Characterization",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      152.8804473876953,
      670.7812042236328,
      239.85162353515625,
      694.5155639648438
    ],
    "caption": "1.26 x 10-2 mm˛ / s",
    "file_name": [
      "figures/fileoutpart1.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_03.png"
  },
  {
    "page": 1,
    "bbox": [
      152.8804473876953,
      670.7812042236328,
      239.85162353515625,
      694.5155639648438
    ],
    "caption": "1.26 x 10-2 mm˛ / s",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      159.97288513183594,
      570.4017486572266,
      239.9243927001953,
      665.3060760498047
    ],
    "caption": "Language Characterization",
    "file_name": [
      "figures/fileoutpart2.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_05.png"
  },
  {
    "page": 1,
    "bbox": [
      159.97288513183594,
      570.4017486572266,
      239.9243927001953,
      665.3060760498047
    ],
    "caption": "Language Characterization",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      250.03736877441406,
      564.5191497802734,
      343.60498046875,
      701.2451171875
    ],
    "caption": "1 2 compute the increase in white matter hypointensity volume since the ˜rst visit 4.4x increase (+9.7 ml) 1 2 calculate progressive signal reduction of the basal ganglia hyperdensity 0.31x less dense (-24.1 HU) indicate the vascular territory of the infarct middle cerebral artery",
    "file_name": [
      "figures/fileoutpart3.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_07.png"
  },
  {
    "page": 1,
    "bbox": [
      250.03736877441406,
      564.5191497802734,
      343.60498046875,
      701.2451171875
    ],
    "caption": "1 2 compute the increase in white matter hypointensity volume since the ˜rst visit 4.4x increase (+9.7 ml) 1 2 calculate progressive signal reduction of the basal ganglia hyperdensity 0.31x less dense (-24.1 HU) indicate the vascular territory of the infarct middle cerebral artery",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      359.97169494628906,
      570.4017486572266,
      452.9900207519531,
      665.3072052001953
    ],
    "caption": "Analysis Across Visits",
    "file_name": [
      "figures/fileoutpart4.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_09.png"
  },
  {
    "page": 1,
    "bbox": [
      359.97169494628906,
      570.4017486572266,
      452.9900207519531,
      665.3072052001953
    ],
    "caption": "Analysis Across Visits",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      459.21751403808594,
      564.5191497802734,
      562.8606719970703,
      701.2451171875
    ],
    "caption": "Analysis Across Visits",
    "file_name": [
      "figures/fileoutpart5.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_11.png"
  },
  {
    "page": 1,
    "bbox": [
      459.21751403808594,
      564.5191497802734,
      562.8606719970703,
      701.2451171875
    ],
    "caption": "Analysis Across Visits",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      50.14591979980469,
      399.1639099121094,
      143.71351623535156,
      535.8898773193359
    ],
    "caption": "Multiple Acquisition Analysis",
    "file_name": [
      "figures/fileoutpart6.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_13.png"
  },
  {
    "page": 1,
    "bbox": [
      50.14591979980469,
      399.1639099121094,
      143.71351623535156,
      535.8898773193359
    ],
    "caption": "Multiple Acquisition Analysis",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      150.1877899169922,
      399.1639099121094,
      561.8766479492188,
      535.8898773193359
    ],
    "caption": "Multiple Acquisition Analysis",
    "file_name": [
      "figures/fileoutpart7.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_15.png"
  },
  {
    "page": 1,
    "bbox": [
      150.1877899169922,
      399.1639099121094,
      561.8766479492188,
      535.8898773193359
    ],
    "caption": "Multiple Acquisition Analysis",
    "file_name": ""
  },
  {
    "page": 1,
    "bbox": [
      50.14653015136719,
      233.73634338378906,
      561.8766479492188,
      370.4623107910156
    ],
    "caption": "Figure 1. Examples from the diverse set of tasks supported by the VoxelPrompt framework. For each example, we show the input prompt (gray) above the input images(s). VoxelPrompt annotates the images and generates language responses (shown in purple). These scans are processed entirely in 3D, but here we show only a single extracted slice.",
    "file_name": [
      "figures/fileoutpart8.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_17.png"
  },
  {
    "page": 1,
    "bbox": [
      50.14653015136719,
      233.73634338378906,
      561.8766479492188,
      370.4623107910156
    ],
    "caption": "Figure 1. Examples from the diverse set of tasks supported by the VoxelPrompt framework. For each example, we show the input prompt (gray) above the input images(s). VoxelPrompt annotates the images and generates language responses (shown in purple). These scans are processed entirely in 3D, but here we show only a single extracted slice.",
    "file_name": ""
  },
  {
    "page": 3,
    "bbox": [
      50.39668273925781,
      485.44483947753906,
      564.6481323242188,
      721.2248229980469
    ],
    "caption": "Figure 2. To solve a language-prompted task, the adaptive agent model α outputs instructions η as code to run in a persistent execution environment Ω. Across multiple steps, the agent interprets execution outcomes z (blue) to guide subsequent instruction prediction. To perform vision operations, such as volume encoding or generation, α can instruct the execution of vision networks menc and mgen, which are manipulated by image-specific latent instruction embeddings ϕ.",
    "file_name": [
      "figures/fileoutpart9.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_19.png"
  },
  {
    "page": 3,
    "bbox": [
      50.39668273925781,
      485.44483947753906,
      564.6481323242188,
      721.2248229980469
    ],
    "caption": "Figure 2. To solve a language-prompted task, the adaptive agent model α outputs instructions η as code to run in a persistent execution environment Ω. Across multiple steps, the agent interprets execution outcomes z (blue) to guide subsequent instruction prediction. To perform vision operations, such as volume encoding or generation, α can instruct the execution of vision networks menc and mgen, which are manipulated by image-specific latent instruction embeddings ϕ.",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      91.37600708007812,
      133.55299377441406,
      262.5439453125,
      171.9931182861328
    ],
    "caption": "Interpretable Volume Encodings. For each volume v passed through menc, we reduce the spatial dimensions of the deepest layer output using a global max operator. We pass these pooled features through a fully-connected",
    "file_name": [
      "figures/fileoutpart12.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_21.png"
  },
  {
    "page": 4,
    "bbox": [
      91.37600708007812,
      133.55299377441406,
      262.5439453125,
      171.9931182861328
    ],
    "caption": "Interpretable Volume Encodings. For each volume v passed through menc, we reduce the spatial dimensions of the deepest layer output using a global max operator. We pass these pooled features through a fully-connected",
    "file_name": ""
  },
  {
    "page": 4,
    "bbox": [
      352.98826599121094,
      470.53370666503906,
      522.0821228027344,
      510.71751403808594
    ],
    "caption": "where P (φ) is output by the language model and volumes W are generated by the vision networks while executing φ∗ . The function Lce measures cross-entropy between predicted vocabulary probabilities and tokenized target text, and Limg measures differences between a predicted and target image, weighted by a scalar λ. In our experiments, we focus on the most consequential type of intermediate volume for ROI processing – spatial segmentation. Therefore, we set Limg as the soft Dice loss [(<>)124].",
    "file_name": [
      "figures/fileoutpart13.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_23.png"
  },
  {
    "page": 4,
    "bbox": [
      352.98826599121094,
      470.53370666503906,
      522.0821228027344,
      510.71751403808594
    ],
    "caption": "where P (φ) is output by the language model and volumes W are generated by the vision networks while executing φ∗ . The function Lce measures cross-entropy between predicted vocabulary probabilities and tokenized target text, and Limg measures differences between a predicted and target image, weighted by a scalar λ. In our experiments, we focus on the most consequential type of intermediate volume for ROI processing – spatial segmentation. Therefore, we set Limg as the soft Dice loss [(<>)124].",
    "file_name": ""
  },
  {
    "page": 7,
    "bbox": [
      55.31083679199219,
      613.4106750488281,
      133.44528198242188,
      692.0345001220703
    ],
    "caption": "segment white matter hyperintensities",
    "file_name": [
      "figures/fileoutpart14.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_25.png"
  },
  {
    "page": 7,
    "bbox": [
      138.87814331054688,
      613.3675842285156,
      217.01431274414062,
      691.5894470214844
    ],
    "caption": "isolate left, peripheral hyperintensities",
    "file_name": [
      "figures/fileoutpart15.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_26.png"
  },
  {
    "page": 7,
    "bbox": [
      55.232452392578125,
      497.89231872558594,
      300.9113311767578,
      576.4037780761719
    ],
    "caption": "˜nd hypodense, necrotic tissue in the mass",
    "file_name": [
      "figures/fileoutpart16.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_27.png"
  },
  {
    "page": 7,
    "bbox": [
      55.28968811035156,
      383.08331298828125,
      133.4664306640625,
      461.3633270263672
    ],
    "caption": "Figure 3. Natural language input prompts (shown above each image) enable targeted analysis of nuanced, context-specific image regions, especially for multi-lesion cases. Borders of segmentations predicted by VoxelPrompt are shown in purple.",
    "file_name": [
      "figures/fileoutpart17.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_28.png"
  },
  {
    "page": 7,
    "bbox": [
      138.80624389648438,
      382.7929992675781,
      217.0862579345703,
      461.07301330566406
    ],
    "caption": "Figure 3. Natural language input prompts (shown above each image) enable targeted analysis of nuanced, context-specific image regions, especially for multi-lesion cases. Borders of segmentations predicted by VoxelPrompt are shown in purple.",
    "file_name": [
      "figures/fileoutpart18.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_29.png"
  },
  {
    "page": 7,
    "bbox": [
      222.65478515625,
      613.3675842285156,
      300.87664794921875,
      691.5894470214844
    ],
    "caption": "˜nd the hypointensity near the right ventricle",
    "file_name": [
      "figures/fileoutpart19.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_30.png"
  },
  {
    "page": 7,
    "bbox": [
      217.4143829345703,
      379.1349639892578,
      311.4127502441406,
      463.17713928222656
    ],
    "caption": "Figure 3. Natural language input prompts (shown above each image) enable targeted analysis of nuanced, context-specific image regions, especially for multi-lesion cases. Borders of segmentations predicted by VoxelPrompt are shown in purple.",
    "file_name": [
      "figures/fileoutpart20.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_31.png"
  },
  {
    "page": 8,
    "bbox": [
      49.79512023925781,
      448.6943359375,
      562.0319213867188,
      720.9540405273438
    ],
    "caption": "Figure 4. VoxelPrompt (black) yields segmentations with accuracy that matches or exceeds that of specialized single-task (purple) and state-of-the-art (blue) brain segmentation benchmarks. We plot the Dice score between estimated segmentations and the ground truth for a set of label targets, with the average differences between VoxelPrompt and the single-task benchmarks above each label plot. Significant differences (p < 0.05, paired t-test) are marked with an asterisk. For visual simplicity in the SynthSeg comparison, we group results for cortical regions by their associated cortical lobe.",
    "file_name": [
      "figures/fileoutpart21.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_32.png"
  },
  {
    "page": 8,
    "bbox": [
      49.79512023925781,
      448.6943359375,
      562.0319213867188,
      720.9540405273438
    ],
    "caption": "Figure 4. VoxelPrompt (black) yields segmentations with accuracy that matches or exceeds that of specialized single-task (purple) and state-of-the-art (blue) brain segmentation benchmarks. We plot the Dice score between estimated segmentations and the ground truth for a set of label targets, with the average differences between VoxelPrompt and the single-task benchmarks above each label plot. Significant differences (p < 0.05, paired t-test) are marked with an asterisk. For visual simplicity in the SynthSeg comparison, we group results for cortical regions by their associated cortical lobe.",
    "file_name": ""
  },
  {
    "page": 9,
    "bbox": [
      49.76264953613281,
      632.9466552734375,
      561.9964904785156,
      720.5532073974609
    ],
    "caption": "Figure 5. Accuracy of pathology characterization using natural language for five separate classification subtasks. Average subtask accuracy is shown on the left. VoxelPrompt (black) parallels the performance of individually-trained, single-task classifiers (purple) and a fine-tuned RadFM model (blue) – a state-of-the-art method for 3D visual question-answering.",
    "file_name": [
      "figures/fileoutpart22.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_34.png"
  },
  {
    "page": 9,
    "bbox": [
      49.76264953613281,
      632.9466552734375,
      561.9964904785156,
      720.5532073974609
    ],
    "caption": "Figure 5. Accuracy of pathology characterization using natural language for five separate classification subtasks. Average subtask accuracy is shown on the left. VoxelPrompt (black) parallels the performance of individually-trained, single-task classifiers (purple) and a fine-tuned RadFM model (blue) – a state-of-the-art method for 3D visual question-answering.",
    "file_name": ""
  },
  {
    "page": 17,
    "bbox": [
      82.5687255859375,
      465.7147521972656,
      270.1436309814453,
      504.1504669189453
    ],
    "caption": "During upsampling, this process is reversed. To prevent disproportionate convolution of spatial information for volumes with ωn > 2, we instead apply a 2D convolution across each volume slice, using a central 3D kernel slice extracted from the image through-plane dimension.",
    "file_name": [
      "figures/fileoutpart23.png"
    ],
    "output_file": "assets/images/paper/2410.08397_VoxelPrompt A Vision Language Agent for Grounded Medical Image Analysis/fig_36.png"
  },
  {
    "page": 17,
    "bbox": [
      82.5687255859375,
      465.7147521972656,
      270.1436309814453,
      504.1504669189453
    ],
    "caption": "During upsampling, this process is reversed. To prevent disproportionate convolution of spatial information for volumes with ωn > 2, we instead apply a 2D convolution across each volume slice, using a central 3D kernel slice extracted from the image through-plane dimension.",
    "file_name": ""
  }
]