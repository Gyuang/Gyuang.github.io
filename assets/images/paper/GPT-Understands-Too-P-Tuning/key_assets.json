{
  "architecture": {
    "page": -1,
    "bbox": [
      306.07203674316406,
      560.3830413818359,
      524.4800262451172,
      629.3613433837891
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/GPT-Understands-Too-P-Tuning/fig_01.png"
  },
  "results": {
    "page": 2,
    "bbox": [
      334.79730224609375,
      527.169677734375,
      500.67901611328125,
      585.6106719970703
    ],
    "caption": "Table 2: Task settings and summary of results in our experiments. P-tuning shows improvement over baselines on all task settings, and can stabilize performance on LAMA and Few SG. For Full SG, the gap between discrete prompts is not large and training is stable even without P-Tuning. (Full SG: fully-supervised learning on SuperGLUE; Few SG: few-shot SuperGLUE; Improved: overall performance improved; Stabilized: training stabilized by minimizing difference between discrete prompts).",
    "file_name": [
      "tables/fileoutpart6.xlsx",
      "tables/fileoutpart7.png"
    ],
    "output_file": "assets/images/paper/GPT-Understands-Too-P-Tuning/table_32.png"
  },
  "results_2": null,
  "markdown": "### Main Architecture\n![Architecture](/assets/images/paper/GPT-Understands-Too-P-Tuning/fig_01.png)\n\n### Main Results Table\n![Results](/assets/images/paper/GPT-Understands-Too-P-Tuning/table_32.png)\n캡션: Table 2: Task settings and summary of results in our experiments. P-tuning shows improvement over baselines on all task settings, and can stabilize performance on LAMA and Few SG. For Full SG, the gap between discrete prompts is not large and training is stable even without P-Tuning. (Full SG: fully-supervised learning on SuperGLUE; Few SG: few-shot SuperGLUE; Improved: overall performance improve…"
}