{
  "architecture": {
    "page": -1,
    "bbox": [
      307.49925231933594,
      452.6142578125,
      525.3180084228516,
      619.4102172851562
    ],
    "caption": "",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/Prefix-Tuning/fig_01.png"
  },
  "results": {
    "page": 6,
    "bbox": [
      77.97010803222656,
      653.8044128417969,
      527.8499298095703,
      776.9750213623047
    ],
    "caption": "Table 1: Metrics (higher is better, except for TER) for table-to-text generation on E2E (left), WebNLG (middle) and DART (right). With only 0.1% parameters, Prefix-tuning outperforms other lightweight baselines and achieves a comparable performance with fine-tuning. The best score is boldfaced for both GPT-2MEDIUM and GPT-2LARGE.",
    "file_name": [
      "tables/fileoutpart6.xlsx",
      "tables/fileoutpart7.png"
    ],
    "output_file": "assets/images/paper/Prefix-Tuning/table_01.png"
  },
  "results_2": null,
  "markdown": "### Main Architecture\n![Architecture](/assets/images/paper/Prefix-Tuning/fig_01.png)\n\n### Main Results Table\n![Results](/assets/images/paper/Prefix-Tuning/table_01.png)\n캡션: Table 1: Metrics (higher is better, except for TER) for table-to-text generation on E2E (left), WebNLG (middle) and DART (right). With only 0.1% parameters, Prefix-tuning outperforms other lightweight baselines and achieves a comparable performance with fine-tuning. The best score is boldfaced for both GPT-2MEDIUM and GPT-2LARGE."
}