{
  "architecture": {
    "page": 1,
    "bbox": [
      54.0,
      440.49989318847656,
      549.8999938964844,
      721.4499053955078
    ],
    "caption": "Fig.1. Overview of the proposed adapter-tuning MLLM framework: the image and text encoder are frozen while the trainable Adapter and Linear Projection Layer are updated. It integrates the fine-tuned newly acquired brain disease-related knowledge with the original medical knowledge inside the MLLM for the downstream tasks: brain disease identification.",
    "file_name": [
      "figures/fileoutpart0.png"
    ],
    "output_file": "assets/images/paper/Brain-Adapter-Enhancing-Neurological-Disorder-Analysis-with-Adapter-Tuning-Multimodal-Large-Language-Models/fig_01.png"
  },
  "results": {
    "page": 3,
    "bbox": [
      59.279998779296875,
      266.6937561035156,
      289.9786682128906,
      422.55311584472656
    ],
    "caption": "Table 2 reports the classification results on our multimodal dataset. When all the parameters of the MLLM are frozen and only the Brain-Adapter is trained, the model can still classify diseases, indicating that the Brain-Adapter effectively leverages the knowledge embedded in the original MLLMs. Moreover, when we simply unfreeze the linear projection layer of both the image encoder and the text encoder, the classification performance improves significantly, showing that the Brain-Adapter can inject new knowledge from fresh training examples into the original MLLMs. Furthermore, the latter shows a significant improvement when we compare Table 1, which uses only a single MRI image modality, with Table 2, which uses multimodal data. This suggests that clinical reports help the model better understand brain diseases and our method aligns",
    "file_name": [
      "tables/fileoutpart8.xlsx",
      "tables/fileoutpart9.png"
    ],
    "output_file": "assets/images/paper/Brain-Adapter-Enhancing-Neurological-Disorder-Analysis-with-Adapter-Tuning-Multimodal-Large-Language-Models/table_01.png"
  },
  "results_2": null,
  "markdown": "### Main Architecture\n![Architecture](/assets/images/paper/Brain-Adapter-Enhancing-Neurological-Disorder-Analysis-with-Adapter-Tuning-Multimodal-Large-Language-Models/fig_01.png)\n캡션: Fig.1. Overview of the proposed adapter-tuning MLLM framework: the image and text encoder are frozen while the trainable Adapter and Linear Projection Layer are updated. It integrates the fine-tuned newly acquired brain disease-related knowledge with the original medical knowledge inside the MLLM for the downstream tasks: brain disease identification.\n\n### Main Results Table\n![Results](/assets/images/paper/Brain-Adapter-Enhancing-Neurological-Disorder-Analysis-with-Adapter-Tuning-Multimodal-Large-Language-Models/table_01.png)\n캡션: Table 2 reports the classification results on our multimodal dataset. When all the parameters of the MLLM are frozen and only the Brain-Adapter is trained, the model can still classify diseases, indicating that the Brain-Adapter effectively leverages the knowledge embedded in the original MLLMs. Moreover, when we simply unfreeze the linear projection layer of both the image encoder and the text en…"
}