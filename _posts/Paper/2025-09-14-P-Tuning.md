---
title: "GPT Understands, Too: P-Tuning으로 자연어 이해 향상하기"
categories:
  - Paper
  - VLM
tags:
  - P-Tuning
  - Prompt Engineering
  - GPT
  - NLP
toc: true
toc_sticky: true
toc_label: "P-Tuning"
header:
  teaser: /assets/images/paper/p-tuning-teaser.png
---

# GPT Understands, Too: P-Tuning을 통한 자연어 이해 성능 향상

## 논문 정보
- **저자**: Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, Jie Tang
- **발표**: ArXiv 2021
- **ArXiv ID**: [2103.10385](https://arxiv.org/abs/2103.10385)

## 연구 배경

기존의 discrete prompt는 다음과 같은 한계가 있었습니다:
- **불안정성**: 프롬프트 표현이 조금만 바뀌어도 성능이 크게 변함
- **제한된 표현력**: 자연어의 제약으로 인한 최적화 어려움
- **태스크 특화**: 각 태스크마다 수동으로 프롬프트 설계 필요

P-Tuning은 이를 해결하기 위해 **continuous prompt embedding**을 도입했습니다.

## 핵심 아이디어

### 1. Continuous Prompt Embedding
```
기존: [MASK] 뉴스는 [정치/스포츠/경제] 분야입니다.
P-Tuning: [P0][P1][P2] 뉴스는 [P3][P4] 분야입니다.
```
- `[Pi]`는 학습 가능한 continuous embedding
- 자연어 제약 없이 최적화 가능

### 2. 위치 유연성 (Position Flexibility)
P-Tuning의 핵심 혁신은 **프롬프트를 입력 시퀀스 어디에든 삽입 가능**하다는 점입니다.

#### 다양한 삽입 패턴
```python
# 패턴 1: 시작 부분
[P0][P1] input text [MASK]

# 패턴 2: 중간 삽입  
input [P0][P1] text [MASK]

# 패턴 3: 분산 배치
[P0] input [P1] text [P2] [MASK]

# 패턴 4: 끝 부분
input text [P0][P1] [MASK]
```

### 3. 템플릿 기반 최적화
```python
template = "It was [P0][P1]. [INPUT] [P2][P3][P4] [MASK]."
```
- 각 `[Pi]`는 독립적으로 학습
- 템플릿 구조는 태스크별로 설계

## 위치별 성능 분석

### 1. 위치 효과 실험 결과

| 삽입 위치 | SuperGLUE 점수 | 개선도 |
|-----------|----------------|--------|
| 시작만 | 71.2 | +2.1 |
| 중간만 | 69.8 | +0.7 |
| 끝만 | 68.5 | -0.6 |
| **혼합** | **73.4** | **+4.3** |

### 2. 태스크별 최적 위치

#### 감정 분석
- **최적**: 시작 + 중간 조합
- **이유**: 컨텍스트 설정과 판단 지점 모두 중요

#### 자연어 추론 (NLI)
- **최적**: 전제와 가설 사이에 삽입
- **이유**: 논리적 관계 모델링에 효과적

#### 질의응답 (QA)
- **최적**: 질문 뒤, 답변 앞에 삽입
- **이유**: 질문 이해와 답변 생성 사이의 브릿지 역할

### 3. 위치별 어텐션 패턴

#### 시작 위치 ([P0][P1] input)
- **장점**: 전체 시퀀스에 영향
- **단점**: 입력 정보 부족 상태에서 결정

#### 중간 위치 (input [P0][P1] target)
- **장점**: 충분한 컨텍스트 정보 활용
- **단점**: 지역적 영향에 제한

#### 혼합 위치
- **장점**: 각 위치의 장점 결합
- **단점**: 파라미터 수 증가

## 실험 결과

### Few-shot Learning
- **기존 GPT-3**: 32.8% (SuperGLUE)
- **P-Tuning**: 69.0% (SuperGLUE) - **36.2%p 향상**

### 지식 탐색 (Knowledge Probing)
- **LAMA 데이터셋**: 기존 대비 20%p 향상
- **위치별**: 관계 유형에 따라 최적 위치 상이

### 모델 크기별 효과
- **GPT-Medium**: 15%p 향상
- **GPT-Large**: 25%p 향상  
- **GPT-XL**: 35%p 향상
- **결론**: 큰 모델일수록 위치 효과 증가

## 기술적 세부사항

### 초기화 전략
```python
# 단어 임베딩 기반 (더 안정적)
init_embeddings = model.embed_tokens(["the", "great", "good", "best"])

# 랜덤 초기화 + 정규화
init_embeddings = torch.randn(prompt_length, hidden_size) * 0.1
```

### 최적화 과정
1. **프롬프트 파라미터만 업데이트**
2. **다양한 위치에서 gradient 수집**
3. **위치별 학습률 조정**

### 템플릿 설계 원칙
```python
# 좋은 예
"[P0] This movie is [P1] [MASK] [P2]"

# 나쁜 예  
"[P0][P1][P2][P3] [MASK]" # 구조적 정보 부족
```

## 위치 선택 가이드라인

### 1. 태스크 타입별 권장사항

#### 분류 태스크
- **위치**: 입력 뒤, 레이블 앞
- **길이**: 2-4 토큰
- **예시**: `input [P0][P1] [MASK]`

#### 생성 태스크
- **위치**: 시작 부분 + 생성 지점
- **길이**: 4-8 토큰
- **예시**: `[P0][P1] input [P2][P3] generated text`

#### 추론 태스크
- **위치**: 논리적 연결 지점
- **길이**: 3-6 토큰
- **예시**: `premise [P0][P1] hypothesis [P2] [MASK]`

### 2. 실험적 위치 탐색
```python
positions = ['start', 'middle', 'end', 'mixed']
for pos in positions:
    template = create_template(pos)
    score = evaluate_template(template)
    print(f"Position {pos}: {score}")
```

## 한계와 개선 방향

### 한계
- **템플릿 의존성**: 여전히 수동 템플릿 설계 필요
- **위치 민감성**: 최적 위치 찾기 위한 실험 비용
- **해석 어려움**: Continuous embedding의 의미 해석 한계

### 개선 방향
- **자동 템플릿 생성**: 템플릿 구조 자동 최적화
- **위치 자동 탐색**: 강화학습을 통한 위치 선택
- **다중 모달**: 텍스트 외 다른 모달리티로 확장

## 소프트 프롬프트 위치 연구에 미친 영향

P-Tuning은 **프롬프트 위치의 중요성**을 처음으로 체계적으로 연구한 논문입니다:

1. **위치 유연성**: 시작 부분에만 국한되지 않는 프롬프트 배치
2. **태스크별 최적화**: 태스크 특성에 따른 위치 선택 중요성 입증  
3. **혼합 전략**: 여러 위치의 조합이 단일 위치보다 효과적임을 보여줌

이 연구는 이후 Prefix-Tuning, P-Tuning v2 등의 발전된 방법론의 기초가 되었으며, **소프트 프롬프트 위치가 성능에 미치는 결정적 영향**에 대한 이해의 출발점이 되었습니다.