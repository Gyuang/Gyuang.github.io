---
categories:
- NLP
- Prompt Engineering
date: '2025-09-16'
excerpt: 'P-Tuning: GPT도 NLU를 잘 할 수 있다! 파라미터 효율적인 프롬프트 튜닝 기법'
header:
  teaser: /assets/images/paper/p-tuning-teaser.png
last_modified_at: '2025-09-16'
published: true
tags:
- P-Tuning
- Prompt Engineering
- GPT
- NLP
- Parameter-Efficient Fine-Tuning
title: 'GPT Understands, Too: P-Tuning으로 자연어 이해 향상하기'
toc: true
toc_sticky: true
---

### 1. 논문 기본 정보

-   **제목:** GPT Understands, Too
-   **저자:** Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, Jie Tang
-   **발표:** ArXiv
-   **발표 연도:** 2021
-   **ArXiv 링크:** [https://arxiv.org/abs/2103.10385](https://arxiv.org/abs/2103.10385)
-   **코드/데이터 공개 여부:** 코드가 GitHub에 공개됨 ([https://github.com/THUDM/P-tuning](https://github.com/THUDM/P-tuning))

### 2. 핵심 요약 (3문장 이내)

이 연구는 GPT와 같은 대규모 언어 모델(LLM)을 자연어 이해(NLU) 태스크에 효과적으로 적용하기 위한 파라미터 효율적인 fine-tuning 방법인 'P-Tuning'을 제안합니다. P-Tuning은 모델의 모든 파라미터를 재학습하는 대신, 학습 가능한 연속적인(continuous) 프롬프트 임베딩을 최적화하여 NLU 성능을 크게 향상시킵니다. 그 결과, LAMA와 SuperGLUE 같은 벤치마크에서 P-Tuning을 적용한 GPT가 비슷한 크기의 BERT와 필적하거나 더 나은 성능을 보였으며, 이는 LLM의 잠재력을 더 효율적으로 활용할 수 있는 새로운 길을 열었습니다.

### 3. 배경 & 동기

GPT-3와 같은 LLM은 NLU 태스크에서 few-shot 학습 능력을 보여주었지만, 비슷한 크기의 BERT와 비교했을 때 NLU 태스크에서의 성능이 떨어지는 경향이 있었습니다. 기존의 fine-tuning 방식은 수십억 개의 파라미터를 모두 업데이트해야 하므로 엄청난 계산 비용과 시간이 필요했습니다. 또한, 수동으로 최적의 프롬프트를 찾는 '프롬프트 엔지니어링'은 불안정하고 성능 변동이 컸습니다. 이러한 비효율성과 불안정성을 해결하고, GPT 계열 모델을 NLU 태스크에 더 잘 활용하기 위해 P-Tuning이 제안되었습니다.

### 4. 방법론

-   **전체 아키텍처 흐름:**
    1.  **입력:** NLU 태스크의 입력 텍스트.
    2.  **Continuous Prompts:** 학습 가능한 가상의 프롬프트 임베딩(pseudo prompt)을 입력 텍스트 임베딩 앞부분에 추가.
    3.  **Prompt Encoder:** 이 프롬프트 임베딩들을 처리하기 위해 작은 BiLSTM과 MLP로 구성된 '프롬프트 인코더'를 사용.
    4.  **LLM:** 프롬프트가 추가된 전체 임베딩을 사전 학습된 LLM(예: GPT)에 통과시켜 태스크를 수행.
    5.  **학습:** LLM의 파라미터는 대부분 고정(freeze)하고, 프롬프트 인코더의 파라미터만 역전파를 통해 학습하여 최적의 프롬프트를 찾음.

-   **새로 제안한 핵심 기법:**
    *   **P-Tuning:** 기존의 이산적인(discrete) 텍스트 프롬프트 대신, 미분 가능하고 연속적인 '가상'의 프롬프트 임베딩을 학습하는 방식. 이를 통해 자동화된 프롬프트 최적화가 가능해집니다.
    *   **Prompt Encoder:** 프롬프트 임베딩 간의 상호 의존성을 모델링하고, 더 표현력 높은 프롬프트를 생성하기 위해 작은 신경망(BiLSTM+MLP)을 도입.

### 5. 실험 & 결과

-   **사용한 데이터셋:**
    *   **Knowledge Probing:** LAMA
    *   **Supervised NLU:** SuperGLUE
-   **비교 대상(Baseline):** Manual Prompting, Fine-tuning, BERT 등
-   **평가 지표:** 정확도(Accuracy), P@1 등

-   **가장 중요한 결과:**
    *   **LAMA:** P-Tuning을 사용한 GPT는 추가적인 컨텍스트 없이 세계 지식의 64%(P@1)를 복원하여, 기존 최고 성능 대비 20% 이상 향상.
    *   **SuperGLUE:** 지도 학습 환경에서 P-Tuning을 적용한 GPT는 비슷한 크기의 BERT 모델과 필적하거나 더 나은 성능을 달성.
    *   **파라미터 효율성:** 전체 모델 파라미터의 극히 일부(0.1% ~ 3%)만 학습하여 fine-tuning과 유사한 성능을 냄으로써, 학습 시간, 메모리, 저장 비용을 크게 절감.

### 6. 의의 & 한계

-   **연구가 주는 실제 임팩트:**
    *   LLM을 각 태스크에 맞게 조정하는 데 필요한 비용과 시간을 획기적으로 줄여, LLM의 활용성을 크게 높였습니다.
    *   '프롬프트 엔지니어링'의 불안정성과 수고를 덜고, 자동화된 방식으로 최적의 프롬프트를 찾을 수 있는 길을 열었습니다.
    *   P-Tuning v2, Deep Prompt Tuning 등 후속 연구에 큰 영감을 주며, 파라미터 효율적 튜닝(PEFT) 분야의 핵심적인 연구 중 하나로 자리매김했습니다.

-   **한계점이나 앞으로 개선할 부분:**
    *   P-Tuning v1은 모델의 깊은 레이어까지 프롬프트의 영향력이 전달되기 어렵다는 한계가 있었으며, 이는 후속 연구인 P-Tuning v2에서 개선되었습니다.

### 7. 개인 평가

-   **강점:** LLM 튜닝의 패러다임을 바꾼 혁신적인 아이디어. 단순하면서도 매우 효과적이며, 후속 연구에 미친 영향이 지대합니다.
-   **약점:** v1의 경우, 복잡한 NLU 태스크나 작은 모델에서는 성능 향상이 제한적일 수 있습니다.
-   **적용 가능성:** LLM을 특정 도메인이나 태스크에 저비용으로 적용하고자 할 때 매우 유용합니다. 챗봇, 분류, 요약 등 다양한 NLU 서비스에 활용될 수 있습니다.
-   **추천도:** ★★★★★ (LLM 튜닝 및 활용에 관심 있는 모든 연구자/개발자에게 필독을 권장)