---
categories:
- Transformer
date: 2024-04-06
excerpt: "\uB17C\uBB38\uC694\uC57D"
last_modified_at: 2024-04-06
published: true
tags:
- Transformer
- 2Dslice
- cross-attention
- Brain
title: "ADAPT: Alzheimer\u2019s Diagnosis through Adaptive Profiling Transformers"
toc: true
toc_sticky: true
---

## Introduction

ADAPT: Alzheimer’s Diagnosis through Adaptive Profiling Transformers는 알츠하이머 질병(AD) 진단을 위한 순수 트랜스포머 기반 모델을 제안합니다. 이 모델은 3D MRI 이미지를 축, 관상, 시상 차원을 따라 세 개의 2D 이미지 시퀀스로 분해하고, 여러 2D 슬라이스를 입력으로 결합하여 별도의 2D 트랜스포머 인코더 모델을 사용해 분류합니다. ADAPT는 각 차원에서 캡처된 다양한 특징을 더욱 지능적이고 효율적으로 활용합니다. 특히, 각 차원의 슬라이스와 세 차원 전반에 걸친 attention 인코더를 구축하여, 단순히 슬라이스를 전체적으로 사용하는 것보다 특징 정보를 효과적으로 결합할 수 있습니다.

ADAPT는 특별한 인코더 블록의 이점을 활용하여, 모든 2D 이미지를 입력으로 사용하지 않고도 몇 개의 슬라이스만 사용하여 AD 병리를 학습할 수 있으며, 이를 통해 메모리 사용량을 추가로 줄일 수 있습니다. 제안된 아키텍처는 실제 세계의 AD 진단 문제를 해결하기 위해 설계되었으며, 슬라이스와 시퀀스 간의 정보를 더 잘 수집할 수 있는 새로운 cross attention 메커니즘과 가이드 패치 임베딩을 도입합니다. 또한, AD와 정상 MRI 이미지 간의 구조적 차이를 고려하여 데이터를 증강하기 위한 형태학 증강 방법을 설계했습니다. 모델이 더 중요한 차원에 더 많은 attention를 기울이도록 유도하는 적응형 학습 전략도 제안됩니다.

종합적으로, ADAPT는 모든 베이스라인 중 최고의 성능을 평가받으며 최소한의 메모리를 차지합니다. 이 방법은 의료 영상에서의 글로벌 장기 의존성 정보를 채굴하는 데 기존 CNN이 가지는 한계를 극복하고, 의사들이 MRI를 읽을 때 적용하는 적응적 전략을 모델에 통합하여 더 효율적이고 정확한 진단을 가능하게 합니다.


## Related Work 

**3D Vison Transformer**

  3D Vision Transformer 섹션은 트랜스포머 아키텍처가 자연어 처리에서 큰 성공을 거둔 이후 컴퓨터 비전 분야에서 주목받고 있다는 내용을 다룹니다. Vision Transformer (ViT)는 트랜스포머를 컴퓨터 비전에 도입하고 이미지와 결합하는 새로운 추세를 시작했습니다. 3D 이미지 분류를 위한 attention 기반 방법들이 제안되었고, COVID-VIT, I3D, Pointformer, 3DERT와 같은 여러 작업에서 트랜스포머를 사용하여 뛰어난 성과를 달성했습니다. 이 모델들은 3D 아키텍처를 사용하여 3D 입력을 처리합니다. 반면에, ADAPT는 3D 입력을 다루기 위해 다른 슬라이스와 차원 간의 특징을 추출한 후 이러한 특징들을 결합하는 cross attention 메커니즘을 사용합니다. 이는 의료 영상의 높은 가치와 제한된 데이터셋 크기로 인해 3D 아키텍처의 사용이 비효율적인 의료 분야에서 트랜스포머 아키텍처의 능력을 더 잘 발휘할 수 있게 합니다.

**Deep Learning for Medical Image Analysis**

  Deep Learning for Medical Image Analysis 섹션은 다양한 의료 영상 작업에서 질병 탐지와 진단을 효과적으로 지원하는 뛰어난 딥러닝 기반 모델들이 개발되다는 내용입니다. U-Net과 그 변형들은 이미지 분할에서 널리 사용되며, Attention U-Net은 U-Net 아키텍처에 attention 게이트를 도입하여 중요한 특징을 학습하고 불필요한 특징을 억제합니다.
  의료 영상 분류를 위해서는, AG-CNN이 전역 2D 이미지에서 구별 가능한 영역을 식별하고 전역 및 로컬 정보를 함께 융합하여 흉부 질환을 더 잘 진단하기 위한 attention 메커니즘을 사용합니다. MedicalNet은 전이 학습을 사용한 ResNet 기반 모델을 사용하여 데이터셋 부족 문제를 해결합니다. DomainKnowledge4AD는 ResNet18을 사용하여 고차원 특징을 추출하고, 도메인 고유 특징 및 도메인 특정 특징을 포착하여 알츠하이머 질병(AD)을 예측하는 데 도움을 주는 도메인 지식 인코딩을 제안합니다. M3T는 CNN을 사용하여 로컬 특징을 포착하고 3D MRI 이미지에서 장거리 관계를 위해 전통적인 트랜스포머 인코더를 사용하려고 시도합니다.
  주요 차이점:  M3T는 CNN 뒤에 트랜스포머 블록을 결합하려 시도하지만, 더 큰 모델을 제안하고 모든 슬라이스를 동일하게 취급하는 비효율적인 접근 방식을 취합니다. 본 연구에서는 알츠하이머 분류를 위해 다양한 종류의 인코더를 사용하는 순수 트랜스포머 기반 모델을 사용하며, ADAPT가 분류 정확도 결과와 모델 크기 모두에서 다른 딥러닝 모델을 능가함을 보여줍니다.

## Method 

### MedTransformer Architecture
<p align="center">
  <img src="/assets/images/paper/transformer/ADAPT2.png" alt="ADAPT Architecture" style="width: 100%;">
</p>

ADAPT 아키텍처는 Vision Transformer (ViT) 아키텍처를 기반으로 하며, 이를 확장하여 3D 이미지 모델링을 가능하게 합니다. ADAPT는 주로 4개의 블록으로 구성되어 있습니다:

**Self-Attention Encoders (SAE)**: 세 가지 관점(sagittal,coronal,axial)에 걸친 자기 attention 인코더입니다. 이 인코더들은 뇌의 다양한 패턴에 따라 의사들이 다른 관점에 서로 다른 attention를 기울이는 실제 상황에서 영감을 받았습니다.

**Dimension-specific Self-Attention Encoders (DS-AE)**: 특정 차원에서 슬라이스 자체의 attention를 학습하는 것을 목표로 합니다. DS-AE는 같은 차원 시퀀스의 슬라이스 간 관계에 더 초점을 맞춥니다.

**Intra-dimension Cross-Attention Encoders (IntraCAE)**: 같은 차원 내의 슬라이스들 사이의 특징을 결합합니다.

**Inter-dimension Cross-Attention Encoders (InterCAE)**: 서로 다른 차원들 간의 관계를 학습합니다.


MedTransformer는 3D 이미지를 여러 개의 2D 슬라이스로 분할하여 모델 입력으로 사용합니다. 이는 각 이미지를 시상(sagittal), 관상(coronal), 축상(axial)이라는 세 가지 관점에서 자르는 것을 포함합니다. 각 관점에서 추출된 이미지들은 Vision Transformer(ViT)와 유사하게 패치와 패치 임베딩 방법을 사용하여 3개의 시퀀스로 임베딩되며, 이렇게 임베딩된 슬라이스는 트랜스포머 인코더의 입력으로 연결됩니다. 가이드 패치 임베딩은 전체 시퀀스를 2D 패치의 평평한 시퀀스로 변환하여 각 슬라이스 시퀀스에 글로벌 정보를 추가하는 데 사용됩니다. 이 임베딩은 모델이 3D 뇌의 상대적 위치 정보를 유지하도록 합니다. MedTransformer는 각 패치 임베딩 시퀀스에 학습 가능한 위치 임베딩을 추가하여 위치 정보를 더 잘 인코딩합니다.


$$ S_0 = \left[ x_{\text{class}}; x_{p1} + x_{\text{guide}}; \cdots; x_{pn} + x_{\text{guide}} \right]_{\text{sagittal}}; \cdots; \left[ x_{p2n} + x_{\text{guide}}; \cdots; x_{p3n} + x_{\text{guide}} \right]_{\text{coronal}}; \cdots; \left[ x_{p3n} + x_{\text{guide}} \right]_{\text{axial}} $$

MedTransformer 모델에서 하위 레이어 인코더들은 $$S_0$$를 입력으로 받아, 다양한 슬라이스와 관점 간의 bias attention를 학습합니다. 특히, 세 가지 관점(sagittal,coronal,axial)에 걸친 Self-Attention Encoders(SAE)는 슬라이스 자체의 attention뿐만 아니라 모든 슬라이스 간의 관계도 학습하도록 설계되어 있습니다. 이러한 네트워크는 같은 가중치를 공유하는 Siamese networks입니다. 또한, 네트워크 훈련 전에 각 슬라이스에 대한 특정 토큰을 설정합니다.

$$ S_0 = S_0 + E_{\text{pos}} $$
$$ E_{\text{pos}} \in \mathbb{R}^{(3 \cdot n \cdot N+1) \times D} $$

**dimension-specific Self-Attention Encoders (DS-AE)**는 각 슬라이스 자체에 대한 attention를 학습하는 것을 목표로 하지만, 공유 자기 attention 인코더(SAE)와 달리 DS-AE는 동일한 차원 시퀀스 내의 슬라이스 간 관계만을 학습합니다. 이는 MedTransformer 아키텍처 내에서 각기 다른 세 가지 관점에 대해 서로 다른 세 개의 인코더가 있음을 의미하며, 각각 동일한 수의 레이어 $$L_DSAE$$ 를 가지고 있습니다. 여기서 t는 세 가지 다른 관점을 나타냅니다.

$$ S_0^s = [x_{\text{class}}^s; x_p^s] \quad s \in (1, 3 \cdot n) $$
$$ S_l^s = \text{SAE}(S_{l-1}^s) \quad l = 1...L_{\text{SAE}} $$

DSAE(Dimension-specific Self-Attention Encoders)의 각 관점에서 나온 출력은 해당 관점의 **Intra-dimension Cross-Attention Encoders(IntraCAE)**의 입력으로 사용됩니다. MedTransformer는 입력 임베딩에 대해 크로스 임베딩 메커니즘을 적용하며, IntraCAE를 거친 후에는 동일한 관점의 다른 슬라이스에서 얻은 특징들이 충분히 결합됩니다. DSAE의 아키텍처를 따라, 각 관점에 의존하는 인코더는 $$L_IntraCAE$$ 레이어를 가질 것입니다.


$$ S_l^{t \cdot s} = \text{DSAE}_t(S_{l-1}^{t \cdot s}) \quad s \in (1,n), t \in (1,3) $$
$$ l = (L_{\text{SAE}} + 1)...(L_{\text{SAE}} + L_{\text{DSAE}}) $$


같은 차원 내의 슬라이스 간 특징을 독립적으로 결합한 후, 서로 다른 관점에서 나온 다양한 시퀀스 간의 차원 간 관계를 학습하기 위해 **Inter-dimension Cross-Attention Encoders (InterCAE)**가 제안됩니다. InterCAE는 각 관점에 종속된 임베딩에 다시 한 번 크로스 임베딩 메커니즘을 적용합니다. MedTransformer는 $$L_InterCAE$$ 레이어를 가진 하나의 인코더만을 가지고 있어, 이를 통해 다양한 차원 간의 특징들을 통합하고 장거리 의존성을 모델링합니다.

$$ S_l^{t \cdot s} = \text{IntraCAE}_t(S_{l-1}^{t \cdot s}) \quad s \in (1,n), t \in (1,3) $$
$$ l = (L_{\text{SAE}} + L_{\text{DSAE}} + 1)...(L_{\text{SAE}} + L_{\text{DSAE}} + L_{\text{IntraCAE}}) $$

마지막으로, 세 차원에서 나온 출력의 특정 토큰들은 평균을 내어 Layer Norm과 분류를 위한 다층 퍼셉트론(MLP) 헤드로 전달됩니다. 



### Fusion Attention Mechanism

다양한 슬라이스와 관점 간 정보를 더 효과적으로 결합하기 위해, 새롭고 간단한 cross attention 메커니즘을 제안합니다. 이 메커니즘을 'fusion attention'라고 부릅니다. 융합 attention 메커니즘은 서로 다른 임베딩을 직접 합치려고 시도합니다. 하지만 단순히 하나씩 임베딩을 더하는 것과는 달리, 토큰이 아닌 패치를 나타내는 임베딩을 추가합니다. 이전 인코더에서 각 임베딩의 [class] 토큰은 하나의 슬라이스로부터 정보를 집약하였기 때문에, 이 연산은 attention를 학습할 때 임베딩이 스스로에게 더 집중할 수 있도록 하는 것을 목표로 합니다. 동시에, 이는 다른 슬라이스나 차원에서의 특징 정보를 추출할 수도 있습니다. 여기에서는 IntraCAE를 예로 들고 있습니다.

$$ S_l^{'s} = x_{\text{class}}^{'s} \left( \Phi_{(c-1)\cdot n+1}^{c\cdot n} + x_{p_{\cdot n}^{'s}} \right) \text{ where } s \in (1, n), t \in (1, 3) $$

이 문단은 두 임베딩을 사용하여 전통적인 어텐션 메커니즘을 수학적으로 접근하는 방식을 설명합니다. 두 임베딩을 결합한 후, 첫 번째 임베딩의 K 행렬은 첫 번째 임베딩의 특정 토큰과 결합 임베딩에 해당하는 K 값들로 구성됩니다. Q 행렬도 유사한 방식으로 구성됩니다. 행렬 계산 후, 특정 토큰의 독특한 정보를 일부 유지하면서 두 임베딩에서의 정보를 크게 결합하는 것이 Eq. 16의 결과입니다.

$$ H = \text{softmax}\left(\frac{QK^T}{d_k}\right)V $$

$$ K_1 = [K_{\text{class}}, K_1 + K_2], Q_1 = [Q_{\text{class}}, Q_1 + Q_2] $$

$$ QK^T = \begin{bmatrix} Q_{\text{class}} \\ (Q_1 + Q_2) \end{bmatrix} \left[ K_{\text{class}}, (K_1 + K_2) \right] \left[ (Q_1 + Q_2), K_{\text{class}} \right] $$

### Morphology Augmentation

해당 텍스트는 알츠하이머병(AD)과 정상 상태의 이미지를 시각화한 후 얻은 중요한 통찰을 설명합니다. AD와 정상 이미지 간 뇌 질량의 위축 정도가 상당히 다르다는 것을 발견합니다. 이러한 발견에 기반하여, 모델이 두 클래스를 구분하는 능력을 향상시키는데 도움이 되는 형태학 증강(morphology augmentation)이라는 증강 방법을 제안합니다. 이 증강은 스케일 침식과 팽창(scale erosion and dilation)에 기반한 것으로, 아래 식에 나타나 있습니다. 여기서 f는 입력 이미지, ⊕ 또는 ⊖는 침식이나 팽창 요소를 나타내며, (x,y)와 (s,t)는 각각 f와 ⊕ 또는 ⊖에서의 좌표입니다. 이러한 형태학적 조작을 통해 뇌 위축의 크기를 확장하거나 줄임으로써, 뇌 위축을 특징으로 하는 알츠하이머병을 더 정확히 식별할 수 있게 됩니다.

$$ F \oplus b_{\downarrow}(x, y) = \min_{(s,t) \in b_{\downarrow}} \{ f(x + s, y + t) - b_{\downarrow}(s,t) \} $$

$$ F \oplus b_{\uparrow}(x, y) = \max_{(s,t) \in b_{\uparrow}} \{ f(x - s, y - t) + b_{\uparrow}(s,t) \} $$

형태학 증강의 시각화는 Fig. 3에서 보여집니다. 알츠하이머병(AD) 이미지에 대해서는 침식 기반 형태학 증강을, 정상 대조군(Normal Control, NC) 이미지에 대해서는 팽창 기반 형태학 증강을 수행합니다. 이를 통해 AD에서는 위축 크기가 증가하지만, NC에서는 감소합니다. 형태학 증강을 사용함으로써 AD와 NC 이미지를 증강하는 것뿐만 아니라, 경도인지장애(Mild Cognitive Impairment, MCI) 데이터를 더 효율적으로 활용할 수 있습니다. MCI는 AD의 전단계 상태이므로, MCI 데이터에 대해 침식 기반의 형태학 증강을 수행하여 AD로 분류할 수 있고, 동시에 팽창 기반의 형태학 증강을 수행한 후 정상 데이터로 분류할 수 있습니다. 이러한 방식은 MCI가 AD로 진행될 가능성이 있는 중간 단계임을 고려하여 AD와 정상 사이의 연속적인 스펙트럼을 모델링하는데 도움이 됩니다.

<p align="center">
  <img src="/assets/images/paper/transformer/ADAPT3.png" alt="ADAPT Architecture" style="width: 100%;">
</p>