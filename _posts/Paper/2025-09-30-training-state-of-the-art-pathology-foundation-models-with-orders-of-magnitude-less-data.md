---
title: Training state-of-the-art pathology foundation models with orders of magnitude less data
excerpt: DINOv2 개선+고해상도 사후튜닝으로 WSI를 최대 100배 적게 쓰고도 SOTA급; TCGA 1.2만 WSI로 평균 Virchow2 수준.
date: 2025-09-30
categories:
- paper
- medical-ai
- pathology
- foundation-models
published: true
tags:
- Foundation-Model
- DINOv2
- Self-supervised
- Pathology
- WSI
- foundation-models
last_modified_at: '2025-09-30'
toc: true
toc_sticky: true
header: {}
---

# Training state-of-the-art pathology foundation models with orders of magnitude less data

## 0. 체크리스트
- [x] `categories` 두 번째 값을 `medical-ai`로 설정했나요?
- [x] `excerpt`에 핵심 성능/데이터 효율 요지를 담았나요?
- [x] 모든 섹션을 실제 논문 내용 기반으로 요약했나요?
- [x] 과도한 표/수치 없이 핵심 메시지를 전달하나요?
- [x] 참고 링크를 정리했나요?

## 1. 핵심 요약 (3문장 이하)
- 병리학 WSI로 학습하는 파운데이션 모델을, 표준 DINOv2 프레임워크의 최신 변형과 고해상도 사후 파인튜닝(post-training)을 결합해 데이터 효율적으로 학습합니다.
- 3개의 신규 병리 FM을 제시하며, 기존 SOTA가 요구한 데이터량 대비 최대 두 자릿수(최대 100배) 적은 WSI만으로도 다운스트림 과제에서 동급 혹은 더 나은 성능을 보입니다.
- 특히 TCGA 1.2만 WSI만으로 학습한 모델조차 다수의 기존 FM을 능가하고, 평균적으로 Virchow2와 비슷한 수준의 성능을 보입니다.

## 2. 배경 & 동기
- 최근 병리 파운데이션 모델은 수백만 타일/수백만 장 WSI 규모의 데이터와 대형 모델을 기반으로 발전해 왔습니다. 하지만 임상 현장이나 연구실에서 그러한 데이터와 연산 자원을 확보하기는 어렵습니다.
- 문제의식은 “데이터/모델 규모 확대”만이 SOTA의 길인지에 대한 의문입니다. 저자들은 도메인 특화 학습 설계와 사후 고해상도 파인튜닝만으로도 데이터 효율을 크게 개선할 수 있음을 보입니다.
- 목표는 더 적은 데이터로도 강력한 병리 표현을 학습하는 실용적 학습 레시피를 제시하는 것입니다.

## 3. 방법론
### 3.1 전체 구조
- 기본 골자는 DINOv2 자기지도 사전학습으로 타일 임베딩을 학습하고, 이후 고해상도 입력으로 추가 파인튜닝하여 임베딩의 세부 정보량을 높입니다.
- 표준 병리 파이프라인(WSI 타일링, 색상 변이/정규화 등)을 따르며, 사전학습 임베딩은 다양한 다운스트림 과제의 특징 추출기로 활용됩니다.
- 결과적으로 타일 수준 표현의 품질을 높이되, 데이터량은 기존 대규모 FM 대비 현저히 줄이는 것을 목표로 합니다.

### 3.2 핵심 기법
- 문헌에서 제안된 DINOv2 개선점들을 병리 도메인에 맞게 통합해 학습 안정성과 표현력을 강화합니다.
- 학습 이후 고해상도 이미지에 대한 사후 파인튜닝을 적용해, 세포·조직 수준의 미세 패턴을 더 풍부하게 임베딩에 반영합니다.
- 이 조합이 데이터 효율과 다운스트림 일반화 성능을 동시에 끌어올리는 핵심 설계입니다.

### 3.3 학습 및 구현 세부
- 데이터는 TCGA(약 1.2만 WSI) 단독 설정을 포함해, 더 작은 규모에서도 효과를 검증합니다.
- 사전학습은 표준 해상도·타일 크기에서 진행하고, 사후 단계에서 더 큰 해상도로 미세조정해 표현의 세밀도를 보강합니다.
- 구현은 공개 문헌 기반의 DINOv2 변형들을 조합한 것으로, 재현을 위해 동일 계열의 증강·옵티마이저·스케줄을 유지하는 것이 권장됩니다.

## 4. 실험 & 결과
### 4.1 설정
- 다양한 병리 다운스트림 과제(타일/슬라이드 수준 분류 등)로 일반화 성능을 평가하며, 기존 공개된 병리 FM들과 비교합니다.
- 비교군에는 대규모 데이터·모델 규모로 학습된 최신 FM들이 포함되며, 특히 Virchow2와의 평균 성능 비교가 강조됩니다.

### 4.2 주요 결과표
| Model | #WSIs | Avg. | PCam (pc) | CoNSeP (cnsp) | MoNuSAC (mnsc) | HEST |
| --- | --- | --- | --- | --- | --- | --- |
| Midnight-92k/392 | 92k | 0.778 | 0.951 | 0.662 | 0.708 | 0.415 |
| Midnight-92k | 92k | 0.767 | 0.948 | 0.629 | 0.656 | 0.425 |
| Midnight-12k | 12k | 0.763 | 0.931 | 0.625 | 0.664 | 0.412 |
| Virchow2 | 3.1M | 0.766 | 0.938 | 0.640 | 0.674 | 0.403 |
| UNI-2 | 350k | 0.776 | 0.951 | 0.626 | 0.644 | 0.431 |

### 4.3 추가 분석
- 고해상도 사후 파인튜닝 효과: Midnight-92k → 92k/392에서 Avg +0.011, CoNSeP +0.033, MoNuSAC +0.052로 특히 분할 지표 개선이 큽니다.
- 데이터 효율: Midnight-12k(12k WSI)의 평균 0.763은 Virchow2(3.1M WSI, 258×)의 0.766과 근접해 데이터 규모 의존성을 크게 낮춥니다.
- 도메인 중요성: 자연 이미지 사전학습 비전 백본(vitg14 nat. img.) 평균 0.674보다 모든 병리 FM이 큰 폭으로 우월합니다.
- 참고: UNI/512(512×512로 리사이즈) 평가는 PCam 0.89 등으로 오히려 감소해, 본 논문의 고해상도 사후튜닝과는 성격이 다름을 시사합니다.

## 5. 의의 & 한계
- 의의: 데이터 수집·정제 비용이 큰 병리 도메인에서, 상대적으로 작은 데이터로도 범용 표현을 학습하는 실용적 경로를 제시합니다. 대규모 사내 데이터가 없는 팀에도 강력한 FM을 구축할 수 있는 가능성을 엽니다.
- 한계: 상세 수치·설정 공개 범위에 따라 재현성 편차가 생길 수 있고, 특정 장비/염색/기관 분포에서의 일반화는 별도 검증이 필요합니다. 또한 고해상도 사후 단계는 여전히 연산 비용이 커질 수 있습니다.

## 6. 개인 평가
**강점**: 데이터 효율을 전면에 둔 설계로, 실제 조직 내 도입 장벽(데이터/컴퓨트)을 낮춘 점이 돋보입니다. Virchow2와의 평균 동급 성능은 실전 활용 가치를 강하게 시사합니다.  
**약점**: DINOv2 변형의 구체 레시피와 각 요소 기여도의 정량적 분해가 충분치 않다면 재현·전이 시 시행착오가 클 수 있습니다.  
**적용 가능성**: 사내 데이터가 수천~1만 슬라이드 수준인 팀에서 범용 병리 임베딩 백본으로 바로 검토할 만합니다.  
**추천도**: ★★★★☆ (데이터 제약 환경의 병리 FM 구축에 강력 추천)

## 7. 참고 자료
- 원문: [arXiv:2504.05186](http://arxiv.org/abs/2504.05186)
- 비교 참조: [Virchow2: Scaling Self-Supervised Mixed Magnification Models in Pathology](http://arxiv.org/abs/2408.00738)
