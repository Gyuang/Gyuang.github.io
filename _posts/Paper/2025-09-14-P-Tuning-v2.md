---
title: "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"
categories:
  - Paper
  - Medical AI
tags:
  - Prompt Tuning
  - Parameter Efficient
  - Deep Prompt
  - NLP
toc: true
toc_sticky: true
toc_label: "P-Tuning v2"
header:
  teaser: /assets/images/paper/p-tuning-v2-teaser.png
---

# P-Tuning v2: 모든 스케일과 태스크에서 Fine-tuning과 비교 가능한 Prompt Tuning

## 논문 정보
- **저자**: Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Lam Tam, Zhengxiao Du, Zhilin Yang, Jie Tang
- **발표**: ACL 2022
- **ArXiv**: [2110.07602](https://arxiv.org/abs/2110.07602)

## 핵심 기여

P-Tuning v2는 기존 P-Tuning의 한계를 극복하고 deep prompt tuning을 통해 NLU(Natural Language Understanding) 태스크에서 fine-tuning과 비슷한 성능을 달성한 연구입니다.

## 주요 개선사항

### 1. Deep Prompt Tuning
- **기존 문제**: P-tuning v1은 입력 임베딩 레이어에만 continuous prompt를 적용
- **해결방안**: 모든 transformer 레이어에 prompt를 적용하는 deep prompt tuning 도입
- **효과**: 각 레이어에서 서로 다른 정보를 학습하여 성능 향상

### 2. Multi-task Learning
- **범용성**: NLU 태스크 전반에서 일관된 성능 향상
- **스케일링**: 모델 크기에 관계없이 효과적
- **효율성**: 전체 파라미터의 0.1%-3%만으로 full fine-tuning과 비슷한 성능

### 3. 레이어별 Prompt 위치의 중요성
- **입력 레이어만**: 제한된 성능
- **모든 레이어**: 각 레이어가 서로 다른 언어적 특성을 학습
- **결과**: 레이어별 prompt가 성능에 결정적 영향

## 실험 결과

### SuperGLUE 벤치마크
- **GPT**: P-tuning v2로 70.1% → 71.6% 성능 향상
- **BERT**: 다양한 NLU 태스크에서 fine-tuning 대비 0.5% 이내 성능 차이
- **RoBERTa**: 일부 태스크에서 fine-tuning을 넘어서는 성능

### 파라미터 효율성
- **전통적 fine-tuning**: 100% 파라미터 업데이트
- **P-tuning v2**: 0.1%-3% 파라미터만 업데이트
- **성능**: fine-tuning과 거의 동등한 결과

## 기술적 세부사항

### Prompt 설계
```
[P0][P1]...[Pi] [input tokens]
```
- 각 레이어 l에서: `h^l_i = Prompt^l_i` (i ≤ |P|)
- Prompt 길이: 태스크별로 최적화 (일반적으로 20-100 토큰)

### 최적화 전략
- **학습률**: Prompt 파라미터에 대해 별도 학습률 적용
- **초기화**: 랜덤 초기화 vs. 단어 임베딩 기반 초기화
- **정규화**: 드롭아웃 등을 통한 과적합 방지

## 소프트 프롬프트 위치 효과

### 레이어별 분석
1. **하위 레이어**: 구문적(syntactic) 정보 학습
2. **중간 레이어**: 의미적(semantic) 정보 학습  
3. **상위 레이어**: 태스크별 특화 정보 학습

### 위치별 성능 비교
- **입력만**: 기본 P-tuning 수준
- **모든 레이어**: 2-5% 성능 향상
- **선택적 레이어**: 태스크에 따라 최적화 가능

## 실무 적용

### 장점
- **메모리 효율성**: GPU 메모리 사용량 대폭 감소
- **빠른 적응**: 새로운 태스크에 빠른 적응
- **안정성**: fine-tuning보다 안정적인 학습

### 한계
- **초기 설정**: Prompt 길이와 위치 설정이 중요
- **태스크 의존성**: 일부 복잡한 태스크에서는 여전히 한계
- **해석가능성**: Prompt가 학습하는 내용의 해석이 어려움

## 의의와 영향

P-Tuning v2는 **레이어별 prompt 위치**가 성능에 미치는 결정적 영향을 보여준 중요한 연구입니다. 특히 모든 레이어에 prompt를 적용함으로써 각 레이어가 서로 다른 언어적 특성을 학습할 수 있음을 입증했습니다.

이 연구는 이후 parameter-efficient fine-tuning 방법론의 발전에 큰 영향을 미쳤으며, **소프트 프롬프트의 위치가 성능에 미치는 영향**에 대한 이해를 크게 발전시켰습니다.