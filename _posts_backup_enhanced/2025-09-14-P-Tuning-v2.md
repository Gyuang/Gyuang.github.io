---
categories:
- Paper
- VLM
date: '2025-09-16'
excerpt: 'P-Tuning v2: 모든 스케일과 태스크에서 Fine-tuning과 비교 가능한 Prompt Tuning에 대한 체계적 분석'
header:
  teaser: /assets/images/paper/p-tuning-v2-teaser.png
last_modified_at: '2025-09-16'
published: true
tags:
- Prompt Tuning
- Parameter Efficient
- Deep Prompt
- NLP
title: 'P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across
  Scales and Tasks'
toc: true
toc_sticky: true
---

# P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks

## 논문 정보
- **저자**: **: Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Lam Tam, Zhengxiao Du, Zhilin Yang, Jie Tang
- **발표**: **: ACL 2022
- **ArXiv**: N/A

## 1. 핵심 요약 (2-3문장)
이 논문의 핵심 기여와 주요 발견을 간결하게 요약합니다.

## 2. 배경 및 동기
기존 방법의 한계점과 연구의 필요성을 설명합니다.

## 3. 제안 방법

### 3.1 아키텍처 개요


### 3.2 핵심 기술/알고리즘
- **저자**: Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Lam Tam, Zhengxiao Du, Zhilin Yang, Jie Tang
- **발표**: ACL 2022
- **ArXiv**: [2110.07602](https://arxiv.org/abs/2110.07602)



![Results Table 4 1](/assets/images/paper/p-tuning-v2/results_table_4_1.png)
*Figure: Experimental results and performance metrics*
*Figure: Results Table 4 1*

P-Tuning v2는 기존 P-Tuning의 한계를 극복하고 deep prompt tuning을 통해 NLU(Natural Language Understanding) 태스크에서 fine-tuning과 비슷한 성능을 달성한 연구입니다.




- **기존 문제**: P-tuning v1은 입력 임베딩 레이어에만 continuous prompt를 적용
- **해결방안**: 모든 transformer 레이어에 prompt를 적용하는 deep prompt tuning 도입
- **효과**: 각 레이어에서 서로 다른 정보를 학습하여 성능 향상


- **범용성**: NLU 태스크 전반에서 일관된 성능 향상
- **스케일링**: 모델 크기에 관계없이 효과적
- **효율성**: 전체 파라미터의 0.1%-3%만으로 full fine-tuning과 비슷한 성능


- **입력 레이어만**: 제한된 성능
- **모든 레이어**: 각 레이어가 서로 다른 언어적 특성을 학습
- **결과**: 레이어별 prompt가 성능에 결정적 영향


- **GPT**: P-tuning v2로 70.1% → 71.6% 성능 향상
- **BERT**: 다양한 NLU 태스크에서 fine-tuning 대비 0.5% 이내 성능 차이
- **RoBERTa**: 일부 태스크에서 fine-tuning을 넘어서는 성능


- **전통적 fine-tuning**: 100% 파라미터 업데이트
- **P-tuning v2**: 0.1%-3% 파라미터만 업데이트
- **성능**: fine-tuning과 거의 동등한 결과




```
[P0][P1]...[Pi] [input tokens]
```
- 각 레이어 l에서: `h^l_i = Prompt^l_i` (i ≤ |P|)
- Prompt 길이: 태스크별로 최적화 (일반적으로 20-100 토큰)


- **학습률**: Prompt 파라미터에 대해 별도 학습률 적용
- **초기화**: 랜덤 초기화 vs. 단어 임베딩 기반 초기화
- **정규화**: 드롭아웃 등을 통한 과적합 방지




1. **하위 레이어**: 구문적(syntactic) 정보 학습
2. **중간 레이어**: 의미적(semantic) 정보 학습  
3. **상위 레이어**: 태스크별 특화 정보 학습




- **메모리 효율성**: GPU 메모리 사용량 대폭 감소
- **빠른 적응**: 새로운 태스크에 빠른 적응
- **안정성**: fine-tuning보다 안정적인 학습


- **초기 설정**: Prompt 길이와 위치 설정이 중요
- **태스크 의존성**: 일부 복잡한 태스크에서는 여전히 한계
- **해석가능성**: Prompt가 학습하는 내용의 해석이 어려움



![Results Table 7 0](/assets/images/paper/p-tuning-v2/results_table_7_0.png)
*Figure: Experimental results and performance metrics*
*Figure: Results Table 7 0*

![Results Table 7 1](/assets/images/paper/p-tuning-v2/results_table_7_1.png)
*Figure: Experimental results and performance metrics*
*Figure: Results Table 7 1*

![Results Table 7 2](/assets/images/paper/p-tuning-v2/results_table_7_2.png)
*Figure: Experimental results and performance metrics*
*Figure: Results Table 7 2*

![Results Table 7 3](/assets/images/paper/p-tuning-v2/results_table_7_3.png)
*Figure: Experimental results and performance metrics*
*Figure: Results Table 7 3*

### 3.3 구현 세부사항


## 4. 실험 및 결과

### 4.1 실험 설정
실험에 사용된 데이터셋, 평가 지표, 비교 대상을 설명합니다.

### 4.2 주요 결과

![Results Table 4 1](/assets/images/paper/p-tuning-v2/results_table_4_1.png)
*Figure: Results Table 4 1*


![Results Table 4 0](/assets/images/paper/p-tuning-v2/results_table_4_0.png)
*Figure: Results Table 4 0*


![Results Table 7 0](/assets/images/paper/p-tuning-v2/results_table_7_0.png)
*Figure: Results Table 7 0*



![Results Table 4 0](/assets/images/paper/p-tuning-v2/results_table_4_0.png)
*Figure: Experimental results and performance metrics*
*Figure: Results Table 4 0*


- **입력만**: 기본 P-tuning 수준
- **모든 레이어**: 2-5% 성능 향상
- **선택적 레이어**: 태스크에 따라 최적화 가능

### 4.3 분석
결과에 대한 정성적 분석과 해석을 제공합니다.

## 5. 의의 및 영향
P-Tuning v2는 **레이어별 prompt 위치**가 성능에 미치는 결정적 영향을 보여준 중요한 연구입니다. 특히 모든 레이어에 prompt를 적용함으로써 각 레이어가 서로 다른 언어적 특성을 학습할 수 있음을 입증했습니다.

이 연구는 이후 parameter-efficient fine-tuning 방법론의 발전에 큰 영향을 미쳤으며, **소프트 프롬프트의 위치가 성능에 미치는 영향**에 대한 이해를 크게 발전시켰습니다.

## 6. 개인적 평가

**강점**: 이 논문의 주요 강점과 인상 깊었던 부분
**약점**: 아쉬웠던 부분이나 의문점  
**적용 가능성**: 실제 연구나 응용에서의 활용 가능성
**추천도**: 다른 연구자들에게 추천할 만한 수준

